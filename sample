.I 1
.T
document.1
.W
Computer-generated imagery
Computer-generated imagery (CGI for short) is the application of computer graphics to create or contribute to images in art, printed media, video games, films, television programs, shorts, commercials, videos, and simulators. The visual scenes may be dynamic or static, and may be two-dimensional (2D), though the term "CGI" is most commonly used to refer to 3D computer graphics used for creating scenes or special effects in films and television. Additionally, the use of 2D CGI is often mistakenly referred to as "traditional animation", most often in the case when dedicated animation software such as Adobe Flash or Toon Boom is not used and/or the CGI is hand drawn using (a) tablet(s) and/or mouse.
The term 'CGI animation' refers to dynamic CGI rendered as a movie. The term virtual world refers to agent-based, interactive environments. Computer graphics software is used to make computer-generated imagery for films, etc. Availability of CGI software and increased computer speeds have allowed individual artists and small companies to produce professional-grade films, games, and fine art from their home computers. This has brought about an Internet subculture with its own set of global celebrities, clichés, and technical vocabulary. The evolution of CGI led to the emergence of virtual cinematography in the 1990s where runs of the simulated camera are not constrained by the laws of physics.
Static images and landscapes
Not only do animated images form part of computer-generated imagery, natural looking landscapes (such as fractal landscapes) are also generated via computer algorithms. A simple way to generate fractal surfaces is to use an extension of the triangular mesh method, relying on the construction of some special case of a de Rham curve, e.g. midpoint displacement. For instance, the algorithm may start with a large triangle, then recursively zoom in by dividing it into four smaller Sierpinski triangles, then interpolate the height of each point from its nearest neighbors. The creation of a Brownian surface may be achieved not only by adding noise as new nodes are created, but by adding additional noise at multiple levels of the mesh. Thus a topographical map with varying levels of height can be created using relatively straightforward fractal algorithms. Some typical, easy-to-program fractals used in CGI are the plasma fractal and the more dramatic fault fractal.
The large number of specific techniques have been researched and developed to produce highly focused computer-generated effects — e.g. the use of specific models to represent the chemical weathering of stones to model erosion and produce an "aged appearance" for a given stone-based surface.
Architectural scenes
Modern architects use services from computer graphic firms to create 3-dimensional models for both customers and builders. These computer generated models can be more accurate than traditional drawings. Architectural animation (which provides animated movies of buildings, rather than interactive images) can also be used to see the possible relationship a building will have in relation to the environment and its surrounding buildings. The rendering of architectural spaces without the use of paper and pencil tools is now a widely accepted practice with a number of computer-assisted architectural design systems.
Architectural modelling tools allow an architect to visualize a space and perform "walk-throughs" in an interactive manner, thus providing "interactive environments" both at the urban and building levels. Specific applications in architecture not only include the specification of building structures (such as walls and windows) and walk-throughs, but the effects of light and how sunlight will affect a specific design at different times of the day.
Architectural modelling tools have now become increasingly internet-based. However, the quality of internet-based systems still lags behind those of sophisticated inhouse modelling systems.
In some applications, computer-generated images are used to "reverse engineer" historical buildings. For instance, a computer-generated reconstruction of the monastery at Georgenthal in Germany was derived from the ruins of the monastery, yet provides the viewer with a "look and feel" of what the building would have looked like in its day.
Anatomical models
Computer generated models used in skeletal animation are not always anatomically correct. However, organizations such as the Scientific Computing and Imaging Institute have developed anatomically correct computer-based models. Computer generated anatomical models can be used both for instructional and operational purposes. To date, a large body of artist produced medical images continue to be used by medical students, such as images by Frank Netter, e.g. Cardiac images. However, a number of online anatomical models are becoming available.
A single patient X-ray is not a computer generated image, even if digitized. However, in applications which involve CT scans a three dimensional model is automatically produced from a large number of single slice x-rays, producing "computer generated image". Applications involving magnetic resonance imaging also bring together a number of "snapshots" (in this case via magnetic pulses) to produce a composite, internal image.
In modern medical applications, patient specific models are constructed in 'computer assisted surgery'. For instance, in total knee replacement, the construction of a detailed patient specific model can be used to carefully plan the surgery. These three dimensional models are usually extracted from multiple CT scans of the appropriate parts of the patient's own anatomy. Such models can also be used for planning aortic valve implantations, one of the common procedures for treating heart disease. Given that the shape, diameter and position of the coronary openings can vary greatly from patient to patient, the extraction (from CT scans) of a model that closely resembles a patient's valve anatomy can be highly beneficial in planning the procedure.
Generating cloth and skin images
Models of cloth generally fall into three groups:
	•	The geometric-mechanical structure at yarn crossing
	•	The mechanics of continuous elastic sheets
	•	The geometric macroscopic features of cloth.
To date, making the clothing of a digital character automatically fold in a natural way remains a challenge for many animators.
In addition to their use in film, advertising and other modes of public display, computer generated images of clothing are now routinely used by top fashion design firms.
The challenge in rendering human skin images involves three levels of realism:
	•	Photo realism in resembling real skin at the static level
	•	Physical realism in resembling its movements
	•	Function realism in resembling its response to actions.
The finest visible features such as fine wrinkles and skin pores are size of about 100 µm or 0.1 millimetres. Skin can be modelled as a 7-dimensional bidirectional texture function (BTF) or a collection of bidirectional scattering distribution function (BSDF) over the target's surfaces.
Interactive simulation and visualization
Interactive visualization is a general term that applies to the rendering of data that may vary dynamically and allowing a user to view the data from multiple perspectives. The applications areas may vary significantly, ranging from the visualization of the flow patterns in fluid dynamics to specific computer aided design applications. The data rendered may correspond to specific visual scenes that change as the user interacts with the system — e.g. simulators, such as flight simulators, make extensive use of CGI techniques for representing the world.
At the abstract level an interactive visualization process involves a "data pipeline" in which the raw data is managed and filtered to a form that makes it suitable for rendering. This is often called the "visualization data". The visualization data is then mapped to a "visualization representation" that can be fed to a rendering system. This is usually called a "renderable representation". This representation is then rendered as a displayable image. As the user interacts with the system (e.g. by using joystick controls to change their position within the virtual world) the raw data is fed through the pipeline to create a new rendered image, often making real-time computational efficiency a key consideration in such applications.
Computer animation
While computer generated images of landscapes may be static, the term computer animation only applies to dynamic images that resemble a movie. However, in general the term computer animation refers to dynamic images that do not allow user interaction, and the term virtual world is used for the interactive animated environments.
Computer animation is essentially a digital successor to the art of stop motion animation of 3D models and frame-by-frame animation of 2D illustrations. Computer generated animations are more controllable than other more physically based processes, such as constructing miniatures for effects shots or hiring extras for crowd scenes, and because it allows the creation of images that would not be feasible using any other technology. It can also allow a single graphic artist to produce such content without the use of actors, expensive set pieces, or props.
To create the illusion of movement, an image is displayed on the computer screen and repeatedly replaced by a new image which is similar to the previous image, but advanced slightly in the time domain (usually at a rate of 24 or 30 frames/second). This technique is identical to how the illusion of movement is achieved with television and motion pictures.
Virtual worlds
A virtual world is a simulated environment, which allows user to interact with animated characters, or interact with other users through the use of animated characters known as avatars. Virtual worlds are intended for its users to inhabit and interact, and the term today has become largely synonymous with interactive 3D virtual environments, where the users take the form of avatars visible to others graphically. These avatars are usually depicted as textual, two-dimensional, or three-dimensional graphical representations, although other forms are possible (auditory and touch sensations for example). Some, but not all, virtual worlds allow for multiple users.
In courtrooms
Computer-generated imagery has been used in courtrooms, primarily since the early 2000s. However, some experts have argued that it is prejudicial. They are used to help judges or the jury to better visualize the sequence of events, evidence or hypothesis. However, a 1997 study showed that people are poor intuitive physicists and easily influenced by computer generated images. Thus it is important that jurors and other legal decision-makers be made aware that such exhibits are merely a representation of one potential sequence of events.
.I 10
.T
document.10
.W
The History and Evolution of Computer Generated Imagery
Allison Slaton

Computer Generated Imagery (CGI) uses computer graphics to create images in art, printed media, video games, films, television programs, commercials, and simulators. The term "CGI" generally refers to 3D computer graphics used for creating scenes or special effects in films and television, but the visual scenes can also be dynamic or static or 2D. They can even be used by a home user and edited together with other programs. 
The very first movie to use computer animations is a ten minute film by Charles Csuri and James Shaffer. The film shows lines come together into a drawing of a hummingbird. The sequence of movements, which consisted of over 30,000 images and about 25 motion sequences, was generated by the computer and programmed to bring the bird to life. Check it out:

Charles Csuri, Fragmentation Animations, 1968 - 1970: Hummingbird (1968)
Shortly after this short film was created, a group of Russian mathematicians and physicists used a computer program to create a mathematical model of a moving cat. The program allowed them to print hundreds of frames that were later converted to film. Look at this cool cat...

Kitty. - N.Konstantinov.
In the 1970s, many more films were created using CGI. Producers were experimenting with 2D animation by using new inventions like keyframe animation software. 
Thumbnail for Key frame - Wikipedia, the free encyclopedia
Key frame - Wikipedia, the free encyclopedia
[edit] Use of key frames. In computer animation the workflow is basically the same . The animator creates the important frames of a sequ...

WIKIPEDIA
How it works:

Key Frame Animation
The very first feature film to use 2D animation is Westworld, a 1973 science fiction-thriller.
This movie even made it in this article's top 25 best movie CGI effects ever!
Thumbnail for 25 best movie CGI effects ever | Stuff magazine - Stuff.tv
25 best movie CGI effects ever | Stuff magazine - Stuff.tv
Sep 9, 2012 ... 25 best cgi movie effects ever. Westworld (1973). Westworld saw whe first use of 2D digital imagery in the cinema, for ...

STUFF
In 1976, Futureworld premiered with the first used of 3D computer graphics for animated hands and faces. Watch how the hands move around from all angles, and see how the face comes together and looks so real:

1976, Futureworld - World's first 3D animation in a movie
Here's the trailer...

Now we get into the cool, more recognized films at the end of this decade; 3D animations were used in some of our favorite older films, such as Alien, Star Wars Episode IV: A New Hope, and Superman. Wire-frame models and graphics were used in many sequences of these movies, even the title sequence.

See how a visual 3D presentation is made by specifying each edge of the physical object where two mathematically continuous smooth surfaces meet. 
3D Modeling
3D Modeling
IJW081000·3 YEARS AGO
Allow me to introduce you to the first CGI, and 3D CGI shaded, human character, Cindy (1981)...

Looker: Hi, I'm Cindy, the perfect female type, 18 to 25, I'm here to sell for you


It's fascinating how this character was created. The actress, Susan Dey, had her body scanned, and this digitization of her was transformed into a computer-generated simulation. 
All through the 80s, people found new ways to apply Computer Generated Imagery to film. New graphic techniques were created and used in many different ways. For example, fractal-generated landscape, facial animation, extensive 3D CGI, integrated CGI, motion blur effects, and squash and stretch motion were all used in parts of films and even throughout whole movies. Eventually an all-CGI-animated-short was made. This film is called The Adventures of Andre and Wally B. 

Pixar Short: The Adventures Of Andre And Wally B HD
Andre and Wally B. have come a long way from the 2D animations and sketches of hummingbirds!
The editing skills go even farther in the next couple of years. The CGI characters are now expressing emotions through face and body language. Realistic CGI animals, shadows and water effects are also included in films. Star Trek IV: The Voyage Home uses the Cyberware 3D Scanner and 3D morphing. The scanner produced the actors' heads as disembodied cyber-sculptures. This technology scans complex objects and produces a data set and texture map of the surfaces. 
CGI spread to other forms of entertainment, such as television series, game shows, and even music videos. This is the very first computer generated music video for the song, Money for Nothing by Dire Straits. The animators later founded Mainframe Entertainment.

Dire Straits-Money For Nothing.(1985)
Moving into 90s, details were tweaked and perfected even more in CGI. Matte paintings were digitally manipulated, and photorealistic fire, water, fur, and creatures were introduced. Live actors can now interact with CGI characters, and "digital puppetry" is used to create a character in a film. 
Creatures: Dinosaurs of Jurassic Park

STIKKYMEDIA
CGI? Pah! Watch how engineers built Jurassic Park's 40-foot, 9,000 ...
Apr 7, 2013 ... The special effects team that built Jurassic Park's star turn, the mammoth ... creature from scratch rather than us...

WWW.TECHRADAR.COM
Thumbnail for The Jurassic Park Period: How CGI Dinosaurs Transformed Film ...
The Jurassic Park Period: How CGI Dinosaurs Transformed Film ...
Apr 4, 2013 ... When Jurassic Park was released in 1993, CGI was still largely ... started to create entire cities, armies of creatures...

ALEXANDER HULS
Thumbnail for 10 Most Enduring CGI Characters Of All Time - WhatCulture!
10 Most Enduring CGI Characters Of All Time - WhatCulture!
Dec 7, 2012 ... 1993: Jurassic Park included the first photo-realistic CGI characters/creatures in film. 1995: Toy Story is the first f...

NAFISSA JEETOO
Animals: Crowds of 3D wildebeests of Lion King

The Lion King - Stampede scene (instrumental)
Fur: Cavemen of Flintstones
Thumbnail for Visual and Special Effects Film Milestones - Greatest Films
Visual and Special Effects Film Milestones - Greatest Films
The extensive CGI effects were in the scene of Madeline Ashton's (Meryl .... fur rendering - on saber-tooth tiger "Kitty"...


In 1995, the first CGI feature-length animation, Toy Story was released. 
MccordqisMariel
Marielle Mccord
@MccordqisMariel
1995 – Toy Story is released as the first feature-length film created completely using computer-generated imagery.
3 YEARS AGO
emavargasjbr
Ema Vargas
@emavargasjbr
1995 – Toy Story is released as the first feature-length film created completely using computer-generated imagery.
3 YEARS AGO
HartfordkdsKare
Kareen Hartford
@HartfordkdsKare
1995 – Toy Story is released as the first feature-length film created completely using computer-generated imagery.
3 YEARS AGO
The following videos show some behind the scenes creations and character designs for Toy Story. The first video shows how the characters evolved from a simple sketch on paper to the complex computer generated characters they are recognized as today. The second video explains the use of CGI as a cinematic tool in Toy Story, and how the technologies were applied in comparison to other movies of this time. 

"Designing Toy Story" Featurette "SUBTITLES INCLUDED"
TOYSTORYFAN72·6 YEARS AGO

Toy Story and the Evolution of CGI
EMORYUNIVERSITY·6 YEARS AGO
In attempt to get the audience to feel more involved in the movies while watching them, animated movies were now able to be viewed through 3D glasses. Marvin the Martian in 3D was the first movie to use 3D glasses. 
Audience with 3D glasses
Audience with 3D glasses
SASA HUZJAK·3 YEARS AGO

Marvin The Martian In The 3rd Dimension (1997-HQ).mp4
At the end of this decade (1999) The Matrix uses CG interpolation in Bullet time effects. Most people can easily relate this movie to the slow motion action scenes with bullets flying everywhere and all the guys in cool suits just lean and dodge away from their visible paths. Here we go...

The Matrix - Bullet time + Helipad Fight Scene Super High Quality
ACTIONJAWA·6 YEARS AGO
In 2000, films and television shows (Jimmy Neutron) are beginning to use performance capture and off-the-shelf hardware and software. AI, artificial intelligence, is now being used as digital actors in movies like The Lord of the Rings. CGI has advanced significantly over the years and is now even used for every aspect of some films. For example, Sky Captain and the World of Tomorrow used all CGI live actors and backgrounds. 
Director James Cameron and his team developed the first Virtual Art Department (VAD) and complete Virtual Production pipeline to create the film, Avatar in real-time. Avatar was the first full length movie made using performance-capture to create photorealistic 3D characters. It is also the first to feature a fully CG 3D photorealistic world. Isn't that amazing? We have gone from putting 2D drawings in the computer as 3D shapes to creating an entire computer generated world!

Avatar Pushes Limits of Visual Effects
WIRED·6 YEARS AGO
Thumbnail for How Avatar Happened: Lightcycles And Giant Lizards On The Path ...
How Avatar Happened: Lightcycles And Giant Lizards On The Path ...
Dec 15, 2009 ... Avatar pushes computer graphics to the very edge of what's possible, ... First Feature Film To Use Only Computer-G...

CINEMABLEND
karinatshaa
@karinatshaa
Really loved how george lucas make star wars with Motion Control photography or James cameron's avatar with computer generated imagery 3D
3 YEARS AGO
avatar_movie_poster_final_01
avatar_movie_poster_final_01
NASCARDUDE01350·3 YEARS AGO
CGI is used in almost every film that is released today. The earlier techniques have lived through the decades and continue to be used along with new techniques also being applied to films. The CGI feature-length movie, Toy Story 3, grossed over $1,000,000,000. Coronation Street Live (2010) used CGI in a live broadcast. The Hobbit: An Unexpected Journey was filmed at High Frame Rate (HFR). The industry standard projection frame rate is 24 frames per second, so HFR uses an even higher frame rate for filming and projecting; The Hobbit used double (48) frames per second. Criticisms of HFR say that the "cinematic look" is lost with this format and that it looks like video games. 

EXCLUSIVE: HOBBIT'S EFFECTS MAGIC
WATCHTHEDAILY·3 YEARS AGO

THE HOBBIT AN UNEXPECTED JOURNEY CGI CHARACTERS
TOLKIENTV·3 YEARS AGO
Computer Generated Imagery is the dominant form of special effects. The technology has progressed so far that the virtual stunt doubles can't even be distinguished from the actual actors. CGI is more efficient and cheaper than any other form of special effects, such as physical methods and models. The technology allows the creation and modification of images that other forms can't reach. The field of 3D computer graphics has already allowed us to create a virtual world, so it is certainly able to have an even more opportunistic future. Options are limitless with Computer Generated Imagery. 
.I 100
.T
document.100
.W
﻿Recently, a university undergraduate asked me on Twitter for advice on becoming a graphics programmer within the games industry. I wrote a fairly detailed email response and thought the information was good enough to make an article for AltDevBlogADay. This is all my personal opinion of course.

If you're at university, you should research whether there's a programme to do a summer or year long internship at a games studio. There was nothing like that when I was at the University of Liverpool '97-'00 (or I wasn't aware of it), but I've seen people come through that kind of programme with much greater practical game development knowledge and it goes a long way towards persuading an employer to take you on. EA, Lionhead and other large companies tend to run this sort of programme so look on their job pages too. Beware that sometimes companies don't respond to intern applications for various reasons (team is deep in crunch, budget spent elsewhere, etc) and places are extremely limited.

Your best bet is to make a graphics demo, either on your own or with a small group of people. You learn more by doing than by just reading. Pick a modern graphics technique that interests you and implement it. Even better, do more than one. This is also great training for motivating yourself to get a project finished which is often the hardest part of games development, for all disciplines. Make sure you're prepared to talk in detail about the choices you made, performance (in milliseconds, not frames per second!), quality, alternatives and trade offs in a job interview.

When I was in university I did a straight computer science course – there were barely any games courses available back then, but I still think that employers still value computer science graduates above games graduates as there's a perception that you learn a greater range of software engineering skills. This could be a misconception though, as games courses are a lot better than they used to be, but you may have to fight your corner in an interview and prove you know your stuff (and not just the curriculum you were taught).

Computer science courses also tend to be quite maths heavy (I would hope games courses are similar), which is vital for graphics programming. Make sure you understand homogeneous coordinates, matrix maths, dot products, cross products, quaternions, normal vectors, tangent bases, etc and how these things (and countless others) are useful for transforming and lighting geometry. Learn big O notation for algorithmic execution time, understand colour spaces, gamma correction, what high dynamic range means and so on. Learn some basic lighting models - Lambert, Phong, Blinn, etc.
.I 101
.T
document.101
.W
﻿Objectives: (1) To investigate the efficacy of a computer-generated three-dimensional laryngeal model for laryngeal anatomy teaching; (2) to explore the relationship between students' spatial ability and acquisition of anatomical knowledge; and (3) to assess participants' opinion of the computerised model.
Subjects and methods: Forty junior doctors were randomised to undertake laryngeal anatomy study supplemented by either a three-dimensional computer model or two-dimensional images. Outcome measurements comprised a laryngeal anatomy test, the modified Vandenberg and Kuse mental rotation test, and an opinion survey.
Results: Mean scores ± standard deviations for the anatomy test were 15.7 ± 2.0 for the ‘three dimensions’ group and 15.5 ± 2.3 for the ‘standard’ group (p = 0.7222). Pearson's correlation between the rotation test scores and the scores for the spatial ability questions in the anatomy test was 0.4791 (p = 0.086, n = 29). Opinion survey answers revealed significant differences in respondents' perceptions of the clarity and ‘user friendliness’ of, and their preferences for, the three-dimensional model as regards anatomical study.
Conclusion: The three-dimensional computer model was equivalent to standard two-dimensional images, for the purpose of laryngeal anatomy teaching. There was no association between students' spatial ability and functional anatomy learning. However, students preferred to use the three-dimensional model
.I 102
.T
document.102
.W
﻿Even though the human eye is one of the central features of individual appearance, its shape has so far been mostly approximated in our community with gross simplifications. In this paper we demonstrate that there is a lot of individuality to every eye, a fact that common practices for 3D eye generation do not consider. To faithfully reproduce all the intricacies of the human eye we propose a novel capture system that is capable of accurately reconstructing all the visible parts of the eye: the white sclera, the transparent cornea and the non-rigidly deforming colored iris. These components exhibit very different appearance properties and thus we propose a hybrid reconstruction method that addresses them individually, resulting in a complete model of both spatio-temporal shape and texture at an unprecedented level of detail, enabling the creation of more believable digital humans. Finally, we believe that the findings of this paper will alter our community’s current assumptions regarding human eyes, and our work has the potential to significantly impact the way that eyes will be modelled in the future. 
Introduction Creating photo-realistic digital humans is a long-standing grand challenge in computer graphics. One of the cornerstones of producing digital doubles is capturing an actor’s face. Over the past decade this area has been a topic of intense research, and many different approaches have been proposed [Ma et al. 2007; Alexander et al. 2010; Bradley et al. 2010; Beeler et al. 2010; Ghosh et al. 2011; Beeler et al. 2011; Graham et al. 2013; Garrido et al. 2013], most of which focus on reconstructing the skin surface and its appearance in increasing levels of detail. Only recently have researchers
.I 103
.T
document.103
.W
﻿The eyes are the window to the soul -- unless that eye belongs to a CGI animated character.
Until now, that is. The scientists over at Disney Research Zurich are trying to make things a little easier for animators who want to create photorealistic eyes. By using "multiple cameras and varied lighting," they've developed a technique that captures not only the shape, texture, refraction, and coloring of the white sclera, cornea, iris, and pupil, but also the change of the pupil when it dilates and contracts.


Computer animation has come a long way since the revelatory experience that was Toy Story back in '95, but creating anything photorealistic is still an incredible challenge. The problem is variation -- no two eyes, hands, gaits, smiles are exactly alike, because humans are precious snowflakes, I guess -- but attempting to create individual features for every single character that shows up on screen will not only require a lot of time and hard work, but lots and lots of money.

Not only that, but the scientists at Disney Researched realized that part of the reason why it's so difficult for animators to create realistic eyes is because they're often designed 1.) en masse generically, and 2.) without the qualities of human eyes that make them unique, like asymmetry, microscopic surface details, and imperfections.


This is what Pascal Bérard, a Ph.D. student in computer graphics at Disney Research Zurich and ETH Zurich, says about why the team's research is so important to animation:

Creating a photo-realistic digital human is one of the grand challenges of computer graphics, but despite intense research on capturing actors’ faces, especially for reconstruction of the skin surface and features such as hair, little attention to date has been given to the eye, particularly its shape.Generically modeled eyes may be sufficient for background characters, but it now takes significant effort to manually create realistic eyes for heroes and other leading characters. Our reconstruction technique can greatly reduce the time spent and help increase the realism of the eye.

So, how is all of this done? Essentially, the subject lies under the capture setup, which consists of six Canon 650D cameras fitted with 100mm macro lenses, a "modified flash," and 9 RGB LED lights. A series of photos are then taken of the subject's eye in various poses and pupil dilations. The whole data acquisition process takes about 20 minutes. However, there is a lot more that goes into the reconstruction process, so if you're interested, check out Disney Research's abstract.

There are a few exciting possibilities if this process of reconstructing human eyes is used for animation in the future. Not only will we start seeing some truly lifelike characters in animated movies, TV shows, and gaming (which can add new depth to the performances of talented voice actors), but Disney Research also mentions how it'll make creating digital doubles of actors a whole lot easier, too.

Maybe one day we won't even need human actors. Maybe one day -- we won't even need humans. (V folds hands into the Roger Smith finger pyramid of evil contemplation.) 
.I 104
.T
document.104
.W
﻿   
MARK WILSON 06.23.15 12:00 PM
Even the best CGI humans look dead. And while there can be a lot of reasons for that—the helmet-like hair, the glass eyes, the lack of realistic expressions—one of the biggest culprits is the skin. In the worst instances, computer skin has the flat, wrinkle-less glow of a Olay model, and in the best, the skin looks to have been grafted on a model from a corpse.


But a new technique developed by researchers at USC makes artificial skin look remarkably real. Their method? Scan a real human face down to the 10 micron magnification level—close enough to get tiny wrinkles and pores—and then render a special texture map that considers how those tiny fissures and crags squeeze together when you squint, or stretch wide when you smile. Simulated light hits these maps and, as you can see here, it just looks right. Even though I can still tell it’s computer generated (possibly because I already know?), it doesn’t look odd or repulsive in that uncanny valley sort of way.


The implications range from Hollywood blockbusters, to Facebook's virtual reality worlds, to Microsoft's virtual assistants, as the researchers have shown the technique can be applied in real time using a graphics card, or processed using tried-and-true dedicated rendering techniques favored by the film and tv industries. Obviously, the dedicated renders will look more realistic, given that the computer is given more or less unlimited time to make things look pretty, but the fact that this was coded from the start with real time rendering in mind gives it a larger, and more immediate potential impact on the humanoid graphics we see everywhere.

But just do me one favor, USC. Put some sort of limiter on this technology, so that when I raise that sniper rifle to my face in Call of Duty, the soldier looking back at me doesn’t look too much like a real person. I’m not ready to be a full-fledged soldier just yet.
.I 105
.T
document.105
.W
﻿Photo-realism is one of the ultimate goals for many CG artists, and it's also one of the most difficult to achieve. Even if you're relatively new to 3D computer graphics however, today's tools and workflow techniques make photo-realism very obtainable. Here are eight techniques to help you get there:
1.  Bevel, Bevel, Bevel

Forgetting to bevel or chamfer edges is one of the most common errors committed by beginning 3D artists. There are almost no razor sharp edges in nature, and even most man-made objects have a slight roundness where two opposing surfaces meet. Beveling helps bring out detail, and really sells the realism of your model by allowing edges to properly catch highlights from your lighting solution.

Using the bevel (or chamfer tool in 3ds Max) is one of the first things you should learn as a modeler. If you're new enough to 3D that you're unsure how to create a beveled edge, chances are you could truly benefit from a good introductory tutorial, or even a training subscription.
2.  Learn to Use Linear Workflow

Even though linear workflow has been around for years, it's still a confusing and complicated idea for beginners. I'm won't try to completely explain the theory here (there's just too much to say), but I do want to make sure you're at least aware that these techniques exist.

The need for linear workflow essentially comes down to the fact that your monitor displays images in a different color space (sRGB) than what is output by your render engine (linear). In order to combat this, artists must take the necessary steps to apply gamma correction to a render.

But linear workflow actually goes pretty far beyond simple gamma corrections—it's all about eschewing old techniques and workarounds (most of which are based on outdated math), and moving toward true physically based lighting solutions.

There's a lot more to say on linear workflow, and thankfully it's been discussed exhaustively over the past few years. Here's a link that I found useful when learning the theory behind the process—he links out to quite a few sources, so there's plenty of reading to be done. The second link is a Digital Tutors course that deals specifically with linear workflow in Maya 2012.
.I 106
.T
document.106
.W
﻿Recreating eyes in a CG environment, whether it’s for a human, animal or even some type of mythical creature can be a difficult task. There are some very important principles to keep in mind to ensure the eyes on your character are as believable as possible. This article will cover some key techniques for modeling and texturing realistic eyes that can be applied in any 3D application you’re using.

When it comes to the eyes of your character or creature it’s something that really can’t be overlooked, but often times it is. Sure, there are times when going for three basic colors to create the eye will work, and sometimes this is all a cartoony style character needs.

But more often than not, your character needs more detail in the eyes. So much emotion and personality can come just from the eye, that’s why it’s important that the eyes on your character are realistic.

Creating believable eyes is vital for capturing and maintaining the audience’s attention. Eyes that look unnatural can be a dead giveaway to a CG character, which you almost never want.

Find the Right Reference
As with just about every other task in a 3D production you’ll want to find great reference, and when it comes to creating realistic eyes there is no exception.

Before you begin creating the eyes you should search for some reference images online or even just snap some pictures of your own eyes. This is a great way to really study the eye and see all the small details and variety of colors that actually appear on someone’s eye.

Another very important detail you should get out of studying the right reference is to understand the anatomy of an eye. The key features you want to keep in mind are the cornea, the iris, the pupil and the sclera.

Eye Anatomy

The cornea of the eye is actually the transparent area of the eye that covers the iris and the pupil. The cornea is actually what helps give the eye its refractive nature.

Cornea

The iris of the eye is the area of the eye that gives it its unique color. The iris has very intricate details that require the most attention when creating the textures. On a technical level the iris is what controls the diameter of the pupil, but more often than not it just needs to be remembered as the “colored” part of the eye.

Iris
The pupil is the hole located in the center of the eye which allows light to enter in. Of course, you as an artist just needs to remember that the pupil is the black area in the center of the eye. One very important thing you need to keep in mind is that not all pupils are shaped circular. For instance, a cat’s pupil is typically a vertical split in the eye.

Pupil

The white area of the eye is referred to as the sclera, which acts as the protective layer of the eye. One thing you need to remember is that there are usually visible blood vessels that appear on the sclera, and if someone has an itchy eye and rubs it or if the person is tired it can increase the blood shot appearance.
.I 107
.T
document.107
.W
﻿A team led by Disney Research, Zürich has developed a method to more efficiently render animated scenes that involve fog, smoke or other substances that affect the travel of light, significantly reducing the time necessary to produce high-quality images or animations without grain or noise.
The method, called joint importance sampling, helps identify potential paths that light can take through a foggy or underwater scene that are most likely to contribute to what the camera – and the viewer – ultimately sees. In this way, less time is wasted computing paths that aren't necessary to the final look of an animated sequence.
Wojciech Jarosz, a research scientist at Disney Research, Zürich, said the computation time needed to produce noise-free images when rendering a complex scene can take minutes, hours or even days. The new algorithms his team created can reduce that time dramatically, by a factor of 10, 100, or even up to 1,000 in their experiments.
"Faster renderings allow our artists to focus on the creative process instead of waiting on the computer to finish," Jarosz said. "This leaves more time for them to create beautiful imagery that helps create an engaging story."
The researchers, including collaborators from Saarland University, Aarhus University, Université de Montréal and Charles University, Prague, will present their findings at the ACM SIGGRAPH Asia 2013 conference, November 19-22, in Hong Kong.
Light rays are deflected or scattered not only when they bounce off a solid object, but also as they pass through aerosols and liquids. The effect of clear air is negligible for rendering algorithms used to produce animated films, but realistically producing scenes including fog, smoke, smog, rain, underwater scenes, or even a glass of milk requires computational methods that account for these "participating media."
So-called Monte Carlo algorithms are increasingly being used to render such phenomena in animated films and special effects. These methods operate by analyzing a random sampling of possible paths that light might take through a scene and then averaging the results to create the overall effect. But Jarosz explained that not all paths are created equal. Some paths end up being blocked by an object or surface in the scene; in other cases, a light source may simply be too far from the camera to have much chance of being seen. Calculating those paths can be a waste of computing time or, worse, averaging them may introduce error, or noise, that creates unwanted effects in the animation.
Computer graphics researchers have tried various "importance sampling" techniques to increase the probability that the random light paths calculated will ultimately contribute to the final scene and keep noise to a minimum. Some techniques trace the light from its source to the camera; others from the camera back to the source. Some are bidirectional – tracing the light from both the camera and the source before connecting them together. Unfortunately, even such sophisticated bidirectional techniques compute the light and camera portions of the paths independently, without knowledge of each other, before connecting them together, so they are unlikely to construct full light paths that ultimately have a strong contribution to the final image.
By contrast, the joint importance sampling method developed by the Disney Research team chooses the locations along the random paths with mutual knowledge of the camera and light source locations. This approach allows their method to create high-contribution paths more readily, increasing the efficiency of the rendering process.
The researchers found that their algorithms significantly reduced noise and improved rendering performance. "There's always going to be noise, but with our method, we can reduce the noise much more quickly, which can translate into savings of time, computer processing and ultimately money," Jarosz said.


Read more at: http://phys.org/news/2013-11-algorithms-animations-featuring-fog-underwater.html#jCp
.I 108
.T
document.108
.W
﻿he history of computer-generated imagery goes hand in hand with the history of the computer itself. Especially the arrival of the third generation of digital computers in the late 1960s helped pave the way for what later became known as CGI or special effects.



For the origins of computer-generated imagery (CGI) we need to go back to the year 1968. In this year a group of Russian mathematicians and physicists, lead by N. Konstantinov, developed a groundbreaking mathematical model that allowed them to move a cat across a screen.

The scientists turned the mathematical model into a program for a special mainframe computer with the name BESM-4. The BESM-4 computer was able to print hundreds of frames, which when processed could be converted into usable film material.



In the 1970s CGI technology really gained a foothold within the entertainment community. Just a few years after moving a cat across a screen, 2D animator Peter Foldes created the first CGI animated short film, drawn on a data tablet. Foldes also used the world’s first key frame animation software, released in the same year as the short film by Nestor Burtnyk and Marceli Wein.

Westworld CGI effect

Several months later, in 1971, the first CGI was used in a national television program. While cinema visitors in 1973 were able to watch the first 2D animated effect, namely the point of view shot in Westworld, conceived by Yul Brynner.



The first 3D computer-generated imagery was created in the film Futureworld, in 1976. In the specific scene the hand and face of the actor was enhanced with the use of CGI. Futureworld made use of so called 2D digital compositing, in order to materialize characters over the background.

Star Wars: A New Hope (1977) poster

Director George Lucas saw the potential of CGI as well, but in stead of taking a digital approach he choose for the implementation of a mix between analog and digital technologies. His Star Wars franchise became a major box office hit and an inspiration for many CGI effects that followed.

A large number of movies using CGI effects followed soon after Star Wars: A New Hope, showing the potential and mind boggling possibilities of what computer-generated imagery could achieve.

Superman: The Movie (1978) conceived the first computer-generated title sequence, while the movies Alien (1979) and Black Hole (1979) pushed the boundaries of CGI further once more by conceiving 3D wireframe rasters, resulting in more detailed CGI effects.



As the computer developed and became more integrated into society, CGI did as well. The 1980s saw an explosion of CGI achievements. The most important milestones included the first CGI human character (with the first use of 3D shaded CGI), the invention of the Genesis effect for creating alien-like landscapes (such as the ones used in Star Trek 2: The Wrath of Khan in 1982), TRON (1982) that depicted 15 minutes of fully rendered CGI footage (including the famous light cycle sequence), the first water 3D CGI effect in the film hit “The Abyss”  and the first digital composite in Indiana Jones: The Last Crusade (1989).

The Matrix

As we entered the age of the internet and the personal computer became mainstream, CGI effects became more photo realistic. Big innovations came with the development of movies like Terminator 2: Judgement Day, which figured 3D CGI motion pictures.

Two years later, in 1993, Steven Spielberg raised the bar by creating the first realistic computer-generated creatures in Jurassic Parc.

In 1995 Toy Story got the title of having the first fully CGI animated movie and the 1990s CGI era ended with the The Matrix (1999), which was the first movie to use the so called bullet time effect.

As the movie industry matured the game industry made its first steps in the mainstream segment as well. Fifth generation gaming consoles introduced fully 3D playable game environments to the masses. The release of the PlayStation (1994) and the  Nintendo 64 (1996) games got their first fully 3D supported gaming platforms.

Games such as Super Mario 64, Doom, Final Fantasy and Crash Bandicoot set the standard for many computer-generated games that followed.

Gollum CGI

As we entered the 21st century the possibilities for CGI became almost endless, with computer-generated imagery becoming more and more a part of authentic film footage. Movies like The Lord of the Rings: The Fellowship of the Ring (2001), The Matrix: Reloaded (2003) and The Polar Express (2004) are good examples of that development.

Lord of the Rings was the first movie to make use of artificial intelligence for its digital characters, while it also introduced the first photo realistic motion captured character with the creation of Gollum.

The Matrix: Reloaded thereby was the first movie to use a technique called “Universal Capture”, which allowed the movie to capture more frames in an image than ever before.

Furthermore, in 2004 the animated film “The Polar Express” (2004) pushed the boundaries of CGI by implementing motion capture and CGI on all of its actors.

Avatar CGI rendering

Many breakthroughs followed as we entered the realm of photo realistic CGI effects. In 2009 the creators of Avatar pushed CGI to the highest level yet, creating a movie that was entirely conceived with a technique called performance capture, transforming multiple actors into photo realistic 3D characters.

Crysis nanosuit CGI

Aside the movie industry, the gaming industry is currently implementing a multitude of computer-generated imagery techniques as well. Game series like Grand Theft Auto and Crysis have set the boundaries of CGI in games over the last several years, with an interesting detail being that games and movies are starting to show more and more similarities.

Bioware and Lucas Arts their story driven game called Star Wars: The Old Republic (scheduled for a 2011 release) is a good example of this merge between movies, animations and games.
.I 109
.T
document.109
.W
﻿Computer Graphics (CG) was first created as a 
visualization tool for scientists and engineers in government 
and corporate research centers such as Bell Labs and Boeing 
in the 1950s. Later the tools would be developed at 
Universities in the 60s and 70s at places such as Ohio State 
University, MIT, University of Utah, Cornell, North Carolina 
and the New York Institute of Technology.	
The early breakthroughs that took place in academic 
centers continued at research centers such as the famous 
Xerox PARC in the 1970¹s. These efforts broke first into 
broadcast video graphics and then major motion pictures in 
the late 70¹s and early 1980¹s. Computer graphic research 
continues today around the world, now joined by the research 
and development departments of entertainment and production 
companies. Companies such as George Lucas¹s Industrial 
Light and Magic are constantly redefining the cutting edge 
of computer graphic technology in order to present the world 
with a new synthetic digital reality.


1940s

	The very first ³computer assisted² graphics began in 
many different unrelated fields around the world. There is a 
very blurred line that is crossed somewhere between 
mechanical and analog computer assisted graphics, and the 
first directly digital computer generated graphics that would 
associate with today as being true ³CG².

The very first radiosity image. 
While at MIT in the 1940s, Professors Parry Moon and 
Domina Eberle Spencer were using their field of applied 
mathematics to calculate highly accurate global lighting 
models which they called ³interflection reflection². The 
illumination algorithms were based on those by H. H. Higbie, 
published in his 1934 book, Lighting Calculations.
Lacking any display or output mechanism, the image 
itself was created by painstakingly selecting Munsel paper 
samples that matched the output data of their mathematical 
model. The paper was cut out and ironed together by hand to 
create the image shown here in print for the first time in 
over 50 years.




	[IMAGE OF THE RADIOSITY PIC]

(The original image is still hanging in the office of 
Dr. Domina Spencer at the University of Connecticut.)

The images were first presented at the 1946 National 
Technical Conference of the Illuminating Engineering Society 
of North America, and published two years later (in color) in 
the book: Lighting Design by Moon, P., and D. E. Spencer. 
1948. (Addison-Wesley. Cambridge, MA) The book was used for 
many years to teach lighting theory at MIT in the 
architecture curriculum there. Dr. Spencer went on to teach 
at Tufts, Brown, Rhode Island School of Design, and the 
University of Connecticut where she remains active today.
.I 11
.T
document.11
.W
A Computer-Generated Imagery (CGI) History
BESM-4 mainframe computer (1968)
May 11, 2011   More, Movies   Share on: Twitter, Facebook, Google+
The history of computer-generated imagery goes hand in hand with the history of the computer itself. Especially the arrival of the third generation of digital computers in the late 1960s helped pave the way for what later became known as CGI or special effects.



For the origins of computer-generated imagery (CGI) we need to go back to the year 1968. In this year a group of Russian mathematicians and physicists, lead by N. Konstantinov, developed a groundbreaking mathematical model that allowed them to move a cat across a screen.

The scientists turned the mathematical model into a program for a special mainframe computer with the name BESM-4. The BESM-4 computer was able to print hundreds of frames, which when processed could be converted into usable film material.



In the 1970s CGI technology really gained a foothold within the entertainment community. Just a few years after moving a cat across a screen, 2D animator Peter Foldes created the first CGI animated short film, drawn on a data tablet. Foldes also used the world’s first key frame animation software, released in the same year as the short film by Nestor Burtnyk and Marceli Wein.

Westworld CGI effect

Several months later, in 1971, the first CGI was used in a national television program. While cinema visitors in 1973 were able to watch the first 2D animated effect, namely the point of view shot in Westworld, conceived by Yul Brynner.



The first 3D computer-generated imagery was created in the film Futureworld, in 1976. In the specific scene the hand and face of the actor was enhanced with the use of CGI. Futureworld made use of so called 2D digital compositing, in order to materialize characters over the background.

Star Wars: A New Hope (1977) poster

Director George Lucas saw the potential of CGI as well, but in stead of taking a digital approach he choose for the implementation of a mix between analog and digital technologies. His Star Wars franchise became a major box office hit and an inspiration for many CGI effects that followed.

A large number of movies using CGI effects followed soon after Star Wars: A New Hope, showing the potential and mind boggling possibilities of what computer-generated imagery could achieve.

Superman: The Movie (1978) conceived the first computer-generated title sequence, while the movies Alien (1979) and Black Hole (1979) pushed the boundaries of CGI further once more by conceiving 3D wireframe rasters, resulting in more detailed CGI effects.



As the computer developed and became more integrated into society, CGI did as well. The 1980s saw an explosion of CGI achievements. The most important milestones included the first CGI human character (with the first use of 3D shaded CGI), the invention of the Genesis effect for creating alien-like landscapes (such as the ones used in Star Trek 2: The Wrath of Khan in 1982), TRON (1982) that depicted 15 minutes of fully rendered CGI footage (including the famous light cycle sequence), the first water 3D CGI effect in the film hit “The Abyss”  and the first digital composite in Indiana Jones: The Last Crusade (1989).

The Matrix

As we entered the age of the internet and the personal computer became mainstream, CGI effects became more photo realistic. Big innovations came with the development of movies like Terminator 2: Judgement Day, which figured 3D CGI motion pictures.

Two years later, in 1993, Steven Spielberg raised the bar by creating the first realistic computer-generated creatures in Jurassic Parc.

In 1995 Toy Story got the title of having the first fully CGI animated movie and the 1990s CGI era ended with the The Matrix (1999), which was the first movie to use the so called bullet time effect.

As the movie industry matured the game industry made its first steps in the mainstream segment as well. Fifth generation gaming consoles introduced fully 3D playable game environments to the masses. The release of the PlayStation (1994) and the  Nintendo 64 (1996) games got their first fully 3D supported gaming platforms.

Games such as Super Mario 64, Doom, Final Fantasy and Crash Bandicoot set the standard for many computer-generated games that followed.

Gollum CGI

As we entered the 21st century the possibilities for CGI became almost endless, with computer-generated imagery becoming more and more a part of authentic film footage. Movies like The Lord of the Rings: The Fellowship of the Ring (2001), The Matrix: Reloaded (2003) and The Polar Express (2004) are good examples of that development.

Lord of the Rings was the first movie to make use of artificial intelligence for its digital characters, while it also introduced the first photo realistic motion captured character with the creation of Gollum.

The Matrix: Reloaded thereby was the first movie to use a technique called “Universal Capture”, which allowed the movie to capture more frames in an image than ever before.

Furthermore, in 2004 the animated film “The Polar Express” (2004) pushed the boundaries of CGI by implementing motion capture and CGI on all of its actors.

Avatar CGI rendering

Many breakthroughs followed as we entered the realm of photo realistic CGI effects. In 2009 the creators of Avatar pushed CGI to the highest level yet, creating a movie that was entirely conceived with a technique called performance capture, transforming multiple actors into photo realistic 3D characters.

Crysis nanosuit CGI

Aside the movie industry, the gaming industry is currently implementing a multitude of computer-generated imagery techniques as well. Game series like Grand Theft Auto and Crysis have set the boundaries of CGI in games over the last several years, with an interesting detail being that games and movies are starting to show more and more similarities.

Bioware and Lucas Arts their story driven game called Star Wars: The Old Republic (scheduled for a 2011 release) is a good example of this merge between movies, animations and games.

As we move forward toward the future it is fairly certain that computer-generated imagery effects will reach new heights as well. Aside seeing what this will mean for blockbuster projects that implement the latest innovations, it will also be interesting to see what this will mean for smaller projects that will be able to gain access to more and more technologies as CGI becomes more mainstream and affordable.

.I 110
.T
document.110
.W
﻿"Toy Story 3," which has been raking in money at the box office, is the first film in the "Toy Story" franchise to be screened in 3-D . But it isn't the first "first" for its main characters, Woody and Buzz Lightyear.

The bickering buddies were part of another watershed moment in 1995, when Toy Story became the first feature-length computer-animated movie.

The entire movie was created with Computer Generated Imagery (CGI). This marked a huge departure from the longtime industry animation standard of animated films being made from hand-drawn pictures.

The of the "Toy Story" movie franchise not only launched Pixar as a creative powerhouse, but it also marked the arrival of an entirely new way of making animated movies.

CGI, which was first used as a visual effects tool in the 1973 live-action film "Westworld," has now become the dominant tool in animation. Because of the speed and limitless possibilities provided by modern-day computing power, computer animation is credited with revolutionizing live-action visual effects. And with animated movies, it has expanded the potential of the medium to the point that the impossible has became possible.

How CGI became the standard

Before CGI came along, animated films were hand-drawn masterworks. Walt Disney basically invented the animated movie genre, and with his legendary group of animators his Nine Old Men turned out classics such as "Snow White and the Seven Dwarfs, " "Lady and the Tramp" and "Pinocchio."

And when feature-film animation experienced its rebirth in 1989, it was thanks to "The Little Mermaid" and its hand-drawn, two-dimensional imagery. But then, "Toy Story" came along six years later and essentially put a stake through the heart of traditional animation. Now, 3-D computer-generated animation is standard issue. The summer of 2010 will have "Toy Story 3" and "Shrek Forever After" as examples.

There are still those who believe in the power and effectiveness of traditional, 2-D animation. Perhaps ironically, the loudest voice belongs to John Lasseter, the Chief Creative Officer at Pixar and Disney Animated Studios.

An avowed fan of old-school animation, he spearheaded the 2009 release of "The Princess and the Frog," a film that marked a return to the classic Disney style of animation. But while the film was a solid critical and commercial success, it didn't come close to reaching the level of acclaim and box-office appeal that Pixar's CGI-created "Up" enjoyed that year.

We can thank the "Toy Story" crew for setting the bar so high.
.I 111
.T
document.111
.W
﻿I would say one of the biggest improvement has come from computer technology and clever algorithms making pathtracing more feasible.

The older way of CGI was to shoot rays from the camera in the direction of the pixel, and bounce off all objects depending on their surface characteristics, and accumulate the colour. This led to nice images with detailed optical effects, like reflection and refraction, but still looked pretty fake, especially by today's standards. 

But path tracing bounces light all around the scene and given enough time, it converges on the rendering equation which is a proper representation of real light, not a hack as before. It allows for much more realistic images with things like true global illumination and true caustics.

Comparison between whitted-style raytracing (left) and pathtracing (right)

The image on the right seems a bit noisy, but that's how it works, it just takes more time to generate more samples, to get a better quality. Also, there are many clever algorithms that can speed it up.

Notice the bright caustic on the ground, the light reaching into shadowed areas to make them warmer and the green and red influence on other objects from light bleeding. It is far more realistic.

Here is an image that has been rendering longer, converging on the true rendering equation:

This allows for some very realistic CGI these days.
.I 112
.T
document.112
.W
﻿If keen observers of video game cinematics and CGI films think the computer graphics look great now, especially in how cloth material and hair are rendered, the next wave is going to be amazing.

The science behind how these surfaces are rendered have been restudied and restructured in such a way, where if there was a real world analogy: the way any type of thread is weaved on a loom in specific patterns is what the team of computer engineers from the Jacobs School of Engineering/UC San Diego looked at, but at a microscopic level. What they have discovered is a simpler method which matches this real world analogy and the ‘virtual threads’ are more cylindrical.

When writing software to deconstruct how the real world looks inside a computer, programmers are required to have an intimate mathematical understanding of how to make those visual images understood within the machine. For the technically inclined, that means writing a proper sequence of logical statements to describe how a ray of light reflects off a particular object molecule by molecule. How the computer responds is by instructing what’s inside its mechanisms to draw the right color, shape, transparency and density (to name a few) to a screen after all that complex math resolves what a computer eye sees of this virtual object.

But for the team who already know this science known as ray tracing theory, to find a new method to measure and render how light reflects off fabrics is going to revolutionize how any entertainment product utilizing computer graphics is going to look. When the next wave of display technologies include 4K, a ultra-high definition display format, this recent discovery will most likely take advantage of really making any CGI world look beyond photo-realistic. It will be unmistakable from the real thing!

realistic-simulated-cloth
(Image: Iman Sadeghi, et. al/Jacobs School of Engineering/UC San Diego)
Software like Maya or Cinema4D will have to be updated for those computer artists looking to recreate the world of James Cameron’s Avatar.

In a report by Gizmag, Oleg Bisker is a fellow researcher who believes that the new algorithms developed can simulate any kind of weaving pattern and thread types in a computer animated world. Even in still life, the simulations of real world cloth objects look far more realistic than ever before. Bisker is working with Henrik WannJensen, PhD advisor to Iman Sadeghi, software engineer who has done work in the past with ILM and Walt Disney Animation Studios.

Tangled

When the team consists of people who have done work within the movie-making industry in the past (Sadeghi worked on Lord of the Rings and Tangled), their work will certainly not go unnoticed. Gizmag also reported that their work has raised eyebrows at SIGGRAPH, a computer graphics conference. As for when it will appear in end products is simply a matter of time.

If Cameron is not aware of this technology yet, he will hear about it soon enough. He may invest into it as well if he truly wants to remain ahead of the game with creating visual wonders to wow audiences with. After all, that is what he does best.
.I 113
.T
document.113
.W
﻿Tony DeRose wanders between rows at New York's Museum of Mathematics. In a brightly-colored button-up T-shirt that may be Pixar standard issue, he doesn't look like the stereotype of a scientist. He greets throngs of squirrely, nerdy children and their handlers — parents and grandparents, math and science teachers — as well as their grown-up math nerd counterparts, who came alone or with their friends. One twentysomething has a credit for crowd animation on Cars 2; he's brought his mom. She wants to meet the pioneer whose work lets her son do what he does.

"It's wonderful to see such a diverse crowd," he says. "How many of you have seen a Pixar film?" he asks after taking the podium. The entire room's hands go up. "How many of you have seen three? Five?" He pauses. "How many of you have seen all of them?" Dozens of people raise their hands, maybe a quarter of the room. "Wow," he says. He smiles, to himself and the crowd. This gig is not one bit bad.

ASPIRING ANIMATORS AND GAME DESIGNERS, STUDY YOUR CALCULUS AND COMBINATORICS

The topic of DeRose's lecture is "Math in the Movies." This topic is his job: translating principles of arithmetic, geometry, and algebra into software that renders objects or powers physics engines. This process is much the same at Pixar as it is at other computer animation or video game studios, he explains; part of why he's here is to explain why aspiring animators and game designers need a solid base in mathematics. As Pixar's Senior Scientist, DeRose has more than a solid base: PhD in computer science, specialty in computational physics, a decade as a professor of computer science and engineering at the University of Washington. This is the first instance of the Math Encounters lecture series at MoMath's new campus in midtown Manhattan, but DeRose given a version of this talk many times before, continually updating it as Pixar's technology improves and fans want to hear about the latest films.

Brave_merida

Hair, cloth, fluids, and gaseous phenomena like clouds, smoke, and fire all have their own physics at Pixar. These basic engines are then augmented to try to produce specific outcomes. "Simulating water is easy," says DeRose. "What's hard is, how do you make water more directable?" For Brave, DeRose explains, Merida's voluminous, bright red, highly animated curls required building an entirely new physics engine. The studio's animators had to figure out how to make Merida's hair beautiful, expressive, and even more living than lifelike. DeRose and his team of scientists had to engineer a model that makes that animation computationally possible
.I 114
.T
document.114
.W
﻿Rendering is always an exercise in managing how much computer power you are willing to devote to simulating reality - that cost is expressed in both dollars and time.

Once considered a commodity item in the whole CG / VFX world - rendering is now a hot topic. CG supervisor Scott Metzger jokes that one can't talk about renderers without annoying someone. "Renderers are like religion (laughs). Rendering is a religion! Especially now in this era, which is really really exciting, there is so much going on and there are so many renderers, so much happening. To me it is the most exciting part of being in our industry right now."

As Dana Batali, Vice President of RenderMan products at Pixar commented to fxguide at an earlier Siggraph,  "Rendering drives the largest computational budget of getting the pixels to the screen." He pointed out at that time 'sims' (physical sims like cloth etc) were only about 5% of most film's computation budgets. Since rendering dominates render farms one cannot devote as much effort to perfect light simulations in a render as you can to a destruction simulation in just perhaps one shot.

Renderers are easy to write in the abstract, as perhaps a university project, but to work in production environments is extremely difficult. Arnold, by Solid Angle, is some 200,000 lines of highly optimized C++ code, and it is considered a very direct implementation without a lot of hacks or tricks. Production requirements in terms of rendertime and scene complexity are staggering. And the problem is not just contained to final render time, as Arnold founder Marcos Fajardo pointed out at Siggraph 2010 - final render CPU time might cost $0.10 per hour, but artist time is closer to $40 an hour, so interactivity is also vital.

This leads to the heart of rendering: picking the best approach that will get the results looking as good as possible, in the time you have, and more precisely picking which attributes of an image - be it complex shading, complex motion blur, sub-surface scattering or some other light effects should be your priority - which ones will play in your shot, and which attributes need to be more heavily compromised.

Rendering is an art of trying to cheat compromises.
.I 115
.T
document.115
.W
﻿One of the most challenging problems in computer graphics is to generate images that appear realistic;
that is, images that can fool a human observer when displayed on a screen. The quest for this "Holy
Grail" began in earnest in the early 70’s when memory prices dropped low enough to allow raster technologies
to be cost-effective over the then prevailing calligraphic displays. Calligraphic displays could only
drawalimited number of lines and even the most capable of these displays allowed for only a handful of
colours. Previously, research work concentrated on removing "hidden lines" from objects drawn on these
displays. The objects displayed were obviously not realistic but contained enough information for the task
at hand, such as computer aided design. Raster technology, by subdividing the screen into pixels, allowed
whole regions of the screen to be filled with colours, colours that had a wide variety of intensities and tints.
This new technology, capable of displaying realistic images, opened up research in this direction and it is
this research that we will outline.
This paper will survey most of the major issues that one must deal with when generating realistic
images†. We begin with an overview of the rendering process and a quick review of visible surface determination
algorithms. We then discuss, in more detail, shading, anti-aliasing, texture mapping, shadows,
optical effects and close with a discussion of modeling primitives.
.I 116
.T
document.116
.W
﻿A realistic camera model for computer graphics
Most recent rendering research has concentrated on two subproblems:
modeling the reflection of light from materials, and calculating
the direct and indirect illumination from light sources and other
surfaces. Another key component of a rendering system is the camera
model. Unfortunately, current camera models are not geometrically
or radiometrically correct and thus are not sufficient for synthesizing
images from physically-based rendering programs.
In this paper we describe a physically-based camera model for
computer graphics. More precisely, a physically-based camera
model accurately computes the irradiance on the film given the incoming
radiance from the scene. In our model a camera is described
as a lens system and film backplane. The lens system consists of a
sequence of simple lens elements, stops and apertures. The camera
simulation module computes the irradiance on the backplane from
the scene radiances using distributed ray tracing. This is accomplished
by a detailed simulation of the geometry of ray paths through
the lens system, and by sampling the lens system such that the radiometry
is computed accurately and efficiently. Because even the
most complicated lenses have a relatively small number of elements,
the simulation only increases the total rendering time slightly
.I 117
.T
document.117
.W
﻿Computer scientists have come up with a new simple, accurate way to simulate the appearance of fabric that could change the way artists and animators in the film and computer game industries go about the business of rendering computer-generated clothing and other materials.

 The method hinges upon the perpendicular arrangement of cylinders (Image: Iman Sadeghi, et. al/Jacobs School of ... Photographs of fabrics with their simulated counterparts below (Image: Iman Sadeghi, et. al/Jacobs School of Engineering/UC ... Photographs of fabrics with their simulated counterparts below (Image: Iman Sadeghi, et. al/Jacobs School of Engineering/UC ... The simulated weaving patterns of, left to right, linen plain, silk crepe de chine and polyester ...
"The model solves the long standing problem of rendering cloth," says Henrik Wann Jensen, PhD advisor to Iman Sadeghi who developed the method. "Cloth in movies and games often looks wrong, and this model is the first practical way of controlling the appearance of most types of cloth in a realistic way," he adds.

Jensen knows more than a little bit about computer graphics. In 2004 he was a co-recipient of an Oscar for technical achievement following his work on the subsurface scattering of light in translucent materials, now de rigueur for the rendering of realistic skin in film (Gollum in The Lord of the Rings trilogy, for example).

Sadeghi's method tackles the interaction between light and material by modeling the surface of the fabric more realistically. The method involves creating a mesh of perpendicular cylinders arranged similarly to the threads in the material being simulated.

 
The simulated weaving patterns of, left to right, linen plain, silk crepe de chine and polyester satin charmeuse (Image: Iman Sadeghi, et. al/Jacobs School of Engineering/UC San Diego)
The method is an adaptation of a similar process developed by Sadeghi used to render realistic hair, which has since been used in Disney's take on the Rapunzel fairytale, Tangled. The arrangement of cylinders is the crucial difference between the two.

The team discovered that the material's weave was essential when examining fabrics under a microscope. The team also photographed materials and measured light scattering from single threads of material.

Co-researcher Oleg Bisker thinks the technology could have other applications, include the visualization of new fabrics. "We can simulate any combination of weaving pattern and thread types," he says.

As a demonstration of the power of this process, the team simulated linen, crepe de chine and the complexing threading of a polyester charmeuse, which is shiny on one side but not the other.

The method was received with interest at this year's SIGGRAPH computer graphics conference, and the team fully expects the method to be used in many forthcoming productions.
.I 118
.T
document.118
.W
﻿We present Ed, he can blink, look around and show expression. He almost looks too perfect, and that's because he is. Ed is a computer-generated face that debuted in a video by Australian designer and digital artist Chris Jones, but the 'human' head is not what he seems.  

Using Lightware, Scuptris and Krita, Jones created a computer-generated human face, that includes oils and pores on his face and wrinkles around his soulful eyes.

The eyes of the 'human face' look around, and Ed comes to life in the video. Jones zooms out the camera to reveal that the computer-generated images are only that of a head and neck. A hand that is closed to comically resemble a puppet comes for the neck and hops off screen.

Jones uses the hypothesis of the uncanny valley, which says that we instantly recognize human features when they look and slightly move like human beings, an aesthetic that is used in robotics and 3D computer animation.

While there are shots in the video where one can tell Ed isn't human, overall his appearance and movement could be almost too real to even notice he is only a face. Jones did not scan a human face for this project, but rather created the computer-generated face from scratch.

Jones started working on the project in 2012, creating the first  humanoid computerized face.

How would Ed compare to the graphics of video games? Check out the video below.
.I 119
.T
document.119
.W
﻿Creating a realistic computer simulation of how light suffuses a room is crucial not just for animated movies like "Toy Story" or "Cars". Special computing methods should ensure this, but they require great effort. Computer scientists from Saarbrücken have now developed a novel approach that turned out to be so promising, that it was adopted by companies in record time—among others by Pixar, well-known in the movie industry for its computer animation, and now a subsidiary of the Walt Disney Company.
The realistic depiction of light transport in a room is important within the production of computer-generated movies. If it does not work, the three-dimensional impression is rapidly lost. Hence, the movie industry's digital light experts use special computing methods, requiring enormous computational power and therefore raising production costs.
Not only in the film industry, but also in the automobile industry, the companies invest to make lighting conditions for a computer generated image as realistic as possible. Already during the development process, entire computing centers are used to compute and display realistic pictures of the complex car models in real time. Only in this way, designers and engineers can evaluate the design and the product features in an early stage and optimize it during the planning phase. "They build hardly any real prototypes. Hence, the designers want to make sure that the car body on the screen looks exactly as the real vehicle will appear later," explains Philipp Slusallek, professor of computer graphics at Saarland University, Scientific Director at the German Center for Artificial Intelligence (DFKI) and Director of Research at the Intel Visual Computing Institute at Saarland University.
With current computing methods, it has not been possible to compute all illumination effects in an efficient way. The so-called Monte Carlo Path Tracing could depict very well the direct light incidence on surfaces and the indirect illumination by reflecting light from surfaces in a room. But it does not work well for illumination around transparent objects, like semi-transparent shadows from glass objects, or illumination by specular surfaces (so-called caustics). This, on the other hand, was the advantage of the so-called photon mapping. But this method again led to disappointing results for direct lighting of surfaces. But since these two approaches were mathematically incompatible (Monte Carlo integration versus density estimation), it was not possible to merge them, and therefore it was necessary to compute them separately from each other for the particular images. This raised the computation costs for computer-animated movies like "The Hobbit: An Unexpected Journey", where up to 48 pictures per second have to be computed—for a movie whose "normal" version is 169 minutes long.
In cooperation with Ilyan Georgiev, PhD student at the Graduate School for Computer Science in Saarbrücken, Jaroslav Krivanek from the Charles University in Prague and Thomas Davidovic from the Intel Visual Computing Institute at Saarland University, Slusallek developed a mathematical approach in 2012 that combines both methods with each other in a clever way. They reformulated photon mapping as a Monte Carlo process. Hence, they could integrate it directly into the Monte Carlo Path Tracing method. For every pixel of the image the new algorithm decides automatically, via so-called multiple importance sampling, which of both strategies is suited best to compute the illumination at that spot.
The researchers from Saarbrücken also supplied mathematical proof that the results of the new computing method comply with those of the two former methods. "Our new method vastly simplifies and speeds up the whole calculating process," says Slusallek.
The method "Vertex Connection and Merging'" abbreviated as VCM, was not only accepted at one of the most important conferences within the computer graphics research field ? SIGGRAPH ? in 2012, but was also very well received by industry. "We know of four different companies that partially integrated VCM in their commercial products only a few months after the scientific publication. The most recent example is the new version of the software Renderman developed by the company Pixar. For decades this has been the most important tool in the movie industry. We are very proud of this achievement," Slusallek says. The Californian (US) company Pixar, famous for movies like "Toy Story," "Up," "Finding Nemo," and "Monsters, Inc." is part of the Walt Disney Company. Pixar originally got its name from Apple founder Steve Jobs. Up to now, Pixar has received twelve Oscars for its movies.
Slusallek and his research group are presenting a new scientific paper at the Siggraph conference, which is being held in Vancouver this year. They are demonstrating that the new VCM method can be implemented on highly parallel graphics processing units very efficiently. As this research has been funded by the American semiconductor producer Intel, among others, the researchers will be presenting their results at Intel's Siggraph booth.


Read more at: http://phys.org/news/2014-08-realistic-graphics-technology-walt-disney.html#jCp
.I 12
.T
document.12
.W
A history of CGI in the movies
We thought that this would be a good time to look at the history, evolution and occasionally devolution of the art form.
Year: 1984
Significance: Pixar’s first-ever animation

This gleeful one-minute short about a giant-honked android and his buzzing nemesis was technically a Lucasfilm, but, for all intents and purposes, it was Pixar’s first animation. With it John Lasseter pushed yet more CG boundary. Working under the auspices of George Lucas’ Computer Graphics Project, his team pioneered animation’s first use of motion blur, a significant breakthrough, while taking a big step towards Pixar’s modern-day fluidity by abandoning geometric form for a much curvier palatte of shapes. “I was playing with the teardrop shape,” Lasseter remembers, “ and I just started envisioning this fat bumblebee with these gigantic water balloon-like feet hanging from him and big stainless-steel stinger.” Lasseter and his Pixar-ites would soon break away from Lucasfilm, but this was a vital piece in the Pixar puzzle that informed the goal it would come to hold dear: the perfect marriage of art and technology.

Year: 1989
Significance: Water effects

To create cinema’s first CG computer water effects, The Abyss’ worm-like subsea pseudopod, effects guru Phil Tippett pointed James Cameron towards George Lucas’ ILM. Work on the 75 second sequence was ultimately divvyed up between seven different FX houses, with ILM taking on the bulk of the work and designing a program that could simulate the watery beast-tube-thing with incredible realism. The whole process took more than six months – the set had to be photographed from every angle so the effects could be composited onto the live-action – which delayed the film’s release, but it was worth waiting for. Another Oscar winner.

Year: 1993*

**Significance: First physically textured CGI

*Empire voted Jurassic Park’s first glimpse of those ginormous, tree-munching Brachiosauri as its 27th most magical moment in cinema history. It was a breathtaking reveal: physically textured dinosaurs so realistic it felt like they might come pounding out of the screen. Again, Lucasfilm’s ILM division provided the Oscar-winning visual effects wizardry. The CGI was bleeding edge, but the studio also used a smorgasboard of physical effects on the movie: of 14 minutes of dinosaurs in Jurassic Park, only four minutes were entirely computer generated. Along with the CGI, animatronics and stop-motioned miniatures were used to create the thunderous Gallimimus stampede, and a computer-generated stunt double created for the first time (he was munched by the animatronic T-Rex). Perhaps the movie’s effects DNA – Lucas’ CGI mingling with stop-motion of the kind pioneered by Ray Harryhausen and the animatronics Stan Winston helped developed – explains why Jurassic Park remains magical to this day.

Year: 1995

Significance: First full-length CG film

The first ever full-length CG feature, Toy Story was a mighty undertaking undertaking with a team of animators less-than-mighty in number. 27, in fact. “If we’d known how small our budget and our crew was”, remembers writer Peter Docter, “we probably would have been scared out of our gourds. But we didn’t, so it just felt like we were having a good time.” Up to that point Pixar’s longest CGI animation had been Tin Toy, a full 80 minutes shorter than Buzz and Woody’s first outing. The challenges were compounded by a seriously inexperienced crew (half hadn’t even used computers before) and Disney’s budget constraints. It was enough to have Rex cowering in terror, but Pixar came through, again mingling super-detailed animation with emotional beats. Bill Reeves, Toy Story’s supervising technical director, looks back on the experience with pride: “To this day, it’s the hardest, most exhausting, and still most fun I’ve ever done at Pixar. We were essentially kick-starting an industry in terms of CG films.”

Year: 1997
Significance: First large-scale CG battle scenes

A box-office flop weighed down by its $100m+ budget, Paul Verhoeven’s sci-fi war movie was the first film to feature a large-scale CG military battle, with the VFX wizardry of Phil Tippett and Tippett Studios to the fore. Starship Troopers was also nominated for a Best Visual Effects Oscar, which it might just have won were it not for Titanic’s sailaway success that year. Over 300 artists and technicians were hired to digitally breed that icky strain of alien bug warrior, and those CG designs still hold up today, helping enshrine Starship Troopers as cult viewing. Some filmmakers have tried, and failed, to replicate its iconic battle scenes; others, like Peter Jackson on Lord Of The Rings, Zach Snyder’s 300 and Ridley Scott’s Kingdom Of Heaven all struck CG gold, each benefitting from the steps first made here.

Year: 1997
Significance: Landmark CG effects

The most expensive film of its time, commanding a hefty budget of $200 million, James Cameron’s Titanic required over 500 visual effects shots to recreate one of the biggest disasters of the 20th century. Not only were the fundamental pieces of the ship – the hull, boiler room and boat deck – generated by computers, but major advancements were made in the depiction of flowing water that allowed the audience to immerse themselves in the illusion of a watery grave. More than four studios were reportedly involved behind the scenes, tasked with the meticulous nature of wire removal for flying objects and falling people, and the eventual grand-scale destruction of the ship. It was good enough to fool Davy Jones himself.

Year: 1999
Significance: First use of photogrammetry

We’d be impressed if you remember this film for its use of photogrammetry, and double points if you actually knew what the word means. It's the method of measuring objects using photographs, and its emergence in Fight Club was an important step towards finding a balance between CGI and storytelling. Most notably applied in architecture, engineering and geology, its practical use in film was uncovered by David Fincher when he looked to solve a common filmmaking problem. The story goes that in the ‘kitchen explosion’ scene Fincher wanted to avoid the camera being seen in the reflection of the stove as it passed over. Instead wire-frame 3-D models were rendered from photographs to map and recreate the set seen in previous shots. Not exactly a straightforward solution.

Year: 1999
Significance: Development of bullet time effects

The Wachowski brothers and their VFX supervisor John Gaeta looked east to help inject The Matrix with its hyper-real action beats. Akira director Katsuhiro Otomo’s view-morphing techniques were a major influence on the movie. Multiple cameras, CG and wire work-driven motion played with viewers perceptions and created the rotating, slow-motion bullet-time: a full-throttle extension of traditional time-slice photography. Helping with the wire work was Hong Kong action cinema choreographer Yuen Woo-ping – a veteran Jackie Chan and Jet Li collaborator whose martial arts whirlwind Fist Of Legend had caught the Wachowski’s eye – who also enhanced the Oscar-winning effects team create Neo’s suspended, airborne kung fu fights.

Year: 2001
Significance: First photo-realistic human actors

Cinema’s first near-photorealistic character wasn’t Gollum or The Polar Express’ conductor, but Dr Aki Ross, the heroine of Hironobu Sakaguchi’s entirely CGI sci-fi. She was rendered in incredible detail – down to the 60,000 hairs on her head – in a production process that took four years and cost nearly $150m. It was a painful process (the 141,964 frames each took an average of 90 minutes to render) and a revolutionary one (early shots had to be redone as the advancing technology allowed for extra detailing), employing a crew of 200 and a render farm in Hawaii boasting nearly a thousand Pentium workstations. To give an idea of how far technology had come in 19 years, the final animation represented 15 terabytes of memory. In 1982, Tron’s effects were created on a computer with 0.0000019 terabytes. Sadly, audiences didn’t much care for the end product: it was a flop so catastrophic it sent its studio, Square Pictures, to the wall.

Year: 2004
Significance: First motion-capture feature film

While the debate over performance capture rumbles on, at least in some sections of Hollywood and at Meryl Streep’s house, its journey into the mainstream began with Robert Zemeckis’ chilly choo-choo adventure. Zemeckis, whose digitised box of tricks injected Forrest Gump, Zelig-like, into various historic scenes, whipped off Gary Sinise’s legs and won him an Oscar in 1995, reunited with Tom Hanks, clad him in a fetching mo-cap suit and set to work pushing the boundaries of the medium. Ping pong balls – sorry, mo-cap markers – tracked Hanks five different performances, feeding them into computers which whizzed them into revolutionary, performance-driven animation. Zemeckis’ innovation built on Peter Jackson’s work with Gollum in LOTR. He developed it further with Beowulf and A Christmas Carol, but The Polar Express was the first major game-changer, an entirely mo-capped movie. The problems Zemeckis had with those scary dead-eyes have since been solved by Weta’s facial rig on Avatar. Which is just as well because if Santa came down our chimney with those blank peepers, we’d run screaming.

Year: 2002

Significance: Motion-capture and CG artificial intelligence

With Avatar and District 9 now behind it, Weta Digital has joined Pixar and ILM at the bleeding edge of CG special effects, but it was Peter Jackson’s Tolkien epic that got the ball rolling. Thanks to Andy Serkis’ remarkable performance and Weta’s digital effects team, Gollum became the first motion-captured CG character to interact directly with other actors. Traditional animation techniques, including rotoscoping and keyframing, were used to replace Serkis’s face with Gollum’s after Jackson decided against making Gollum an entirely CGI character. “We have little piece of Gollum in the first film,” says Jackson, “little teasing the blips of Gollum in the mines. That was our R&D kind of prototype Gollum. We basically threw him away at the beginning of this year because we were able to do so much better. We rebuilt Gollum from scratch – using new software that had been written, new software that our guys had written – and improved him a lot.” LOTR was also notable for its MASSIVE software (acronym boffins will know it better as ‘Multiple Agent Simulation System in Virtual Environment’), which generated artificial intelligent CG orcs by the thousands, lending its epic battles serious levels of realism.

Year: 2009
Significance: Facial capture

On Avatar, motion-capture became 3D e-motion capture, thanks to Weta Digital’s pioneering facial capture rig, state-of-the-art prosthetic work and texture painting that made the CG performances sing. There were also post-production meetings in which the actors talked through every beat of every scene with the people who would render their Na’vi counterparts. While the studio boasted plenty of LOTR veterans, as well as the battle-hardened MASSIVE software, James Cameron raised the bar still higher, demanding that every plant, tree and bioluminescent speck be individually rendered. No mean feat considering a single Pandoran plant comprised of a million CG polygons (Gollum was 50 polygons). Cameron’s Lightstorm Studio sent across the mo-cap data and camera moves to Wellington, where Weta rendered them into sparkling Pandora-ready animation using one of the world’s biggest servers to store the data. But it was the giant leap forward in facial performance capture – a wave farewell to dead eye syndrome – that Cameron is most proud of. “It’s funny that the press has latched on to the 3D thing for Avatar," reflects the director, "because in a way 3D was the least of Avatar for me. We spent two years in R&D to develop the facial capture, the CGI. For me this was the big thing.”
.I 120
.T
document.120
.W
﻿ANIMATORS will soon be able to construct startlingly realistic sylvan beauty in movies and video games with a new system for generating 3D virtual trees.

At the moment, computer-generated images (CGI) of trees are either drawn manually on a computer and then animated, or someone has to shoot video of a tree moving in the wind. This is digitally transformed into a CGI copy of the original. Either process takes days – and you can only produce one size and shape of tree, says Chuan Li, a computer animator at the University of Bath in the UK.

To solve this problem, Li and colleagues have developed software that generates realistic-looking 3D animated trees of any size and shape based on a rough 2D sketch. The trees even blow in the wind like their woody counterparts, and can be whipped around just by piping in a soundtrack of a blustery day.

The system can start with just a 2D sketch of a tree’s leafless branches, and an outline of what the tree’s shape will be once it is in full leaf. The 2D sketch is then copied and rotated 90 degrees into 3D space. From there, an algorithm “grows” additional branches for the tree until a 3D skeleton is complete.

The software contains a model of how real tree branches move in both light and strong winds, based on video footage the team shot. The system applies this model to the tree skeleton to work out how the branch structure would move large clusters of leaves as they billow in the breeze. Each virtual branch in the skeleton is then broken into six segments. “By rotating each segment independently we can get the right magnitude of tree movement for the wind speed,” says Li. Once they have captured a tree’s 3D skeleton, they can scale it up or down for trees of different shapes and sizes, from a short wispy cherry to a dense, tall oak. The team’s work was published in December in the journal ACM Transactions on Graphics (DOI: 10.1145/2070781.2024161).

This means that any sketch of a tree skeleton can be used to generate a 3D model that moves like a real tree. Better still, the trees automatically respond to the sound level of the wind in a soundtrack, measured in decibels, without adding physical parameters like wind speed. So as noise increases from a light breeze to a howling gale, tree branches go from swaying peacefully to flailing wildly.

“When I saw this my jaw was on the floor,” says Jordi Bares, 3D creative director at London animation studio The Mill, who marvelled at the package’s simplicity and speed, and adds he hopes it will be commercialised soon. “It’s a game changer that could save us the huge chunk of our time we currently spend creating natural 3D assets like trees.”
.I 121
.T
document.121
.W
﻿1941

Although the punched card was first used in 1801 to control textile looms, they were first used as an input medium for “computing machines” in 1941. Special typewriter-like devices were used to punch holes through sheets of think paper. These sheets could then be read (usually by optically based machines) by computers. They were the first input device to load programs into computers.
punchedcard.jpg

Salustri used punched cards in 1980 in his first-year Introduction to Computing course at the University of Toronto.
1950

Ben Laposky created the first graphic images, an Oscilloscope, generated by an electronic (analog) machine. The image was produced by manipulating electronic beams and recording them onto high-speed film.


1951

The Whirlwind computer at the Massachusetts Institute of Technology was the first computer with a video display of real time data.
1951_whirlwind.jpg

1955

The light pen is introduced.
1955_sagelightpen.jpg lightpen.jpg

1960

Although known since the 1940's, the first serious work on finite element methods of analysis is now published. FEA allows us to test products virtually and produce results that are as accurate as physical tests - at far less cost and time. The results of such an analysis was, back then, hundreds of pages of numbers that humans had to interpret. These days, thanks to computer graphics, we can literally see what would happen to our products in real-time.
A modern FEA of a bicycle frame.

1961

Fil Salustri was born.
The first video game, SpaceWar, ran using an oscilloscope as a display.
Oscilloscopes are vector displays.
Ivan Sutherland writes the first computer drawing program - SketchPad - which included things like pop-up menus.
To generate one GFLOPS1) of processing power with 1961 technology, you would need to spend over $8 trillion (in 2013-adjusted US dollars).
1961_spacewar.jpg sutherlandsketchpad.jpg

1963

Doug Engelbart invents the computer mouse.
1963_mouse.jpg

1965

Jack Bresenham invents the “ideal” line-drawing algorithm.
NASTRAN FEA software released.


1970

Size of CAD market estimated at $25 million.
ANSYS founded.
1972

Nolan Kay Bushnell creates Pong, video arcade game.
Raster displays begin to appear.
Introduction of the CT scanner.
  upload.wikimedia.org_wikipedia_commons_a_ae_emi1010.jpg

1975

K. Vesprille's PhD dissertation “Computer-Aided Design Applications of the B-Spline Approximation Form” develops the mathematical representation of arbitrary curves suitable for computation.
1977

The Apple II is the first graphics personal computer.
Star Wars is released; its only computer effects were vector-based, and then filmed.
CADAM, the first commercial 2D CAD package, is released.
McDonnell Douglas buys United Computing, forming Unigraphics.
 application.denofgeek.com_images_m_sw_quad0.jpg

1978

First real standard for constructive solid geometry developed by H. Voelcker et al.
Charles Lang at Cambridge University develops the first real boundary representation modelling engine.
1979

Size of CAD market estimated at $1 billion.
1981

CATIA, one of the first 3D CAD packages, is developed, using constructive solid geometry.
1982

The Commodore 64 personal computer used raster graphics so that regular televisions could be display devices.
TRON is the first movie to make extensive use of computer graphics.
AutoCAD 1.0 is released - it uses wireframe representation only.
SDRC I-deas CAD package released.
Voelcker introduces the notion of a voxel.
The Apple Lisa was a fantastic computer that failed. The Lisa was first introduced at a cost of 9,995US(9,995US(20,893 in 2007 dollars). It was one of the first commercial personal computers to have a GUI and a mouse. It used a Motorola 68000 CPU at a 5 MHz clock rate and had 512 KB or 1 MB RAM. This made it a quantum leap in technology.
But it was so innovative that it was wrong2). It simulated hardware in software, so it's very powerful CPU seemed slow to users. Also, there was no real software for it - it was in some ways too powerful. And it was certainly too expensive.
www.larwe.com_museum_img_c64system.jpg seandodson.files.wordpress.com_2008_07_tron_lightcycles.jpg  upload.wikimedia.org_wikipedia_commons_b_b6_apple_lisa.jpg

1984



To generate one GFLOPS of processing power, you would need to spend over $30 million in 2013-adjusted US dollars. (Compare that to the 1961 data.)
The original Macintosh was in many ways a “stripped down” Lisa. It had 20% of the base memory of the Lisa, but it ran faster because it used conventional hardware configurations. In the design of the Macintosh, Apple recognized that computational power was only one of many aspects of computer use by humans and that if they wanted a good design, they would have to satisfy human nature.
The Macintosh set a new standard for computer design, and for design in general. This went to the point of establishing Apple as the “anti-IBM” (these days, the anti-PC) with a television advertisement originally aired during Superbowl XVIII3).

1985

Pixar releases Luxo, Jr.
Voxel technology is embedded in most medical imaging software.

regmedia.co.uk_2004_09_29_chest_image.jpg

1987

VGA graphics standard introduced. Pro/Engineer launched as first pure UNIX CAD software. Everyone laughed. 18 months later, all major CAD vendors were developing CAD for UNIX.
1988

CATIA selected as CAD package for Boeing 777 leading to a $1 billion revenue for Dassault.
1989

SVGA graphics standard introduced.
The Parasolid solid model engine standard released by Unigraphics; it is licensed to nearly every other vendor.
Tim Berners-Lee creates the very first website ever (this is even the actual original URL). The version linked here is from 1993, as it seems older backups have gone missing. (more info)
1991

EDS buys Unigraphics.
1992

All major CAD packages run on UNIX. SMEs lead the change from mainframes to high-end UNIX workstations. IBM loses $5 billion because no one wants mainframes any more.
1993

UIUC releases Mosaic, the first web browser for general usage. Mosaic's “codename” was mozilla.
Jurassic Park was the first big-budget CGI effects movie.
First public call made from a cell phone.
thecia.com.au_reviews_j_images_jurassic-park-4.jpg

1994

Dragged kicking and screaming into the 20th Century, Autodesk finally releases a 3D version of AutoCAD.
Key developers of the Mosaic browser found Netscape.
First flight of Boeing 777, tested entirely via ANSYS
.I 122
.T
document.122
.W
﻿The phenomena described by Ibn al-Haytham explains why we see objects. Two interesting remarks can be made based on his observations: firstly, without light we cannot see anything and secondly, without objects in our environment, we cannot see light. If we were to travel in intergalactic space, that is what would typically happen. If there is no matter around us, we cannot see anything but darkness even though photons are potentially moving through that space.

Forward Tracing


Figure 1: countless photons emitted by the light source hit the green sphere, but only one will reach the eye's surface.
If we are trying to simulate the light-object interaction process in a computer generated image, then there is another physical phenomena which we need to be aware of. Compared to the total number of rays reflected by an object, only a select few of them will ever reach the surface of our eye. Here is an example. Imagine we have created a light source which emits only one single photon at a time. Now let's examine what happens to that photon. It is emitted from the light source and travels in a straight line path until it hits the surface of our object. Ignoring photon absorption, we can assume the photon is reflected in a random direction. If the photons hits the surface of our eye, we "see" the point where the photon was reflected from (figure 1).


QUESTION FROM A READER: above you claim that "each point on an illuminated area or object radiates (reflects) light rays in every direction." Doesn't this contradict ''random''?

ANSWER: explaining why light is reflected in every possible direction is a off-topic for this particular lesson (one can refer to the lesson on light-matter interaction for a complete explanation). However, to answer your question briefly: yes and no. Of course in nature, a real photon is reflected by a real surface in a very specific direction (and therefore not a random one) defined by the geometry's topology and the photon incoming direction at the point of intersection. The surface of a diffuse object appears smooth if we look at it with our eyes. Although if we look at it with a microscope, we realize that the micro-structure is very complex and not smooth at all. The image on the left is a photograph of paper with different magnification scales. Photons are so small that they are reflected by the micro-features and shapes on the object's surface. If a beam of light hits the surface of this diffuse object, photons contained within the volume of the beam will hit very different parts of the micro-structure and, therefore, will be reflected in lots of different directions. So many, that we say, "every possible direction". If we want to simulate this interaction between the photons and the micro-structure, we shoot rays in random directions, which, statistically speaking, is about the same as if they were reflected in every possible direction.

Sometimes the structure of the material at the macro level is organized in patterns which can cause the surface of an object to reflect light in particular directions. This is described as an anisotropic reflection and will be explained in details in the lesson on light-materials interaction. The macro structure of the material can also be the cause of unusual visual effects such as irridescence which we can observe of butterflies wings for instance.

We can now begin to look at the situation in terms of computer graphics. First, we replace our eyes with an image plane composed of pixels. In this case, the photons emitted will hit one of the many pixels on the image plane, increasing the brightness at that point to a value greater than zero. This process is repeated multiple times until all the pixels are adjusted, creating a computer generated image. This technique is called forward ray-tracing because we follow the path of the photon forward from the light source to the observer.
2
.I 123
.T
document.123
.W
﻿Our graphics capabilities have sort of plateaued as of late. Games and movies look better than they ever have, but we’re still embroiled in an eternal battle with the Uncanny Valley. No matter how great a video game heroine’s hair looks, or how many individual furs are articulated on an anthropomorphic Pixar character, we can still instantly tell that computer-generated graphics are just that — generated by a computer. Aside from human eyes and mouths, one of the biggest enemies of the Uncanny Valley is computer-generated water. With PhysX’s position based fluids, though, CG water flows the best we’ve ever seen.

Perhaps the closest we’ve come to mind-blowing computer-generated water effects in a consumer product is the water in the Uncharted series. The way the water flows won’t explode any brains, but how it dampens anything it touches, exactly where it touches, is nothing short of mesmerizing. For instance, whatever angle a character enters a body of water, his or her shirt and pants will become damp based on which parts of the clothing actually touched the water. While that realism is impressive, it certainly doesn’t translate to the way the water flows. However, PhysX’s position based fluids research seems to have produced computer-generated water that moves just like the real thing.


CG water that behaves similarly to real fluid has been around for a while — most notably in tech demos showing off that it’s possible, or perhaps appearing in the occasional big-budget movie. However, it’s too computationally intensive to put into a real-time application, like a video game. For as pretty as the CryEngine is, our hardware just can’t dedicate enough resources to generate fancy flowing fluids. Now, though, Nvidia’s Miles Macklin and Matthias Müller-Fischer have figured out a way to reduce the load on hardware, generating a result that is remarkably fluid, but “suitable for real-time applications.”

Position based fluids — the method used — is similar to the one that dictates the behavior of computer-generated cloth, position based dynamics. Unfortunately, the exact methods used to reduce the computational load and create lifelike water movements haven’t yet been revealed, as Macklin and Müller-Fischer are saving the details for a forthcoming research paper. What the pair did note, though, is that they were able to create surface tension, improve particle distribution, and lower the overall computational requirements to get everything working.

The “real-time applications” weren’t defined, and we’re not sure if that means consumer-grade entertainment media, or expensive and powerful systems used by professional designers. The above video is a mightily impressive tech demo either way. The water bounces and flows like it would in real life, shimmying between cracks, rolling off of curved surfaces, and adhering to inertia. Almost benevolently, the video morphs the water into little spheres, giving us something of an X-ray view of how the water moves.

Hopefully, the PhysX duo will be able to transfer the position based fluids method to next-gen consumer-grade applications, and we’ll soon be able to watch water soak a character’s shirt, but realistically bounce around between his arms and off of his torso during the process.
.I 124
.T
document.124
.W
﻿Introduction
This course is an introduction to realistic 3D rendering in computer graphics. You will learn about the theory and practice of designing 3D rendering programs to generate realistic images. We will cover the background of phyiscally based image synthesis including radiometry, the bidirectional reflectance distribution functions, the rendering equation, and the radiative transfer equation. We will discuss algorithms to compute the rendering equation such as Monte Carlo path tracing, importance sampling, photon mapping, and radiosity. You will learn about strategies for efficient ray tracing, high-quality antialiasing, and more.

The course has several programming assignments in which you will implement a 3D rendering program based on ray tracing step by step. The rendering program will include acceleration structures, and advanced rendering capabilities such as Monte Carlo path tracing and photon mapping. A detailed schedule and all class materials are available on Ilias.

Learning Outcomes
On successful completion of this class, you will be able to:

Design and implement a rendering system to generate realistic images in an object oriented programming framework.
Describe how the problem of realistic image synthesis is formulated mathematically using the rendering equation.
Explain radiometric concepts such as radiance, irradiance, radiosity, and the bidirectional reflectance distribution function (BRDF).
Describe how the appearance of physical materials can be modeled using BRDFs.
Describe how the rendering equation can be solved using Monte Carlo path tracing.
Describe improvements of Monte Carlo path tracing such as importance sampling, bidirectional path tracing, and photon mapping, and list their advantages.
Describe how the rendering equation can be solved using finite element methods such as radiosity, and compare these to Monte Carlo methods.
Design and implement extensions and optimizations of a basic path tracing algorithm, including: spatial data structures such as kd-trees; irradiance caching; participating media; lens effects; texturing.
Programming Assignments
The course contains several programming assignments. The goal of these assignments is to build your own 3D renderer step by step. There will be four assignments:

Basic ray tracer
Acceleration structures and area lights
Global illumination
Advanced features
Class Material
All class material including slides and exercises is available on Ilias.
Recommended Reading
Suffern, "Ray tracing from the ground up", AK Peters, 2007
Shirley, "Realistic ray tracing", AK Peters, 2nd ed. 2008
Pharr and Humphreys, "Physically Based Rendering", Morgan-Kaufman 2004
Wann Jensen, "Realistic Image Synthesis Using Photon Mapping", AK Peters, 2001
Dutré, Bala, and Baekert, "Advanced Global Illumination", AK Peters, 20
.I 125
.T
document.125
.W
﻿The title of this thesis 'Mathematical Frameworks and Monte Carlo Algorithms for Global Illumination in Computer Graphics' refers to a domain in the field of computer graphics known as photo-realistic image rendering or global illumination. The goal of this domain is to compute realistic pictures of a three-dimensional scene, as could have been observed by a human observer or more precisely, a camera. The first part of this work describes the physical and mathematical foundations which are needed in order to describe the global illumination problem. The fundamental physical measure needed to describe the distribution of light in an environment is radiance. The equation describing the transport of radiance is a recursive integral equation. The dual problem introduces potential as a basic measure, and the potential equation as the corresponding transport equation. Both dual formulations can be used in order to solve the global illumination problem. Once the mathematical framework has been developed, the equations describing the transport of light or potential can be solved. Due to the high number of integrals and the complexity and unknown behaviour of the functions to be integrated, Monte Carlo integration provides a viable method of computing the global illumination in a three-dimensional scene. Depending on the choice of what transport equation to use, the radiance transport equation leads to distributed ray tracing or path tracing, and the potential transport equation leads to light tracing or particle tracing. The latter method generates particles at the light sources, which each carry a small amount of power. They carry out a random walk in the three-dimensional scene, and possibly contribute their power to the flux of a pixel on the screen. Mathematically, this algorithm can be considered as the dual algorithm of ray tracing. The sampling functions used for the generation of the random walks can be based on reflective properties of the surfaces encountered. However, in diffuse environments, better results can be expected when they are based on the (unknown) potential distribution. Since the optimal sampling function is not known in advance, one solution is to use adaptive probability density functions. As more particles are being generated, the potential distribution can be approximated more accurately, and thus a better sampling function can be con- structed. This technique requires a substantial amount of memory, but produces better results. The used sampling algorithms can also be extended to other Monte Carlo rendering algorithms, such as bidirectional path tracing.
.I 126
.T
document.126
.W
﻿New York City has just been destroyed by a 40-foot-tall deluge. Pirates battle around a giant, violent whirlpool. Without years of work by the 2007 Scientific and Technical Oscar winners, none of those images would have made it to a computer—and then a multiplex—near you.
The geek's Oscars, held every year in a separate ceremony a few weeks before the main event, are more like a hall of fame for the mathematicians, engineers and scientists behind standout movie tech than awards for recent efforts. While award recipients this year ranged from film technicians to makeup artists, two of the night's winners centered around the field of fluid animation, which makes possible those crazy flood scenes and massive faked explosions. The first went to Jos Stam, a computer scientist whose paper "Stable Fluids" formed the foundation for the entire field, and the other to technicians at Industrial Light and Magic and Digital Domain, who over the past seven years have developed software based on Stam's formulas that gives directors an unprecedented amount of control over fluid effects in their movies.
Faking fluids on a large scale is a fairly new development. Until the late 1990s, effects like the water tentacle in The Abyss were drawn into the computer one frame at a time by hand, as with traditional cell animation, or by laying liquid-looking skins over solid, computer-generated frames.
That's because the equations for calculating the physics of fluids are so complex that until recently, the only fluid simulation being done was at Los Alamos National Laboratory to predict the flow of nuclear explosions. The 1998 movie Antz was the first to use computer-simulated fluids, but the process was so time-consuming and complex that few were willing to attempt it.
Then, in 1999, Stam presented his paper at a computer-graphics conference that changed everything. Building off a 1996 paper by Nick Foster and Dimitri Mataxas, Stam showed how basic fluid-dynamics equations could be calculated by far less powerful computers. The equations soon became integrated into a range of animation software that contributed to the effects of such movies as The Lord of the Rings and Pirates of the Caribbean. But the new equations had two clear shortcomings: Ironically, they couldn't handle water-like fluids (to a physicist, gases and fire are also fluids), and they only helped animators simulate, not control, the fluids.
That's because a fluid simulator can only make fluid behave as it does in real life. If the director wanted to manipulate an explosion to get a more dramatic look, tough luck. The programmers needed to develop software that allowed animators to make fluids behave unrealistically while still fooling the audience into believing what they were seeing. "It's a common misconception that visual effects are about simulating reality. They're not. Reality is boring. Visual effects are about simulating something dramatic," says Jonathan Cohen, a 2007 Sci-Tech Oscar winner and principal software engineer at effects house Rhythm and Hues.
Then the geniuses at ILM and Digital Domain came to the rescue. Over the past couple years, designers there have solved the control problem by adding to the equations virtual copies of the kinds of things that move fluids in the real world: fans, invisible whirlpools, hidden suction pumps. Now designers are able to nudge, pull, and generally manipulate their virtual fluids to meet the directors' and animators' desires. That control can be seen at work during special-effects set pieces like the whirlpool in the third Pirates of the Caribbean movie or the flooding of New York City in The Day after Tomorrow.
And now that they've got the fluid control down, maybe someone can start working on the writing.
.I 127
.T
document.127
.W
﻿In 3D assisted simulation and test environments it is often required to interactively navigate in highly complex 3D scenes, which are partly generated at run time. To render such 3D scenes in real time, we develop rendering algorithms, which reduce the amount of data to be processed in such a way that fluent navigation is possible.

On-the-fly approximation of emerging virtual worlds

Nowadays, the specific testing of functions of driver assistance systems takes place with the aid of driving simulators which contain modern complex virtual reality representations of numerous different test scenarios. The 3D scenes of the test scenarios are highly complex, highly dynamic, and have to be rendered in real time. We develop algorithms and methods to simplify and reduce the complexity of the 3D data to be processed, to make such virtual worlds navigable. In traditional applications, these partly very large datasets are stored on physical storage media and can be preprocessed to create data structures to make this task easier. Unfortunately, such preprocessing steps are not possible in our application field, the simulation of driver assistance systems, because the virtual environment around an observer might not be completely known beforehand. For example, this is the case, when the 3D-data is generated at run time through a test leader, or received from an external data source. We develop data structures and algorithms to simplify and render complex geometry on-the-fly, without preprocessing. Future works will also focus on realistic lighting simulation for the generated scenes, using global illumination information.


Automatic detection of the animation path of a conveyor chain in a 3d polygon model
Real-time rendering of CAD-data using PADrend

Since 2007, we develop in our group the rendering system PADrend (Platform for Algorithm Development and Rendering). PADrend is a software system for virtual walk-throughs in highly complex virtual 3D scenes and is aimed at the aided development of rendering algorithms and the possibility to fairly compare different algorithms. Last year, we developed new rendering algorithms in PADrend, to speed up the visualisation of highly complex CAD data. The algorithms that were developed last year focus especially on the requirements of machinery which have a high degree of moving parts in the virtual scene. In the leading-edge cluster “it's OWL”, we used PADrend to visualise highly complex CAD construction data in design reviews for mechanical engineering companies from Ostwestfalen-Lippe. The mechanical engineering company WP Kemper GmbH used PADrend at their exhibition stand at the iba in Munich for the 3D visualisation of their highly complex dynamic machinery. For this project, we also developed an algorithm for the automatic detection of animation paths for the material transport with conveyor chains, rails, or conveyor belts, using only the surface information of the 3D polygonal models.
.I 128
.T
document.128
.W
﻿Mark charts some of the groundbreaking moments in computer animation from Pixar's relatively short history...
These days most people don't consider the technology that goes into a CGI movie or advert. It's assumed that the computer does most of the work and those involved simply take the accolades.

But that thinking is naive, as computer graphics have evolved dramatically since the first CGI scenes were incorporated into movies and, in many ways, Pixar has always been at the bleeding edge of what was technically possible. To understand the development of Pixar's rendering technology (called Renderman, incidentally) let's go through some of their movies and explain the advancements that each contributed to each, making each production special.

Toy Story (1995)

Disney/Pixar's Up - Upular Remix

video playingDisney/Pixar's Up - Upular Remix
Disney/Pixar's Up - Upular Remix
15/02/10Disney/Pixar's Up - Upular Remix
Disney/Pixar's Toy Story 3 - Official Full Length...
11/02/10Disney/Pixar's Toy Story 3 - Official Full Length Trailer #3 (HQ)
Skulls throughout history
09/02/10Skulls throughout history
Disney/Pixar's Toy Story 2 in 3D - Bloopers
26/01/10Disney/Pixar's Toy Story 2 in 3D - Bloopers
Short stories
21/01/10Short stories


The fact this could be made at all was probably the biggest innovation, but behind that was a very careful balancing act between the complexity of the images and animation, and actually getting the production completed within a reasonable timeframe.

To help do this, logic was applied to each scene so as to identify those portions of the image that would require re-rendering between frames. So, if Woody, for example, was standing in front of a background that was largely unmodified by his movement, that was only rendered once and then retained as the animation sequence developed.



It's unfeasible not to acknowledge the importance of Toy Story in the history of CGI, as it was the point at which the impossible became possible. Unusually for the Academy of Motion Pictures, they actually noticed its significance, and awarded  the mastermind behind Pixar and the director of the movie, John Lasseter, a special Oscar in 1996 "for the development and inspired application of techniques that have made possible the first feature-length computer-animated film".

Toy Story proved that CGI could be used to tell a character-based story, and in doing so changed the world of animation forever.

A Bug's Life (1998)



This story of insect uprising marked a notable jump in the complexity of both character design and environment. Yet, this was still finely balanced with the demands on computer resources.

As such, much the same choices that drove the character design in Toy Story also lead them to choose hard exoskeleton bodied insects in this. But the extra computing power available did allow them a little 'soft body' extravagance with Heimlich the caterpillar.



In repeat viewing what's impressive about A Bug's Life are the simulations of natural vegetation and the sheer number of characters in some scenes. 

See also: A Bug's Life - The Forgotten Pixar Movie

Toy Story 2 (1999)



Plenty of effort went into making the script for this movie as good as the original, but it was also another significant technical leap.

In the original, not wanting to push the technology too far, Pixar limited the screen time of human characters. But in Toy Story 2 they're much more apparent, and required to do more acting.



But in technical terms, the highlight of this production was certainly the fabric handling routines that allowed Woody to be sewn up and repaired.

Monster's Inc. (2001)



For very obvious reasons, in Toy Story Pixar avoided hair. It eats vast amounts of computing cycles to calculate, move and render, but in Monster's Inc it finally bit the bullet on exploring that requirement.

And just to prove it'd mastered hair entirely, it made Sully - one of the two main characters - entirely covered in long fine fur. In the movie, it's required to be blown by the wind, be moved by hand and generally look real at all times.



The richness of the visuals in Monsters Inc is striking, as is the quality of movement and expression in the characters.

Finding Nemo (2003)



In a word, 'underwater'. Creating believable visuals for numerous types of ocean environment was the challenge Pixar had here, along with portraying the various states of the sea surface. But along with that challenge, it also simulated the movement of bubbles and characters caught in eddies and currents.



This is probably the production where Pixar could rely least on tricks to reduce rendering times, and by the very nature of the environment, most frames needed to be fully rendered.

The Incredibles (2004)



The visual styling of this movie hides a significant change in the capability of Pixar's CGI technology. Where in previous productions notable limitations funnelled the look into particular directions, here design was king and the technology bent to achieve that.



It also has some huge external scenes on the island, dwarfing any CGI sets that it'd previously considered. But these were just the tip of a whole CGI iceberg of problems that the complexity of The Incredibles represented.

It's Pixar's first film that has an entirely human cast, using long flowing hair and realistic folding and tearing fabrics, among a long list of firsts.

Cars (2006)



For once the mechanics of a Pixar film didn't include creatures or people, but mechanical objects with suspension and friction with the ground. As such, these came with their own problems, not least designing them to move believably.

But with 1,000 times the computing power of the systems that rendered Toy Story, Pixar did have some scope for calculating more complex interactions between objects, and also handling reflections and imperfections.



The surfacing of the cars is amazing as it's built up from successive layers of gloss paint, nicks and scratches and then further degraded with dust and other damage. The scenes in the various race meetings also have more characters seen in a single shot than any Pixar production before or since.

.I 129
.T
document.129
.W
﻿Software developed in Heriot-Watt Texture Laboratory is vital to the production of over 200 million IKEA catalogues every year, for more than 40 countries worldwide.

When retailers create images for sales catalogues and web pages it is not always practical to use photographs of the final product. Where a product is available in many colours and finishes, it may not be cost-effective to produce photographs that show customers every possible variation. Using a virtual image featuring a three-dimensional (3D) model of a product solves this problem, while allowing catalogues to be put together well in advance, before new designs go into full production.

This is very important software for IKEA Communications... it has completely transformed the way in which we produce both traditional and digital content.
Anton Berg, 3D Specialist, Ikea Communications
A typical IKEA catalogue image of a lounge, for example, is a computer-generated image (CGI), created via access to a library of captured 3D textures. Producing a photorealistic version of each item requires precise attention to detail. Designers and artists must both generate an accurate 3D scale model and achieve a convincing surface finish in a wide variety of materials. Capturing 3D textures in a way that is fast and accurate is therefore essential.

IKEA investigated commercially available ways of achieving this (such as 3D laser scanners) but were unable to find a satisfactory solution. The company then approached Heriot-Watt’s Prof Mike Chantler of the School of Mathematics and Computer Science, an expert in the digitisation and presentation of surface textures. Long-term work led by Prof Chantler in Heriot-Watt’s Texture Laboratory on developing techniques to capture 3D surfaces via stereo scanning had achieved the capability IKEA was looking for.

In 2007 the Texture Laboratory installed its system at IKEA Communications, Sweden. Since then it has been used continually to amass a digital library of over 5,000 materials for generating sales imagery.

IKEA’s decision to seek Heriot-Watt expertise has helped put the company at the forefront of companies using CGI to optimise homeware marketing.
.I 13
.T
document.13
.W
A critical history of computer graphics and animation
History is the version of past events that people have decided to agree upon.
Napoleon Bonaparte (1769 - 1821)

History never looks like history when you are living through it.
John W. Gardner (1912 - 2002), quoted by Bill Moyers

 
 	 	 	 	 	 
 	
The study of the history of CGI (computer generated imagery) is an important part of our overall educational experience, not necessarily to build on the historical precedent, but to gain an understanding of the evolution of our discipline and to gain a respect for the key developments that have brought us to where we are. The discipline is so recent in its early developments and so rapidly changing that we are in fact living it, and it evolves as we speak. Yet we have been so busy in advancing the discipline that we have often neglected to accurately record this history. So we will decide to agree upon certain past events in order to begin to develop a definitive record of what has transpired in this evolutionary process.

We must learn from the past, as we develop a theory and methodology which is tuned to the capabilities and qualities inherent in software, hardware, animation techniques, etc. that are part of our broad, contemporary, and creative computer graphics environment. It is in this context that this course has been developed.

Herbert Freeman, in an introduction to his 1980 IEEE compilation of computer graphics papers, presents a succinct overview of the first two decades of the development of the CGI discipline. Like many other disciplines, computer graphics and animation has a rich (albeit relatively short) history that involves the following four eras, which are very much linked and related:

pioneers
innovators
adapters
followers
Early pioneers include artists (such as Chuck Csuri and John Whitney) and researchers (such as Ivan Sutherland and Ken Knowlton). These visionaries saw the possibilities of the computer as a resource for making and interacting with pictures, and pushed the limits of an evolving technology to take it where computer scientists never imagined it could go. Their work motivated the work of the others as they tried to realize the potential of this new vision. In this course, we will survey work from Sutherland, Csuri and Whitney, National Research Council of Canada (Burtnyk, Wein and Foldes), Michael Noll, Lillian Schwartz and Ken Knowlton, and others.

Many of the so-called innovators were housed in universities and research labs, and were working toward solving fundamental problems of making "pictures" of data using the computer. We will survey work from many of these facilities, including Bell Labs, Ohio State, University of Utah, New York Institute of Technology, Evans & Sutherland and several aerospace and automotive companies, MIT, and others. Individual work of Nelson Max, Jim Blinn, Loren Carpenter, Turner Whitted, and others will also be reviewed.

The early adapters included pioneering CGI production facilities, artists, researchers, and research labs and industries with an interest in converting much of this early work into a viable (and marketable) tool for realizing their disparate goals. Notable companies include Robert Abel and Associates, Digital Effects, MAGI, Information International Inc., and others. Artists include more from Whitney Sr., Yoichiro Kawaguchi, David Em, Jane Veeder, and others.

The late seventies and early eighties saw the second wave of adapters, which were primarily special effects production companies, equipment and software developers, universities, motion picture companies, etc. We will survey work from PDI, Cranston/Csuri Productions, Digital Productions, Omnibus, LucasFilms, and others.

As the technology advanced and the acceptance of this new approach to image making increased, the industry likewise evolved, and many of the current contributors, or followers (this descriptor is not intended to be demeaning or derogatory) came into being. These include effects production companies such as Pixar, Disney, Metrolight, Rhythm and Hues, ILM, Sony, Digital Domain and others. We will also look at work from universities such as Cal Tech, Ringling, Cornell, Ohio State, UNC, Brown, Utah, etc., and companies and research labs such as Apple, SGI, Microsoft, Alias, Softimage, Interval Research, and others. We will look at the impact on related areas, such as HCI, design, multimedia, virtual reality, scientific visualization, etc.

The course will include a review of the work of these individuals and institutions on video and film, as well as a review and discussion of printed material from the literature. Students are expected to participate in these discussions.

For a review of the various institutions and individuals that have contributed to the discipline and that are covered in the course readings, take a look at the CGI Family Tree (which is also in the infancy stage and evolving on a daily basis!!)

An historical timeline (always under construction) can also be accessed, as can a short history of CGRG and ACCAD. Additional resources (eg, papers) used in this class can be accessed from the readings or obtained from the resources link.
.I 130
.T
document.130
.W
﻿San Diego, CA, April 15, 2008 -- UC San Diego computer scientists have created a fog and smoke machine for computer graphics that cuts the computational cost of making realistic smoky and foggy 3-D images, such as beams of light from a lighthouse piercing thick fog.
By cutting the computing cost for creating highly realistic imagery from scratch, the UCSD computer scientists are helping to pull cutting edge graphics techniques out of research labs and into movies and eventually video games and beyond. The findings are being presented this week at Europe’s premier computer graphics conference, Eurographics 2008 in Crete, Greece on April 17.
This new work is part of a shift in the computer graphics, film, animation and video game industries toward greater realism through the use of “ray tracing algorithms.” Much of the realism in ray tracing technologies comes from calculating how the light in computer generated images would behave if it were set loose in the real world and followed the laws of nature.
At the heart of the new UCSD advance are computationally slimmed “photon mapping” algorithms, which are a subset of the ray tracing algorithms. The computer scientists found a way to collect all of the pertinent lighting information in computer generated scenes at once, which made the new photon mapping approach more lightweight than conventional photon mapping. This technique is especially good for creating smoky, foggy or cloudy scenes and producing images that do not have much unwanted visual noise.
“We took an algorithm that is already great and made it more efficient,” said Wojciech Jarosz, the first author on the new Eurographics paper and a Ph.D. candidate from the Department of Computer Science and Engineering at UCSD’s Jacobs School of Engineering.
This approach is an improvement upon the Academy Award winning photon mapping technique first developed by UCSD computer science professor Henrik Wann Jensen during his doctoral studies. Jensen is a co-author on this new Eurographics paper, along with UCSD computer science professor Matthias Zwicker. 
Antelope Canyon
The above picture from Antelope Canyon Navajo Tribal Park provides a real life example of the kinds of scenes that the new research can capture in a computationally efficient manner. The interplay between the dust in the air and the light pouring down from above creates the same smoky ambiance that Wojciech Jarosz creates in his cutting edge computer graphics research at UCSD’s Jacobs School of Engineering.
To date, ray tracing algorithms are primarily used in settings where ultimate realism is required and where heavy computation can be tolerated – such as offline environments that do not require real-time image rendering. An ice-cube-filled drink in the animated movie Final Fantasy is one example of photon mapping in the movies.
Computational constraints, however, have limited the use of photon mapping and other ray tracing approaches in places where speed and lightweight computation are crucial – such as video games. These domains have embraced an approach called rasterization, which is faster, but unable to easily simulate advanced lighting effects.
The new photon mapping approach from UCSD, and related advances, are poised to increase the reach of ray tracing algorithms – perhaps even into the domain of 3-D animation software for the general public and video games. The Larrabee chip that Intel is working on is just one indication that ray tracing technologies may play an increasing important role in consumer oriented graphics of the future.
Computerized Fog Costs 

Much of the richness in images created with photon mapping algorithms comes from precise accounting for the amount of light is in a scene and where that light is. Photon mapping algorithms provide a way to follow the light around the scene, as it bounces off various objects and lands on other objects. Photon mapping can also determine how light will interact with fog, smoke or other “participating media” that absorb, reflect and scatter some portion of the light – a task that has been traditionally quite computationally costly to perform because it requires sampling the light at many locations in order to make sure that nearly all the light is accounted for.
“Instead of computing the light at thousands of discrete points along the ray between the camera and the object, which is the conventional approach, we compute the lighting along the whole length of the ray all at once,” said Jarosz.
Photon mapping comparison image from UCSD
The same scene. The same image rendering time. Very different results. The noisy and pixilated image on the left  was created with the conventional “ray marching” photon mapping technique while the images on the right was created using the new “beam estimate” approach to photon mapping that is computationally more efficient.
To Movies, Then Milk 
This more efficient approach to photon mapping could be extended well beyond foggy and smoky scenes, because many materials, including skin, milk and plants, behave like fog or smoke, but on a more limited basis.
“Most natural materials behave like really dense fog because light penetrates them to a limited extent, so this work has a lot of potential future applications,” said Jensen, who published work in 2007 at SIGGRAPH on a graphics model capable of generating realistic milk images based on the fat and protein content. This research is pushing the field of computer graphics into the realms of diagnostic medicine, food safety and atmospheric science.
While photon mapping and other ray tracing algorithms that more closely mimic the natural world are making their way into movie special effects and animated films, Jarosz does not expect movies and video games to strictly follow the laws of nature.
“In live action movies, the lighting is incredibly controlled. If a character walks into a shadow, they will add light to the face even if you would never get that kind of light in a real shadow. The composition on the screen must tell the story and not distract the viewer. Realism doesn’t always matter. It’s the movies.”
Eurographics 2008 Paper: “The Beam Radiance Estimate for Volumetric Photon Mapping,”
.I 131
.T
document.131
.W
﻿When you see Sulley’s soft, blue fur in Monster’s University, you’d be forgiven for thinking you can reach out and touch it. It’s hard to imagine that only a few decades ago, animators were hand-inking plates for animated films and cartoons, or relying on stop-animation to create realistic effects. Now, the adventures of Sulley and Mikey can be realised in full, jaw-dropping 3D.

The birth of 3D animation was a long, drawn-out process and has cost billions and years to develop. James Cameron notably waited 20 years until 3D animation was sufficiently advanced before starting filming of his 2009 Avatar film. 3D is big business now and is constantly being advanced with every new released.

So how did CGI get to where it is today?

 

The early days

The first computer animated film was basic to say the least, but paved the way for what would become one of the most successful animation methods. Charles Csuri and James Shaffer’s simplistic Hummingbird was created in 1967 and featured a pre-programmed drawing of a hummingbird. An early computer generated more than 30,000 images for the animation.



Next up was Kitty in 1968, created by a group of Russian mathematicians. The enormous BESM-4 computer, which had only 45 bits of internal memory and was built using transistors, was used to create the animation. The bulky technology printed hundreds of frames, which were then converted into film, by use of a specially-created program.



It wasn’t until 1972 that what many consider as being the first ‘true’ computer animated film was created, by none other than one of the founders of GCI giant Pixar, Ed Catmull.

A Computer Animated Hand demonstrated the capabilities of computer animation by rendering a hand entirely in 3D graphics. The short film showed exactly how the effect was achieved – it was the acorn from which great oaks would grow.



 

On the big screen

The first ever instance of CGI in feature-length films came along in 1973, in Yul Bryner flick Westworld. Pixelated POV shots were created with CGI – by colour-separating each frame of footage and scanning it to be converted into the pixel effect. Colour was then added to complete the effect.



In the sequel, the 1976 film Futureworld, more CGI imagery was used. 2D compositing was employed to materialise characters over certain backgrounds. The previously-mentioned A Computer Animated Hand would make an appearance on the big screen, with the same technology being used for a face.



After this, wire-frame 3D animation was used in Star Wars Episode IV: A New Hope in 1977 and The Black Hole and Alien in 1979.

In 1982, Disney’s Tron would extensively use 3D CGI – for more than 15 minutes – to create special effects. The Light Cycle sequence would go on to become one of the most famous CGI scenes in animation history.



The 80s would see an increasing use of CGI, but it wasn’t until the 90s that CGI animation started to really come into its own.

 

The golden age of CGI

Terminator 2: Judgement Day in 1991 showcased exactly what CGI was capable of with pioneering multiple morphing effects for its partially computer-generated main character of the liquid metal, shape shifting T-1000.



Pixar, a subsidiary of Lucasfilm, presented its ground-breaking form of entirely GCI-rendered animation with the John Lasseter-fronted short The Adventures of Andre and Wally B, but it wasn’t until 1988 that the animation company started to make a buzz for its short Tin Toy.

The use of the cell shading and rendering in that short would be continued into the flagship CGI feature, Toy Story in 1995. Having been approached by Disney after the success of Tin Toy, Toy Story would put Pixar firmly on the map.



Thanks to technological advancements at the time and to the methods tried and tested in the films previously mentioned, Pixar was able to create a whole new world with character, depth and charm. Using a complex system of model articulation and motion control coding, each character required its own set of motion controls. Woody himself required 723.

Each shot went through a series of computer-run teams, including a render process completed by a set of 117 Sun Microsystems that had to run 24 hours a day to complete the film. The animation was finished at an average of around three minutes per week.

On the back of Toy Story’s success, a sudden surge in 3D-rendering software boomed. The next decade would see a wealth of progressively more complex CGI films appear – including Pixar’s second CGI film A Bug’s Life in 1998, Final Fantasy: the Spirits Within in 2001, The Polar Express in 2004, Chicken Little in 2005 and motion-capture CGI film Beowulf.

James Cameron’s decade-in-the-making magnum opus Avatar used an advanced version of previous CGI and motion capture techniques, at one point employing nearly 900 people to do so. In order to render the film, animators required 2,000 Hewlett-Packard servers, sporting 35,000 processor cores and 104 terabytes of RAM.

That’s a long way from the 45 bits of memory that created Kitty.

 

Where next?

With the promise of more CGI films in the near future, including The Smurfs 2 and Cloudy With a Chance of Meatballs 2 and 3D viewing technology taking huge leaps and bounds with every feature, there’s no sign that CGI animation has had its day.

From explosions to lighting effects, the use of computers to create film effects and animation offers so much more scope for the creation of brilliant cinematography. Who knows what kind of amazing things we can expect to see on the big screen next?
.I 132
.T
document.132
.W
﻿Computer generated imagery (CGI) is now so good that it's often impossible to tell what was filmed and what only ever existed inside a computer.

Game graphics aren't quite that good but they're getting close.

Starting from a 3D model of a scene inside a computer, complete with virtual lighting and a virtual camera, how does the computer render a realistic representation of the model on to the grid of pixels that make up the screen? It's not a simple problem, but there are a few solutions.

Probably the gold standard of computer graphics, used a lot these days in CGI, is a technique called ray tracing, which approaches the problem starting with the pixels. It begins by working out the path that a light ray would take coming from a pixel on the screen to a viewer in front of it. Then it just keeps following the ray backwards into the virtual world behind the screen, finding the closest object in the model that lies along the ray. The pixel gets the colour of that object because that's what the viewer would see if the model really existed on the other side of the screen.

The colour of the object depends on the light falling on it, which in turn depends on the lights in the scene, the colour and transparency of the object itself and reflections and shadows from other objects. So the computer traces additional rays from the source of the first one to discover what the lighting situation is before it colours the pixel on the screen. If there's a lot of reflections and other effects then a lot of rays will be bouncing back and forth.

All this ray tracing can take a long time. That's OK if you're making a movie and can spend hours behind the scenes rendering each second of final footage, but to render interactive graphics in real-time for games there are quicker approaches. The main one is rasterisation, which starts with the model instead of the pixels.

The model in this case is made up of lots of triangular surfaces. Even curved surfaces are approximated by lots of little triangles stitched together. Using a bit of trigonometry to take perspective into account, and taking care not to draw distant triangles over near ones, each triangle is projected on to the two dimensional screen and the corresponding pixels are coloured. Rasterisation takes a less disciplined approach to working out the actual colour of the surface, using a big bag of tricks to approximate the effects of lighting, transparency, reflections and so on.

There are other approaches, too, and its even possible to blend these and other techniques in hybrid graphics systems. But ray tracing and rasterisation have emerged as key technologies in the computer graphics world.

Rasterisation is very fast, but it has many limitations which stop it reaching the photorealism of ray tracing. Photorealism is not always the goal, of course, but real-time ray tracing is just possible at present and as technology improves it is bound to eventually usurp rasterisation, even in games
.I 133
.T
document.133
.W
﻿What is Computer Graphics? 
Cornell University Program of Computer Graphics	 Cornell Seal
The term computer graphics includes almost everything on computers that is not text or sound. Today almost every computer can do some graphics, and people have even come to expect to control their computer through icons and pictures rather than just by typing.
Here in our lab at the Program of Computer Graphics, we think of computer graphics as drawing pictures on computers, also called rendering. The pictures can be photographs, drawings, movies, or simulations -- pictures of things which do not yet exist and maybe could never exist. Or they may be pictures from places we cannot see directly, such as medical images from inside your body.

We spend much of our time improving the way computer pictures can simulate real world scenes. We want images on computers to not just look more realistic, but also to BE more realistic in their colors, the way objects and rooms are lighted, and the way different materials appear. We call this work "realistic image synthesis", and the following series of pictures will show some of our techniques in stages from very simple pictures through very realistic ones.

Object Rendering

  
Computer graphics uses several simple object rendering techniques to make models appear three-dimensional.

Shading

   

Shading techniques extend the realistic appearance of objects and introduce features such as transparency and textures.

Color

 
Computers don't create color exactly the way we see it.

Ray Tracing

Reflection and Transparency
 

The best way to appreciate how far these simple techniques have been developed is through much more complex (and more recent) Cornell computer graphics images

Radiosity

Why Radiosity?
   

Most surfaces are diffuse, not shiny, and ray tracing does not correctly depict how light reflects from diffuse surfaces. Our laboratory has played a major role in developing radiosity techniques for more realistic and more physically accurate rendering.

Quality of Light

   

Our research image sampler shows more current work in radiosity and other techniques.
.I 134
.T
document.134
.W
﻿Semcon supports Volvo Cars with a large number of digital images for the use on their global website.

 

Challenge
Volvo Cars needed to make a change in their processes for creating images for marketing purposes. Shorter product development lead times, limited access to pre-production vehicles and high costs for photo vehicles were all reasons accentuating the need for this change.

Solution
After a proof of concept project, Semcon now uses its proprietary tool Illuminator to prepare and standardize data for digital 3D models in a solution called ‘Digicars’. Using CAD data straight from the R&D department as input, Digicars contains the digital resources required to describe all Volvo Car’s models and all available visible options and features.

The 3D data in Digicars can be reused for both marketing and aftermarket assignments. From just a few test images the number of CGI images produced for Volvo Cars has increased and today Semcon produces some 150 000 digital images, animations and films annually. Use of these images span internal product presentations, launch films, campaigns, advertising, press releases, brochures, owners and parts information just to name a few.

Result
By shifting to CGI, Volvo Cars has gained from;

reducing the need for physical vehicles,
significantly reducing lead times, and
retained or even improved image quality.
At the same time Volvo Cars has succeeded in decreasing the costs per image dramatically, to about a fifth of the earlier used traditional approach. The great benefits of using CGI has led to Volvo Cars today using a majority computer generated 3D renditions for publishing on the web as well as a large portion of images for printed publications.

Illuminator is Semcon’s proprietary visualisation tool. It can handle a multitude of CAD formats as input data, and use this input for creation of repair methods or illustrations. With Illuminator, Semcon can make sure we deliver top quality information products at low cost and with short lead time.
.I 135
.T
document.135
.W
﻿While I don’t have the problem with CGI that some people do, there are days (and movies) that have me wishing filmmakers would just cut back on it. That said, there are other movies that use it in a truly legitimate way. Smaller movies like Mirrormask are able to bring wild dreams to the screen on a tight budget, and bigger movies like The Dark Knight mix CGI with practical effects to evoke a subtly heightened reality.

And then there are people who put CGI right smack in the middle of the shot and we never notice it. Or I don’t. Well, I do, but only after I have it pointed out to me by a director commentary or something. MOVING ON.

Here are five examples of CGI that totally fooled me. Spoilers ahead. Not obscure ones, but still.

The rat from The Departed

httpv://www.youtube.com/watch?v=V3f9UJTmgd0#t=1m4s

Yeah, okay, this is a minor thing. But I never would have guessed that they couldn’t get a real rat to just run across a porch railing like that. I’m sure there’s a perfectly logical reason why that thing had to be put in later with a computer, but I haven’t done enough digging to find out. But anyway, it looks real to me.

Doc Ock sinks in Spider-man 2

httpv://www.youtube.com/watch?v=hrOMpaoylbY#t=7m27s

I guess it would have been a little much to ask Alfred Molina to drown himself, just for the sake of a superhero movie. It’s a good thing the wizards behind the computers were up to the challenge. It’s impressive to pull off a ton of nutty action scenes, but slow, dramatic ones present their own challenges. Just look at that shot — how many synthesized extreme closeups do we get that actually work? The only other attempts that spring to mind are in The Matrix Revolutions, and those don’t even come close to Ock’s departure.

C3PO’s plating in Attack of the Clones

httpv://www.youtube.com/watch?v=nSY4QLpYKN0#t=11m10s

I literally just found out about this about a month ago, and it’s what initially sparked the idea for this post. Apparently the original version of Attack of the Clones included a scene in which C3PO was finally given his outer coverings, but it got nixed in the editing process. Unfortunately, Lucas had already shot the bits with a skeletal C3PO in them (I would assume that it’s primarily the first couple of Tatooine scenes). So he got the guys at ILM to simply put a digital C3PO over the original footage, and bam. Fooled me for almost ten years.

Zodiac

httpv://www.youtube.com/watch?v=TT491ctM8Kk

It’s gotta be hard to shoot a convincing period piece. Nothing we use today – cars, streets, lampposts – looks exactly like it did thirty years ago. Most moviemakers will rent out some old cars, dress up a couple buildings, maybe drop in an artificial background, and call it a day. Most moviemakers aren’t David Fincher. His repsonse to the challenge of making a historically accurate movie set in 1970s San Francisco was to basically rebuild the whole damn city in a computer. You wouldn’t think a quiet police thriller like Zodiac could be called a visual effects extravaganza, but once you watch them break down the effects that went into it there’s almost no other way to put it.

Spidey dodges bats in Spider-man

httpv://www.youtube.com/watch?v=7GAXZDl0WKA#t=1m9s

And we’re back to Spider-man, this time from the first movie. The shot in question is the super slow-mo shot where we see Spidey dodging a series of the Goblin’s razor bats. Obviously the bats are CG, but I still have trouble coming to terms with the fact that Spider-man is, too. I’m not entirely sure why it was necessary to do it this way. My best guess is that moves like the 360-degree flip he does at the beginning of that shot were too precise to be pulled off by a stuntman. Whatever the reason, I’m pretty sure I saw this movie five times before I found that out, and I still almost don’t believe it.

Any great ones that I missed? Obviously, the theme of the post leaves the possibility wide open. List your favorites in the comments.
.I 136
.T
document.136
.W
﻿Computer graphics have greatly expanded the possibilities of cinema. Special effects using CGI (computer-generated imagery) today enable directors to shoot scenes that were once considered impossible or impractical, from interstellar combat to apocalyptic action sequences to fantastical digital characters that realistically interact with human actors.

In science, computer graphics are also creating sights that have never been seen before. But where movie special effects artists are realizing the vision of a screenwriter and director, scientific computer models are inspiring new discoveries by revealing a restless molecular world we cannot yet see with the naked eye.

Using computers to peer into this hidden universe was the theme of CI faculty and senior fellow Gregory Voth's Chicago Council on Science and Technology talk last week, titled Molecular Modeling: A Window to the Biochemical World. Scientists at Voth's Center for Multiscale Theory and Simulation use computers to recreate real-world physics and produce awe-inspiring, intricate images, pushing the frontiers of discovery one femtosecond and nanometer at a time.

[Some of those images, including the one above by Mijo Simunovic, were on display as a "Science as Art" gallery, which you can view in a slideshow here.]

"The computer simulation allows us to make a movie, if you will, but it's a movie describing what the laws of physics tells us," Voth said. "It's not a movie where we tell the computer we want this figure to run and shoot this figure. We don't know what's going happen. We know the equations, we feed them in [to a supercomputer], and we solve those equations…and we can reach scales we never dreamed of reaching before."

Those equations are Newton's laws of motion and quantum mechanics, applied in a molecular dynamics model to simulate the activity of individual atoms. For a single molecule of water, this would only require calculating the equation for three atoms. But to simulate a volume of thousands of water molecules, or a protein made up of millions of atoms, or thousands of those proteins, an incredible number of calculations must be done at every time step of the model. An increment, Voth said, that is usually a single femtosecond, or one-millionth of a nanosecond.

If the technical demands can be met, these simulations can unlock a flood of previously inaccessible information for chemists and biologists. While laboratory methods can produce still images of proteins in various states, molecular simulations can create living animations of the transitions between those states, or how they interact with other proteins or the surrounding environment. That additional insight allows scientists to study subjects such as the HIV virus, cell membranes, actin filaments or ATP hydrolysis in unprecedented detail.

In the CMTS, Voth and his collaborators are looking for ways to increase the complexity of these models without pushing them beyond the point of practicality on today's supercomputers. Through a method called coarse-grained modeling, proteins aren't reduced all the way to their constituent atoms, but instead to "beads" that aggregate the activity of several atoms, requiring fewer calculations and less computational power.

"What this does for you, if you do it well, is it's a bridge," Voth said. "It's an intermediate bridge between the molecular world and the mesoscopic world, and it's dramatically more efficient to solve the equation behind this to push up into the scale model and finish the data."

As an example of molecular modeling's real world potential, Voth used a project with post-doctoral scholar John Grime on HIV that was featured on ScaleOut last year. Voth and Grime are constructing a model that simulates the construction of the HIV capsid, a key step in the virus' maturation that encloses its genetic material in a protective "suit of armor." Their current coarse-grained model is not yet powerful enough to build the complete capsid, but can form "pieces of its shell" that reveal important building blocks – trimers of dimers – that are a promising target for drug makers.

Eventually, Grime and Voth hope to build a model that simulates an entire HIV virion, allowing for even more in-depth study of its behavior and weaknesses. Similarly, computational biologists hope to build models of living cells and molecular engineers are using computer models to find new ways of building nano-scale materials for energy storage and other uses. While ever more powerful supercomputers will be crucial to running these models, the people designing smarter and more accurate ways of simulating cellular processes are even more important, Voth said.

"We've come a long way. It didn't come just from faster computers," Voth said. "It came from a combination of ideas, theory and statistical mechanics. Put all that together with our powerful computers, and we can do all of these beautiful things."
.I 137
.T
document.137
.W
﻿Computer graphics means drawing pictures on a computer screen. What's so good about that? Sketch something on paper—a man or a house—and what you have is a piece of analog information: the thing you draw is a likeness or analogy of something in the real world. Depending on the materials you use, changing what you draw can be easy or hard: you can erase pencil or charcoal marks easily enough, and you can scrape off oil paints and redo them with no trouble; but altering watercolors or permanent markers is an awful lot more tricky. That's the wonder of art, of course—it captures the fresh dash of creativity—and that's exactly what we love about it. But where everyday graphics is concerned, the immediacy of art is also a huge drawback. As every sketching child knows too well, if you draw the first part of your picture too big, you'll struggle to squeeze everything else on the page.... and what if you change your mind about where to put something or you want to swap red for orange or green for blue? Ever had one of those days where you rip up sheet after sheet of spoiled paper and toss it in the trash?

Photo: Oil paints like these can produce magical results in the right hands—but only in the right hands. Thankfully, those of us without the talent and skill to use them can still produce decent everyday art with computer graphics.

That's why many artists, designers, and architects have fallen in love with computer graphics. Draw a picture on a computer screen and what you have is a piece of digital information. It probably looks similar to what you'd have drawn on paper—the ghostly idea that was hovering in your mind's eye to begin with—but inside the computer your picture is stored as a series of numbers. Change the numbers and you can change the picture, in the blink of an eye or even quicker. It's easy to shift your picture around the screen, scale it up or down, rotate it, swap the colors, and transform it in all kinds of other ways. Once it's finished, you can save it, incorporate it into a text document, print it out, upload it to a web page, or email it to a client or work colleague—all because it's digital information. (Find out more about the benefits of digital in our main article about analog and digital.)
.I 138
.T
document.138
.W
﻿A Dartmouth College-led study shows that people find it increasingly difficult to distinguish between computer-generated images and real photos, but that a small amount of training greatly improves their accuracy.
The findings, which have implications for the legality and prosecution of child pornography, appear in the journal ACM Transactions on Applied Perception.
As 3-D rendering software and hardware become more powerful, the computer-generated characters they create for film making, video games, advertising and other venues have become more photo-realistic. But the drive to create virtual characters that are indistinguishable from human characters has also given rise to complex forensic and legal issues, such as the need to distinguish between computer-generated and photographic images of child pornography, says senior author Hany Farid, a professor of computer science and a pioneering researcher in digital forensics at Dartmouth.
"As computer-generated images quickly become more realistic, it becomes increasingly difficult for untrained human observers to make this distinction between the virtual and the real," Farid says. "This can be problematic when a photograph is introduced into a court of law and the jury has to assess its authenticity."
Real or virtual: Dartmouth scientists ask -- can we tell the difference?
A Dartmouth College study shows that people find it increasingly difficult to distinguish between computer-generated images and real photos, but that a small amount of training greatly improves their accuracy. Credit: Dartmouth College
Legal background:
In 1996, Congress passed the Child Pornography Prevention Act (CPPA), which made illegal "any visual depiction including any photograph, film, video, picture or computer-generated image that is, or appears to be, of a minor engaging in sexually explicit conduct."
In 2002, the U.S. Supreme Court ruled that the CPPA infringed on the First Amendment and classified computer-generated child pornography as protected speech. As a result, defense attorneys need only claim their client's images of child pornography are computer generated.
In 2003, Congress passed the PROTECT Act, which classified computer generated child pornography as "obscene," but this law didn't eliminate the so-called "virtual defense" because juries are reluctant to send a defendant to prison for merely possessing computer-generated imagery when no real child was harmed.
In their new study, Farid's team conducted perceptual experiments in which 60 high-quality computer-generated and photographic images of men's and women's faces were shown to 250 observers. Each observer was asked to classify each image as either computer generated or photographic. Observers correctly classified photographic images 92 percent of the time, but correctly classified computer-generated images only 60 percent of the time.
In a follow-up experiment, the researchers found that when a second set of observers was provided some training prior to the experiment, their accuracy on classifying photographic images fell slightly to 85 percent but their accuracy on computer-generated images jumped to 76 percent.
With or without training, observers performed much worse than Farid's team observed five years ago in a study when computer-generated imagery was not as photo-realistic.
"We expect that as computer-graphics technology continues to advance, observers will find it increasingly difficult to distinguish computer-generated from photographic images," Farid says. "While this can be considered a success for the computer-graphics community, it will no doubt lead to complications for the legal and forensic communities. We expect that human observers will be able to continue to perform this task for a few years to come, but eventually we will have to refine existing techniques and develop new computational methods that can detect fine-grained image details that may not be identifiable by the human visual system."


Read more at: http://phys.org/news/2016-02-real-virtual-scientists-askcan-difference.html#jCp
.I 139
.T
document.139
.W
﻿Throughout this book we have seen many examples of CGI scripts generating dynamic output. However, in almost all cases, the output has been HTML. Certainly this is the most common format your scripts will generate. However, CGI scripts can actually generate any type of format, and in this chapter we will look at how we can dynamically generate images.
Generating images dynamically has many uses. One of the most common is to generate graphs. If you have a data source that is continually changing, such as the results of an online survey, a CGI script can generate a graph that presents a visual snapshot of this data.
There are also times when generating images dynamically makes less sense. It is much less efficient to generate an image dynamically than for your web server to serve the image from an image file. Thus, just because some of these tools allow you to generate really cool graphics dynamically doesn't mean you must use them only in a dynamic context. Unless the images you generate are based upon data that changes, save the image to a static file and serve that instead.
This chapter presents a broad overview of the different tools available for generating dynamic images online, and includes references with each for finding more information. The goal of this chapter is to explain techniques for generating images dynamically and familiarize you with the most popular tools available to you. A full description of many of these tools along with others is available in a book of its own, Programming Web Graphics with Perl and GNU Software by Shawn Wallace (O'Reilly & Associates, Inc.).

.I 14
.T
document.14
.W
The Forgotten History Of CGI

The roots of CGI lie in the first mechanical aids to drawing and painting. The earliest of these were developed to help solve a problem every artist has found to be sticky: perspective.

Before the introduction of geometric perspective, the realistic depiction of nature was not one of the purposes of art. Instead, artists chose the size and position of objects in a picture by their relative importance to one another. A distant castle might appear to be larger than one in the foreground simply because it was considered more important.

Italian artist Filippo Brunelleschi (1377—1446) created the rules of perspective in the early fifteenth century. His breakthroughs led artists to portray the world as it really looked to the human eye. Some artists, such as Albrecht Durer (1471—1528) of Germany, even went so far as to make special tools to help them create mathematically perfect perspective drawings. These were perhaps the first mechanical devices to be used to create art.

Most artists quickly adapted these new technologies to create their artwork. In the ensuing centuries they have used all sorts of machines to make the creation of art easier. The pantograph, for instance, is a simple mechanical device that enlarges or reduces a drawing. Pantographs are not only still used by artists today, they have wide applications in modern industry as well.


Artists also use a camera obscura ( "dark room" in Latin). The earliest of these were full-size, light-tight rooms with a small hole in an outside wall. Visitors would see an image of the surrounding landscape projected onto the opposite wall. Artists used this concept in a different way. They reduced the room to a small box with a tiny pinhole in one side and a white screen opposite to it. When the light from a scene or model passes through the pinhole, an image is projected onto the screen. The artist can then easily trace the image. It's still a valuable tool used by many artists today (who usually shorten the name to "lucy").

The camera lucida eventually evolved into what we know today as just...

The Camera

Occasionally, an innovation is not met with such widespread enthusiasm. After the invention of photography in the early nineteenth century, painter Paul Delaroche said that photography "completely satisfies art's every need." By this he meant that a photograph could do anything an artist could, so painters would become useless.

Delaroche reflected the feelings of many academic painters, who supported themselves by making highly lifelike paintings: portraits, landscapes, historical scenes, and so forth that pleased their rich patrons. The camera could capture scenes with an accuracy that even the finest painter could not achieve. Photography was also cheap and could be done by anyone.

Many artists, though, quickly realized the possibilities of photography, looking at it not as a rival but as an ally. For example, Eugene Delacroix (1798—1863) studied the human body by using photographs of the nude. He also worked from photographs of models when making drawings and paintings.

Many other artists began doing this too since photos were much easier than living models, who not only might move while posing but also charged for their time. (Eadweard Muybridge made this into a science, in the process laying the foundation for motion pictures...but that's another story.)

Meanwhile, other artists found it advantageous to let photography take over the dull depiction of reality. It freed them to explore other realms of color, light, and composition. Impressionism and other schools of art that sprang up at the end of the nineteenth century might have been delayed by decades, if not longer, if not for the liberating influence of photography.

The airbrush was another transformative mechanical innovation. Invented in 1879 by Abner Peeler, the airbrush uses compressed air to create a jet of very fine paint particles. By adjusting the amount of air pressure and the amount of paint, artists can create soft lines and shapes and blend colors together smoothly. The airbrush also creates incredible lighting effects. Although a very valuable tool, the airbrush has taken a great deal of abuse. Traditional painters often consider it a form of cheating.

Many professional artists dislike that non-artists can easily create beautiful effects with an airbrush. Unfortunately, the result is often beautiful effects but very bad art. Airbrush art soon became associated— unfairly perhaps—with cheap, gaudy, amateur artwork. Although it quickly became one of the most important tools of modern artists working in advertising and illustration, most other artists scorned it.

The Computer

The early computers of the late 1940s and 1950s output data through typewriter-like devices. This was usually in the form of columns of numbers and letters. Artist realized these letters and numbers could be seen as areas of light and dark. For instance, an m or x looks darker on the page than an o, i, or dot. Pictures could be created if users fed the right numbers into the computer.

By using combinations of many different characters, users could create complex and surprisingly realistic images. The process was very similar to the way black-and-white photos are reproduced in newspapers, magazines, and books. The photo is broken up into tiny dots. The size of the dot determines how dark it is. Small dots have a lot of white around them and look lighter, while larger dots make a space look darker.

A plotter is another device that creates images with the computer. It is a pen that the computer moves over a sheet of paper in two directions: up and down and back and forth. By combining these two motions, users can make the computer draw complex curves. Plotters can produce very detailed work, as well as work of very large dimensions. People soon realized that computers could be used to make curves and graphs that were visually appealing. Thus, the computer might be a tool for creating art.

The First Computer Art

The first tools used to make electronic art—a predecessor to digital art— were originally designed for testing sound equipment. The company that eventually became Hewlett Packard developed the first of these products, an audio oscillator. This instrument creates one pure tone, or frequency, at a time. The waves that this tone produces can be displayed on the screen of an oscilloscope. The patterns on the oscilloscope screen give scientists and engineers information about the wave and its source.


Ben Laposky, an artist and mathematician from Cherokee, Iowa, realized that by changing the input he could create patterns of his own design. In 1950 he created the first graphic images made by an electronic machine. Laposky captured his electronic oscilloscope imagery by photographing it onto high-speed film. He called them oscillons and electronic abstractions.

Meanwhile, the Viennese artist Herbert W. Franke also created electronic images. Franke's images were similar to those of Laposky's but reflected his own artistic sensibilities and goals. Franke eventually wrote the first book on digital art: Computer Graphics-Computer Art (1971).

John Whitney Sr., who studied music and photography, closely followed Laposky's and Franke's work. In the 1940s, Whitney created an experimental film with his brother James that won first prize at a film festival in Belgium. His work in 1955 as a director of animation at the famous UPA cartoon studios led him to a partnership with Saul Bass. Together they created the title sequence for the Alfred Hitchcock film Vertigo (1958), as well as graphics for television shows.

In 1960 Whitney founded Motion Graphics Incorporated. The company used a computer to produce motion picture and television sequences and commercials. Whitney had built the computer himself from war-surplus electronics. Gradually it evolved into a huge machine that towered 12 feet (3.6 meters) high. Whitney continued to perfect his computer and the effects it created.

In 1961 Whitney produced a seven-minute color film called Catalog. In this film, he showed all the effects he had perfected with his homemade computer. Whitney achieved worldwide recognition for his work with the analog computer. In 1966 IBM awarded him the company's first artist-in-residence status, allowing him to freely explore the potential of computer graphics.

The First Digital Artists

In 1969 German artist Manfred Mohr turned from traditional painting to the computer. He worked on variations of the cube, which he distorted and transformed endlessly. Mohr worked only in black and white, using a plotter to print his work. In 1971 the Musee d'Art Moderne de laVille de Paris gave him a one-man show. It was the first such honor from any museum for a computer artist.


Larry Cuba is a widely known pioneer of computer animation. He created his first film, First Fig, in 1974. Computers capable of digital art were not easy to come by at that time. So Cuba joined with computer scientists at the National Aeronautics and Space Administration's Jet Propulsion Laboratory in Pasadena, California. In 1975 John Whitney Sr. invited Cuba to work with him on the movie Arabesque. Later films, such as 3/78 (Objects and Transformations) (1978), Two Space (1979), and Calculated Movements (1985) have been shown all over the world.


Lillian Schwartz pioneered the use of computers in graphics, film, video, animation, special effects, virtual reality, and multimedia. Her work was the first in the new medium of computer-aided art to be bought by the Museum of Modern Art in New York. The museum used her sculpture, Proxima Centauri, in its 1968 Machine Exhibition.

Independently and in collaboration with scientists at Bell Labs, Schwartz later developed ways to use computers in film and animation. Her award-winning films—such as Mirage (1974)—have been shown all over the world.

Yoichiro Kawaguchi, one of the leading international computer artists, originally teamed up with computer scientists. With their help, he developed art using metaballs. This technology, invented by Jim Blinn, created soft, fluid, organic shapes. Before this, most computer artists were limited to hard-edged geometric shapes. The patterns Kawaguchi found in natural forms, such as seashells and plants, inspired him. He won many international honors and awards for his art and animation.

Ed Emshwiller is mostly famed as a science-fiction illustrator. He was also a highly respected video artist and dean of the School of Film/Video at the California Institute of the Arts in Valencia. He helped influence the experimental film movement in the 1960s. Many of his films, including Thanatopsis (1962), Totem (1963), Relativity (1966), and Three Dancers (1970), received awards and screenings at film festivals in cities around the world. He was quick to embrace digital technology in the creation of films like Sunstone (1979).

In 1987 Emshwiller created Hungers, an electronic video opera, for the Los Angeles Arts Festival. Hungers combined live performance and interactive devices that changed the sound of the music according to the environment. No two performances were exactly alike.

Fractals

Another major advance in digital art occurred when mathematicians discovered fractals. While fractals involve complex math, the basic concept is simple.

Start with an equilateral triangle. Divide one side of the triangle into three equal parts, and remove the middle section. Replace it with two lines the same length as the section you just removed. Do this to all three sides of the triangle.

The result will be a six-pointed star. Do this again with the twelve new sides you've created. And do it again and again . . . The resulting figure is called a Koch snowflake, after the Swedish mathematician Helge von Koch, who first described it in 1904.

.I 140
.T
document.140
.W
﻿A.1 Introduction

Why does my HTML page/form need a script?

There are times when you might want to have some dynamic information (information that is not constant) in your HTML documents. This could include simple information such as the date and time, or a counter that displays "You are visitor number xxx", but it could also include such things as pie charts/graphs based on user input, results from searching a database, or animations. And the only way you can produce results like these is with CGI scripts (though you can also do so with client-side applications like Java and JavaScript, but that's a totally different story!).

What does CGI stand for?

Here is an excellent description that my editor, Andy Oram, wrote up:

Common
Assures you that CGI can be used by many languages and interact with many different types of systems. It doesn't tie you down to one way of doing what you want.

Gateway
Suggests that CGI's strength lies not in what it does by itself, but in the potential access it offers to other systems such as databases and graphic generators.

Interface
Means that CGI provides a well-defined way to call up its features--in other words, that you can write programs that use it.

What is a script, anyway? What can I do with a script?

Simply put, a script is a program! OK, OK, there are semantic differences between the two words. If you really want to know, pick up a book on computer programming (or is that computer scripting :-)

You can create a lot of magic by writing a CGI program/script. You can create graphics on the fly, access databases and return results, and connect to other Internet information servers.

What is Perl and why do so many people use it for CGI?

The answer is located in the first three lines of the Perl manpage:

Perl is an interpreted language optimized for scanning arbitrary text files, extracting information from those text files, and printing reports based on that information.

Most CGI applications involve manipulating data in some fashion and accessing external programs and applications. Perl provides easy-to-use tools that make these tasks a cinch.
.I 141
.T
document.141
.W
﻿It depends what your goal is. If you want to become a developer then you need to read books about programming. I would recommend for that a book or two on OpenGL. You can then experiment with a lot of different techniques (implement them), rendering, modeling, animation, etc. Another "generic" book is Computer Graphics Principles and Practice. This is a good book and a good introduction. Everything else is really specialized (search for PBRT in Google for rendering for example, the book Physically Based Rendering).

If you are looking to be an artist, then you should probably get a few books on using Maya or Blender. There's also some good websites around (Fx Phd, Gnomon, etc.) but they are not free. Scratchapixel is but as you said, it's not finished (btw it's not supposed to be only about rendering, but they don't have the time to work on anything else right now, since this initiative relies on people writing content of their free time).

If you want to be hired as an artist, practice is the best solution. There's tons of tutorials on the web, so get something like Blender or a student version of Maya (free) and try to create content on your own. While I think it's better for new comers to learn a proper programming langage such as C++, Python is also popular among artists and in studios, so maybe you can learn that as well (write script in Python in Maya).

Good luck. It's better to be passionate to get in this industry, as it is quite saturated right now, and wages are far from being good, to the contrary of what many people seem to think (see the recent scandal about the agreement between big studios Disney-ILM-Pixar on artist's wages). Not a very reliable industry. You should also think about game studios.

However, despite all this, CG rocks!

.I 142
.T
document.142
.W
﻿How Programmers Freed Hollywood
160
Shares
 76 20     
10 min read
In Disney’s 1982 film Tron, software engineer Kevin Flynn is teleported inside a computer by the evil supercomputer Master Control Program. The camera pans over an endless arena with geometric 3-dimensional floating objects above a white grid. Surrounded by a neon-etched digital world, Flynn looks around and whispers in disbelief: “Wow.”  At the push of a button, a laser rod appears in front of Flynn and he grabs the ends like handle bars. Within a split second, he’s propelled forward and inside a digitized Tron Lightcycle, battling two warriors in an endless maze. Voracious sounds of zooming cars are blaring.
This classic Tron Lightcycle scene was a phenomenal technological achievement in cinema. It marked the first extensive use of computer-generated imagery (CGI) illustrating the background, objects and movement in a feature film. For at least 15 minutes, Tron offered a glimpse into an unnatural world of boundless imagination and altered the way we visualized the world forever.
But who was the first to envision this new world and how did he push the limits that bring mind-bending innovations that pioneered the way to our favorite Hollywood films today, like Avatar, Transformers, Interstellar and countless other computer-generated masterpieces?

.I 143
.T
document.143
.W
﻿Applicants to this programme are numerate and logically-minded, and it is likely that they will have previously studied engineering, computer science, maths or physics. They would be interested in computer graphics for games or CGI and visual effects. Graduates would seek employment in both the games and film VFX industries as game developers, animation tool developers, visual effects developers, technical directors, etc.

This programme will equip students with skills at a high academic level and also crucially enable them to practically implement their knowledge because of the ‘hands-on’ emphasis of the programme.

The main themes of the programme are:

 Current and emerging algorithms and techniques used in film visual effects and games programming
Approaches used to generate off-line visual effects
Approaches used to generate real-time interactive games
 The first theme develops in the student the necessary skills required to implement algorithms and techniques used to generate realistic scenes. These concepts will be explored in detail.

The second theme addresses the need for students to identify, evaluate and implement suitable methods to solve specific problems related to creating off-line visual effects.

The third theme recognises the need to solve these problems using approaches optimised for real-time computer games development and develops in the student the requisite skills. 
.I 144
.T
document.144
.W
﻿. What is augmented reality?
Augmented reality is a way of fusing the real and the virtual world by overlaying digital data on to real-world analogue views. Augmented reality applications are appearing in products as diverse as T-shirts on fashion cat walks, interactive games, CVs designed literally to speak to the future employer and jobseeking tools.

And what’s more, anyone with a mobile phone or laptop with built-in video capability can augment and extend their reality with easy-to-use applications. 
2. How does it work?
Applications generally use one of two approaches: marker-based and location-based.

Markers work by having software recognise a particular pattern, such as a barcode or symbol, when a camera points at it, and overlaying a digital image at that point on the screen. If the image is three-dimensional or animated, the effect is of a digital experience unfolding on the surface upon which the pattern is printed.

Location-based applications use the ability of a particular device to record its position in the world and then offer data that’s relevant to that location: finding your way around a city, remembering where you parked the car, naming the mountains around you or the stars in the sky.
3. What’s different about developing augmented reality applications?
Most augmented reality applications rely on superimposing either 3D-generated computer imagery or some form of descriptive knowledge over the real-time images obtained through a camera, webcam or phone. This requires a good understanding of image processing and computer vision techniques, mainly for tracking either markers or the natural features on which this imagery is superimposed.

Computer-generated imagery has to look realistic and be properly aligned with the real environment in order to create an authentic impression. Most of the applications are designed for the general public so a good understanding of intuitive user interfaces is also required to provide a seamless experience.
4. What other skills do you need?
AR developers chiefly need a mixture of advanced computer vision skills, 3D modelling and desktop, web or mobile programming. A grasp of 3D modelling should include texturing, shading and rendering.

Preferred programming languages can vary according to the platform but are usually C++ and C#.

Last, but not least, the bleeding-edge nature of the field means that would-be AR developers should have a passion for pushing the boundaries of new technologies. Keeping abreast of new research in the field is a must - a lot of the technologies come from university-based R&D projects. 

Search for C++ jobs
Search for C# jobs
5. Are there any AR platforms to work with?
The Dutch-based company Layar has a platform, or augmented reality browser, that runs on the iPhone 3G and Google’s Android. Layar works by using a combination of the mobile phone’s camera, compass and GPS data to identify the user’s location and field of view, retrieve data based on those geographical coordinates, and overlay that data over the camera view.
Qualcomm has also unveiled a new software development kit for the Google Android operating system that will make it easier for developers to create new augmented reality apps for devices running Google’s mobile operating system.
6. How can you get into AR?
One of the simplest ways is to develop for an existing platform such as Layar is to join the thriving community of developers busy utilising the browser to deliver functionality.

C2K is one such developer with its Conquar game, which handles most of the game engine - usernames and logins etc - on the C2K server. Developers code in JavaScript Object Notation (JSON) to the platform and Layar is then responsible for making it display on the iPhone and Android phones.

Through the API of Layar and JSON, developers can make use of the triggers such as a web view and also place action buttons such as watch video, listen to audio and call a phone number. This kind of data is provided with PHP. 

Search for Java developer jobs
7. Where’s AR going to be big?
The world of retail is one sector with myriad opportunities for augmented reality applications, especially online. Here, the lack of the ‘try-on’ phase before buying for many products including fashion, jewellery, watches, glasses and home products is an incentive for companies to try out augmented reality applications.

Holition is one augmented reality retailer offering these real-time try on opportunities. This can be combined with providing extra information for the products being displayed.
8. What about education?
The technology offers many opportunities to support experiential and location-based learning by layering data and information on top of the real-world.

Adding historical context to a particular place, highlighting geometric shapes and hidden angles in buildings are just a couple of examples of ways that lessons could be brought to life.

The explosion in popularity of mobile phone apps offers hundreds of possibilities for educators to bring AR into the classroom with relative ease. Apps like Pocket Universe provide star maps relative to your location and offer educators the opportunity to bring objects that are traditionally seen 'out there' right into the classroom.
9. What’s the future for augmented reality?
Perhaps the biggest innovations will come when we step away from the screen. At the moment the majority of AR applications use a camera and screen of some kind, and while the effects are often spectacular, the screen still acts as a barrier.
10. Any other uses?
AR has been around for a long time. One of the oldest examples is the double exposure technique by which the impression of a ghost can be created on stage. The military also equips pilots with goggles that provide a layer of radar data over the real-world view to enable them to target missile attacks.
.I 145
.T
document.145
.W
﻿hat Does Visual Effects Mean?

Visual effects is the process of creating imagery outside of live action shoots. This imagery is typically either too elaborate or even dangerous to create for or capture on film. Some visual effects (also called F/X or VFX) combine live action and say, computer generated imagery, while others are totally computer generated. Some of the most celebrated VFX scenes can be seen in films such as The Dark Knight (2008), Iron Man (2008), Titanic (2007), and Pirates of the Caribbean: Dead Man’s Chest (2006). 

Coursework for Visual Effects Programs

Visual effects degree programs are readily available at art schools, technical schools, and specialty schools, but did you know that many traditional schools also offer degrees in this area? Not only this, but aspiring visual effects artists have several degree types and levels to choose from including a B.A., B.F.A., B.S., M.A., and even an M.F.A. in visual effects.

Visual effects is such a specialized field that (very) specific skills are needed in order to have a successful career. For starters, aspiring visual effects artists must have advanced knowledge of most F/X and other software programs because many productions require the use of multiple programs to achieve the desired effect. Just a few of the programs used in the industry include Maya, Matchmove, Mudbox, XSI, Nuke, PRman, Shake, Movimento, and Lightwave 3D. Many VFX studios use custom software, so aspiring VFX artists must also have the ability to catch onto new programs quickly. Fortunately, required coursework for visual effects programs includes instruction in common VFX software and other computer programs.

Visual effects majors must complete a variety of general education courses, core and major courses, and electives. Required core courses may include Drawing, Design, Color: Theory and Application, and Studio.  Major courses include Digital Lighting and Rendering, Visual Effects, Digital 3D Effects, Compositing, Matte painting, Programming Models and Shaders, Modeling and Animation, Concept Development for Visual Effects, and Visual Effects Studio. Required general education courses are in the areas of art, social and behavioral sciences, English, and communications.

What Can I do with a Degree in Visual Effects?

Visual effects artist work mostly in the film and video industry, gaming, and software design. Job a few job titles include visual effects artist, art director, software developer, and game designer. Visual effects artists have many opportunities to advance in all fields mentioned. In the film and video industry, many artists start out in entry-level positions such as assistant visual effects artist, but with the right skills and talent, you can advance to senior visual effects artists or even art director.  In gaming, you can also advance to upper level positions such as senior game designer or art director and in the software industry, you can advance from an entry-level software developer to senior software developer or senior designer.
.I 146
.T
document.146
.W
﻿Games, animation & VFX
Games, animation & VFX have a lot of overlap in roles, some creative and artistic others are project management or more IT related. You will find some roles occur in more than one field.

Trainee placements
If you have some experience in the field you can still apply even if you have not done an approved course.
Games
Roles include artists, animators, designers, programmers, directors and audio engineers.

A popular route in is becoming a QA tester, they test and debug the game. You must be a keen gamer, some programming, spreadsheet and database skills would be useful.
Programmers will usually have a degree in maths, physics or computer science and may need a postgraduate qualification. You will need to be able to programme in C++ and be up to date with new platforms and techniques.
Animators will normally need a qualification in this area and will be expected to have a showreel or portfolio.
Game designers plan the game and how it plays. Most are graduates and there are courses in game design. It's not an entry level position, you are likely to need several years experience in the industry before moving into this role.
Games developer
Job profile from prospects
More about roles in the games industry
Grads in games
Jobs & competitions to help you enter the job market
Gamedevemap
Global map of game studios
Animation
Roles include model makers, animators - stop motion, drawn, computer and 3D, editors and directors. Animators will find degrees in art, animation, film, computer animation / computer science useful depending on their medium. A good entry route for graduates without these degrees is Digital Painter, you will need good IT skills and a good working knowledge of photoshop and illustrator.

More about roles in animation
Animation Career Review
(USA) information includes salary info and courses in the USA.
List of Animation studios worldwide
From Wikipedia.
Animatedjobs blog
Jobs and jobsearch tips worldwide.
VFX
VFX is the combining of live action with computer generated imagery, common in Film and TV. Job roles include compositors, 3D animators, match move and roto artists and lighting directors.

VFX is very much a team role, large companies will have specialist roles and smaller companies will need generalists. When working on team projects be clear about your contribution.
Deadlines are crucial in the industry, be clear about how you prioritise work and get things done.
This is a service industry and although there is some room for artistic interpretation you will be working to a brief and will receive criticism on your work, be resilient.
VFX is largely freelance so its important to have a portfolio that demonstrates your sepecialisms. It is also important to keep up with new technology, find training courses or teach yourself.
.I 147
.T
document.147
.W
﻿The term computer graphics programming must be broke down to be understood completely. We all have a good understanding of computer- what it is, what it does-and how to use it somewhat efficiently. This article is not going to get into this aspect; the topic is broad and would fill a book.

Instead this article will focus on the graphics part of the title. We will leave the programming for another article as well­-again the topic is broad and requires more space than the one page this article is allowed.

According to Wikipedia, computer graphics is also a broad subject, which can describe anything "on computers that is not text or sound". So we can deduce: graphics are images. It gets more interesting though, when we look at the many ways in which images are captured and created. So, as we move into this topic, it becomes evident that graphics are not simply pictures or images themselves, but it is also a term used to encapsulate how these images are manipulated.

Today computer graphics programming is more popular than ever.

The field of study for computer graphics is sky rocketing. As our culture zooms forward into the 21st Century with new technology appearing almost daily and existing technology improving exponentially, we find ourselves enmeshed in a graphic society. Our movies are more graphically animated than ever before in history-not only because it entrances the viewer but because technology makes it so easy.

In the movie industry we might be familiar with the term "CG". This stands for Computer Generated. This technology allows the ability to create nearly any fantasy scene we can dream up. Movies like 300 create well over 70% of the imagery with computer generated imagery. Interestingly enough, not everyone can even tell the difference. How many of you thought the scenery, or other CG aspects, were real when you saw this movie?

Computer graphic programming exciting

The amazing part of computer graphics is- whatever you can conceive in your imagination, you can likely get it on the computer. There are many programs out there which enable the user to do different things with imagery. Adobe's Photoshop is probably one of the most well known and popular programs for manipulating photos. This program specifically manipulates pixels, the smallest component making up the image of a photograph. Programs such as this one allow us to wipe pimples off our face, get rid of double chins and even cinch our waistlines to produce more attractive results.

This is just the beginning of what is possible with graphics. Look for other articles on computer graphic programming to learn more about graphic potential and the fun things we can achieve with graphics.

Always looking to discover more practices in computer graphic programming, the author, has delved in these arenas for the last few years, Assembling clear, easy to read information is the goal of the author. As a goal, the author would like his articles to be fun, not just informative.


Article Source: http://EzineArticles.com/6498906
.I 148
.T
document.148
.W
﻿jurassic park dinosaur
Universal

Universal Pictures unveiled the first trailer for next summer's "Jurassic World" movie Tuesday starring Chris Pratt. 

From the looks of it, the fourth installment in the series will be filled with plenty of computer-generated (CG) dinosaurs and Velociraptors. 

When the first "Jurassic Park" came out in 1993, it contained very little CG. Director Steven Spielberg originally wanted the dinosaurs in the film to be done through practical effects with stop motion.

It wasn't until producer Kathleen Kennedy spotted CG test footage of a T-Rex on a computer screen at visual effects studio Industrial Light & Magic (ILM), that it was decided to mix CG dinosaurs in with the live action film.

T rex bones, Jurassic ParkThe Academy/YouTube

There are only 14 minutes of dinosaur visual effects in "Jurassic Park," about four of which were made with a computer, but its lasting effect on movies has been monumental. 

Two years later, 1995's "Toy Story" was the first full-length computer-animated movie.

Today just about every film — from James Cameron's "Avatar" to summer blockbusters like Michael Bay's "Transformers" series — owes credit to CG.

Business Insider spoke with Steve “Spaz” Williams, who was a CG Animator at ILM, the visual-effects studio that helped bring “Jurassic Park” to life.

Williams broke down the steps it took to bring the dinosaurs from paper and pad to the big screen in CG.

1. They begin with drawn designs and prosthetics of the different dinosaurs. 

The production used CG for velociraptors, brachiosauruses, and the tyrannosaurus rex, which Williams worked on primarily.

T Rex joint image
Courtesy of Steve Williams.
A T. rex drawing by Williams used to figure out where joints on the dinosaur would go.

2. Next, those renderings needed to make their way into the computer.

They scanned models, including ones for the T. rex and the velociraptors, into the computers.trex stan winston, jurassic park
The Academy screengrab
According to FXGuide, Williams took a model of a 5-foot T. rex made by Stan Winston to scan.

"In order to get it into the computer we actually fire a laser at the three-dimensional rubber prosthetic model and extract the data so the computer had it essentially," says Williams.

Williams explains it's like the opposite of 3-D printing with them taking an object and turning it into data.

3. They then reconstruct the data to make it work in the computer.

These are two images of T. rex data from Williams' monitor using software called Alias.

dinosaur t rex Jurassic Park
Courtesy of Steve Williams

t rex dinosaur
Courtesy of Steve Williams



4. An animation piece of software called SoftImage 3D is used to figure out the joint placement on the dinosaurs. 

jurassic park softimage
Universal

Here, you can see one of the Brachiosauruses in the beginning of the film.

jurassic park softimage
Universal

5. After that, the data has to be "rigged" with a digital armature in wireframes. 

This is the framework for the dinosaur that helps provide its structure allowing it to stand up, move, and run.

"This is the first shot I animated for the movie after I built all of the T. rex data," says Williams. "It took me months to get this run right, but once done, we reused the run data for the rest of the jeep-chase shots and ultimately for the following two 'Jurassic Park' movies."dinosaur t rex jurassic parkSteve Williams/Vimeo

Below is another wireframe for one of the raptors in a kitchen scene where the two children are trying to outsmart the dinosaurs.

wireframe raptor jurassic park
Academy of Motion Pictures Arts and Sciences/Academy Originals
This is a shot of one of the raptors from the popular kitchen scene in "Jurassic Park."

6. Next, the dinosaurs get their skin. 

"We used a program called Viewpaint, which allowed us to actually paint the texture of the skin in the computer so now we have this textured map," says Williams.

7. To put all of the separate images together, they needed to be rendered by massive graphics computers.

"Now we substitute in this high-resolution mesh data into a low resolution wireframe. That's all being done in computer," says Williams. "It pretty much took 10 hours to calculate one frame. You have to remember film is 24 frames per second. So it would sit there and crunch all night."

Williams built and animated the image below of the first fully rendered T. rex test. It was this video that convinced the producer Kathleen Kennedy and Steven Spielberg that "Jurassic Park" should be made in CG rather than stop motion.

initial skin test t rex jurassic park
Courtesy of AMPAS

Williams also animated all of the shots in a famous T. rex Jeep-chase sequence. He says each frame in the entire sequence took an estimated 12 hours to render. 

The point where the T. rex breaks through the log is 75 frames long. 

jurassic park jeep
Steve Williams

"I animated all those shots where the T. rex is chasing the jeep. It took me four months to animate it, just to get the running to work properly," says Williams.

8. From there, the dinosaur needs to be put into a scene through a process called compositing.

This is where all the pieces to the puzzle are assembled together. CG shots are combined together with live-action shots and any background and foreground imagery referred to as plate photography.

In this case, live-action shots of actors were combined with photography shoots in Kauai and ILM's work on the brachiosauruses and birds.

jurassic park composite
Universal

Here's the final shot with the added dinosaurs:

jurassic park composite with dinosaurs
Universal

9. Once it's put together, the images are reviewed to make sure they work. When everything looks good, the scene is put to film.

Final images are reviewed on a high-concentrated projector before translated to film.

All together, Williams says it took about a year to bring the dinosaurs to life.

“Basically May of ’92 to May of ’93 was the entire build and composite time for probably 40 shots,” says Williams. 

After $1 billion at the box office, you can't argue with the result.

jurassic park stampede
Universal

You can watch Williams and others from ILM speak more about the creation of the dinosaurs in a featurette from the Academy of Motion Pictures below:
.I 149
.T
document.149
.W
﻿Animation is older than cinema, indeed almost as old as photography. Niépce made the first still photograph in 1826, just six years before Plateau invented the Phenakistoscope. The Zoëtrope appeared just a year later in 1833. These two devices were examples of what today we would call drawn animation, presenting a series of pictures to the viewer in rapid succession to give the illusion of movement. While such toys were highly popular in the nineteenth century, it was not until the birth of cinema at the end of the century that animated films could tell stories.
Before the advent of CGI in the 1980s, animation techniques could be divided into two broad categories - drawn animation and model (or stop-motion) animation. (9) The former involves photographing a series of two-dimensional images, usually drawings but sometimes cut-out shapes, while the latter uses three-dimensional puppets and models. Both techniques developed rapidly in the early years of cinema, with Cohl (Fantasmagorie, 1908) and McCay (Little Nemo, 1911)among the drawn animation pioneers and Starewicz (The Revenge of a Kinematograph Cameraman, 1912) the pre-eminent puppet animator.
The invention of cel animation by Hurd in 1914 was a key milestone. Not only did it reduce the work required to produce drawn animation by eliminating the need to redraw the backgrounds, it also made it possible to divide the work up among a team of specialists. One artist could design the characters, (10) one draw the backgrounds, another produce key character frames as outline drawings, while yet others would work on the less inventive tasks of inking in outlines or filling in character movements ('in-betweeners'). The development of 'rotoscoping' by the Fleischer brothers was another key improvement, leading to much more realistic character movement.
While the cel technique transformed drawn animation into a streamlined production-line process, model animation remained very much an individual art. As a result it languished, while by the 1930s cel-animated shorts had become part of nearly every film programme. As well as Disney, several of the studios, Warner Brothers and MGM in particular, had flourishing animation departments. Disney produced the first full-length animated feature, Snow White and the Seven Dwarfs in 1937 and from then on released a new one roughly every other year.
The advent of widespread television in the 1960s had a profound effect on film programmes. (11) First newsreels were abandoned, as television news proved more efficient and immediate. Cartoon shorts were edged out more slowly, but became rare by the end of the 1960s. The animation studios, instead of making five-minute shorts for cinema exhibition, started making thirty-minute TV cartoons for children (Top Cat, Deputy Dawg andThe Flintstones for example). (12) While stories of necessity became more complex, the cartoon drawings themselves became highly simplified to meet the budgets that TV imposed.
Within the domain of animated shorts almost every conceivable technique has continued to be used, but until recently cartoon features have been produced exclusively using cel animation. Indeed, for more than forty years, from Snow White (1937) until The Secret of NIMH (Bluth/Goldman, 1982) almost all the feature-length cartoons came from a single studio, Disney. (13) Model animation, while often used for special effects in fantasy and science fiction films, (14) was not used for a feature-length animated film until Nightmare (1993).
Despite the success of Nightmare we have not seen many more stop-motion 3D cartoons. Indeed there has been just one, Chicken Run (Lord/Park, 2000), (15) although the long middle section of James and the Giant Peach (Selick, 1996) is entirely stop-motion. Instead there has been a series of very successful 3D cartoons generated completely by computers, starting with Toy Story in 1995. Before we consider whether there is a causal relationship between the apparent failure of stop-motion and the undoubted success of CGI, we need to investigate how and why the latter has developed.e


.I 15
.T
document.15
.W
Computer animation/Computer generated imagery
Computer-generated imagery (CGI) is the application of the field of computer graphics (or more specifically 3D computer graphics) to special effects. CGI is used in movies, television programs and commercials, and in printed media. Real-time computer graphics, such as those in video games, are rarely referred to as CGI.

CGI is used because it is often cheaper than physical methods, such as constructing elaborate miniatures for effects shots or hiring a great deal of extras for crowd scenes, and because it allows the creation of images that would not be feasible using any other method. It can also allow a single artist to produce content without the use of actors or other contributors to the project.

2D CGI was first used in movies in 1973's Westworld, though the first use of 3D imagery was in its sequel, Futureworld (1976), which featured a computer-generated hand and face created by then University of Utah graduate students Edwin Catmull and Fred Parke. The first two films to make heavy investments in CGI, Tron (1982) and The Last Starfighter (1984), were commercial failures, causing most directors to relegate CGI to images that were supposed to look like they were created by a computer. Photorealistic CGI did not win over the motion picture industry until 1989, when The Abyss won the Academy Award for Visual Effects. Industrial Light and Magic produced photorealistic CGI visual effects, including a seawater creature lovingly dubbed the water weenie, for the film.

2D CGI increasingly appeared in "traditional" animated films, where it supplemented the use of hand-illustrated cels. Its uses ranged from digital tweening motion between frames, to eye-catching quasi-3D effects such as the ballroom scene in Beauty and the Beast.

In 1995, the first fully computer-generated feature film, Pixar's Toy Story, was a resounding commercial success. Additional digital animation studios such as Blue Sky Studios (Fox) and Pacific Data Images (Dreamworks SKG) went into production, and existing animation companies such as Disney began to make a transition from traditional animation to CGI.

Between 1995 and 2005 the average effects budget for a wide-release feature film skyrocketed from $5 million to $40 million. According to one studio executive, as of 2005, more than half of feature films have significant effects.

In the early 2000s, computer-generated imagery became the dominant form of special effects. The technology progressed to the point that it became possible to include virtual stunt doubles that were nearly indistinguishable from the actors they replaced. Computer-generated extras also became used extensively in crowd scenes. The timeline of CGI in movies shows a detailed list of pioneering uses of computer-generated imagery in film and television.

CGI for films is usually rendered at about 1.4–6 megapixels. Toy Story, for example, was rendered at 1536 × 922. The time to render one frame is typically around 2–3 hours, with ten times that for the most complex scenes. This time hasn't changed much in the last decade, as image quality progressed at the same rate as improvements in hardware.

Developments in CGI technologies are reported each year at SIGGRAPH, an annual conference on computer graphics and interactive techniques, attended each year by tens of thousands of computer professionals.

Developers of computer games and 3D video cards strive to achieve the same visual quality on personal computers in real-time as is possible for CGI films and animation. With the rapid advancement of real-time rendering quality, artists began to use game engines to render non-interactive movies. This art form is called machinima.
.I 150
.T
document.150
.W
﻿The digital revolution has taken over our lives and now it’s taking place in our advertising. More and more brands are discovering the value of using virtual images in their advertising. Whether it’s due to their lower costs, higher quality, or overall efficiency, computer-generated images (CGI) allow companies to make their ads more polished and perfect than ever with less aggravation than before. Marketwatch.com outlined the following five scenarios where computer-generated images are changing the look of advertising.

1. The Value of Virtual Models – Supermodels are no longer perfect enough now that computer-generated images of models can give companies high style without the high price tag. These virtual fashion models allow brands to advertise their products on beautiful bodies without having to pay models for hours of poses and wardrobe changes since all of these alterations can be computer generated. Experts expect to see an increase in the use of virtual models since such cost-cutting measures can help companies keep prices down for consumers while retaining the quality and appearance of a high-style photo shoot. The only concern is that these virtual mannequins could place even more pressure on young audiences to attain an impossible standard of beauty, but such issues have always been present in the fashion industry given the prevalent practice of airbrushing. Looking forward, the use of virtual models is expected to become the norm for more and more businesses seeking both style and savings.


2. The Allure of Advertising – The need to save on costs and time is leading many brands to use computer-generated images in their print and advertising. IKEA recently filled its new catalog with digital images of its furniture and expects to take a similar virtual approach to one-quarter of its print and Internet ads next year. In addition to eliminating a lot of expense and effort, the Swedish retailer explains that computer-generated images allow them to show their products in greater detail and dimension than standard photographs.

3. The Thrill of 3-D Houses – Many real estate companies rely on the computer to enhance the appearance and ambiance of their properties. The use of 3-D images can make rooms appear larger and more inviting than traditional photographs, while the computer also allows them to add more expensive accessories to the décor and spruce up the outdoor landscaping. In fact, some developers need to use digital models since their houses are sold directly from the plans and buyers often have difficulty envisioning the finished product. Of course, there’s no doubt that computer-generated images can provide a major selling advantage by showing a property at its fullest potential.

4. The Magic of Movie Enhancements – Computer-generated images have long been used for special effects in the movies, but now this technology is expanding to their posters and advertising campaigns. Film companies seem to constantly worry about budgets and deadlines, so these computer-generated images provide the practical benefits of helping executives save money and time. They also create an additional selling advantage by making the movies themselves appear even more visually appealing to audiences. Recently, controversy has arisen regarding physical enhancements made to some movie posters in order to boost audience appeal, but film companies were quick to correct their extreme moves. Still, critics worry that these computer-generated images are unrealistic and will set up false expectations that ultimately will erode the trust of consumers, as well as put greater pressure on young people to live up to such perfect images. Regardless of these issues, the movie industry shows no signs of stopping when it comes to using computer-generated images. In fact, more and more moviemakers are now working their magic on both the action on-screen and advertising off-screen.

Like what you are reading?
Follow MDG Advertising and always be in the know.
  
5. The Delight of Driving – It’s no secret that car companies love to digitally enhance their models to highlight their form and features in print, but now carmakers are using these virtual touches in their TV ads to appeal to a younger market used to extreme visual images. Brands such as Lexus, Mercedes, Fiat, Toyota, and Volkswagen have all used CGI to create special effects or more-stimulating settings for their TV ads. In fact, many car companies are bringing in prominent film directors to essentially turn their TV ads into mini-movies. It’s all in an effort to capture the attention of audiences and stand out from the competition while enhancing the brand image they wish to create.

Today, the computer is redefining the nature of advertising. The use of computer-generated images clearly cuts down on the cost and time of traditional photography while enabling brands to enhance their images in every way.
.I 151
.T
document.151
.W
﻿
FROM THE GROUND UP 

In 1985 you didn't purchase CGI software, you wrote it. Abel had a software department with some 25 programmers and they pushed the envelope of CGI software for each and every spot they worked on. 

Some of his programming team later went on to found Wavefront Technologies, the first company to sell off-the-shelf 3D software for the production world. Wavefront was acquired by Silicon Graphics in 1994, and integrated with code from a former competitor, becoming Alias|Wavefront in the process. 

All of the early players in the CGI game were producing spots for broadcast. They offered a unique juxtaposition of forces, as illustrated by the sexy robot story. Television commercials had very high production budgets, as much as a million dollars for a 30 second spot - outrageous at the time - combined with an insatiable thirst for ever more stunning visuals. CGI was the new thing that could deliver these stunning visuals. 

But why would anybody spend $1 million for a television commercial? Because they are going to spend $25 million or more on the air time! Who in their right mind would want to lower the commercial's impact to save a few bucks? 

These outrageous costs subsidized a large software development department that wrote the new software required for each commercial. The previously written software was developed just enough to produce the last commercial, so it always needed to be enhanced for the next. 

There were two problems with this approach: first, it took months to produce a 30 second spot; second, the software was not general purpose. Software was written specifically for a single commercial, and was therefore limited and incomplete. 

These two issues prevented early CGI from being useful for feature films and kept it relegated to the rarified atmosphere of high-end commercials. 

CGI Commercials
Above and below: Images taken from one of the earliest CGI commercials, "Brilliance" by Ketcham Advertising, 1984.
CGI Commercials 


SUPERCOMPUTERS 

There was another major obstacle to feature film work, and that was the rendering time. At Abel's, the computer room harbored two "super- mini" computers, each with a 1 Megahertz CPU, with 10 megabytes of RAM and a 500 megabyte hard drive. Wow! 

The video resolution images were rendered in upwards of one hour per frame. They were then sent to a RasterTech frame buffer over Ethernet for viewing on a monitor. 

To lay off to videotape, a 1" reel-to-reel videotape machine was rented for the weekend. It was connected to a Lyon-Lamb animation controller that allowed it to lay down one frame of video at a time. 

Since videotape has to be moving to lay down a frame, the Lyon-Lamb controller commanded the tape deck to back up, pre-roll, then do an insert edit for each frame, one frame at a time, for the 900 frames of a 30 second spot. It took almost three hours to lay a 30 second spot off to tape. 

Today, of course, the "Brilliance" spot could be done by a part-time high-school student on a desktop computer in a week. 

From The Last Starfighter
The Last Starfighter, ©1984 Lorimar Film Entertainment 


FROM TV COMMERCIALS TO THE MOVIE SCREEN 

There were some early efforts to use CGI for feature films, but these were mostly brief "cameo" appearances. One of the earliest was the title sequence for "The Black Hole" (1979, Disney) - done by Robert Abel - featuring a wild ride down the throat of a green wireframe black hole. 

Early 3D animations used vectors instead of bitmapped graphics to save rendering time. The Evans and Sutherland PS-300 vector graphics display could play back a wireframe animation in real time, with one limitation: the monitor was monochrome.

To make colored vector graphics, the vectors were separated into color groups - all the red vectors in this file, the green vectors in that file, etc. Then a 35mm camera was parked in front of the PS-300 monitor to film off of it. Add a color wheel with colored gels, and you're ready to go. 

Start at the beginning of the shot, put up the vectors that are to be red, rotate the red gel in front of the camera lens, then shoot the entire shot one frame at a time. 

When done, back the film up to the first frame, call up the green vectors and the green gel, and repeat. 

It worked surprisingly well and several color vector graphic projects were done this way until raster graphics became more practical. 

The first major use of CGI in a feature film was "The Last Starfighter" (1984) by Digital Productions. To render the high resolution images required by a feature film in a reasonable amount of time, Digital Productions used a Cray X-MP supercomputer (cost: $15 million) and used only phong shading - no texture maps. The resulting shiny metal appearance worked well for the shots of spaceships in outer space, which was the only place it was used. It's a marvelous example of working within the limits of the technology. 

Other cameos followed. Examples that come to mind are the stained glass knight in "Young Sherlock Holmes" (1985, Lucasfilm), a brief morph shot in "Willow" (1988, Lucasfilm), and the water weenie in "The Abyss" (1989, ILM). 

CGI Commercials
A few of the images and commercials created by Robert Abel and Associates at the dawn of CGI 


BULLET-TIME: AHEAD OF ITS TIME 

Around 1994 I had another "bolt upright" moment. In this spot a man was leisurely hosing off the side of his car, when suddenly the scene froze and the camera whipped around to the front of the car. 

What I couldn't figure out was how could the water freeze in mid-air like that? If it was CGI, how could it match the camera move? This was years before motion tracking. 

Little did I know it at the time but I had just been dazzled by my first "bullet- time" shot, years before The Matrix made it famous. 


.I 152
.T
document.152
.W
﻿The music video format has always been a place for experimentation, somewhere that far-flung ideas can be given form and visual expression. Following in that fine tradition, we're happy to premiere Midnight Juggernauts' video for their track "Memorium" from upcoming album Uncanny Valley, due out 9th July. But instead of containing a short film (which is often the case), this music video is a visual documentary on the evolution of CGI from 1951 to the present.

It's a wonderful journey that traces the development of this now standard practice, from its beginnings on military computer systems through its wireframe incarnations to the present day abstractions of Kinect-based graphics. It's a story that's involved the work of many pioneers, from scientists working in computer laboratories to the work of innovators like John Whitney—and the piece serves as a homage to their work.

To find out a bit more about the vid and what inspired it, we fired off some questions to the director of the piece, band member and CGI enthusiast Vincenzi Vandella.

The Creators Project: The video works both as a documentary and as great visuals for the track. What made you want to explore this hybrid form of music video?
Vincent Vendetta: I think music videos should be much more than just a promo clip for a song. I like the idea of their content being intriguing or informative in their own right and seeing how far you can push tangential ideas, though still finding a thread somewhere to keep it cohesive. I've always been heavily into documentary film, and am working on quite a few other long form hybrid projects which have been spanning a few years. I guess there's just more space to explore. 

What made you want to tackle the subject of CGI and its history?
CGI is now embedded in our popular culture and visual language but I don't think younger generations would really be aware of those important formative years, where each new[ly] released trial would represent a new dramatic technological advance. It was an important evolution and a fairly recent one. I think in the future the majority of all films will be completely CGI. Kids will have apps where they punch in a script, click on Al Pacino and Sofia Coppola as photo-realistic CGI actors, press render and you have The Godfather Part 4. This will be an era of quantity over quality. It's inevitable and will be known as Dead Eye Cinema. 


Bell Laboratories animation from 1963

Do you feel the history of CGI is unsung?
Computer programmers and the like would be aware of these pioneers, but considering that CGI is an accepted mainstream field driving most blockbuster entertainment these days, as well as other applications, yes I do think its history is relatively unsung. Most [people] probably think it started from Terminator 2 or Tron or Luxo Jnr. The early pioneers included here led the way to a huge revolution. 
.I 153
.T
document.153
.W
﻿Have you ever wondered how your computer sees the world? Spoiler alert: it's the stuff of psychedelic nightmares, as the internet found out last month when Google revealed that in order to sort and categorize images online, it uses an artificial intelligence program that looks for patterns and sometimes gets things wrong, finding random dog faces, swirls, and hands where there are none.
Google opened the source code up to developers under the name "DeepDream," and now, a couple new websites have sprung up, including a recent one from Psychic VR Lab and (h/t: Prosthetic Knowledge ) and earlier, one from entrepreneur Zain Shah called Deep Neural Net Dreams, or #DeepDream for short. Both take code from Google's AI and let you upload your own photos, transforming them into eerie, computerized dreamscapes. You can see examples of these images below.
Google’s artificial neural networks (ANNs) are used to discern and process the millions of photos scraped by the search giant and organized in Google Images. In the case of the Google Images ANN, Google's developers taught this artificial intelligence hive mind how to recognize certain objects by showing them repeated examples of said object.
For example, after seeing a bunch of pictures of starfish, the program would begin to understand that a starfish is typically a shape with five triangular points, and an orange color. The team realized that this same program could be used to also generate images of those things. The program is a ways off from being able to do this perfectly, but what it “dreamed” up is pretty trippy.
Now you can produce your own psychedelic images with the Psychic VR Lab interface and Deep Neural Net Dreams. All you have to do is upload an image and wait for the code to transform into some kind of surrealist nightmare. Then post your creations to social media with the tag #deepdream, so other researchers can further study them.
.I 154
.T
document.154
.W
﻿We live in a 3D world. People move, think and experience in three dimensions.

Much of our media is also 3D— though it is usually presented on flat screens. Animated films are created from computer-generated 3D images. Online map services allow us to explore our destination, virtually, in a 3D environment. Most video games, whether running on dedicated consoles or mobile phones, are rendered in 3D. Even the news has gone 3D: the sight of a CNN analyst meandering through a virtual set, comically awkward a few years ago, has become an accepted part of the broadcast vocabulary as cable channels vie for increasing attention in a twenty-four hour news cycle.

3D graphics is nearly as old as the computer itself, tracing its roots back to the 1960’s. It has been used in applications spanning engineering, education, training, architecture, finance, sales and marketing, gaming and entertainment. Historically, 3D applications have relied on high-end computer systems and expensive software. But that has changed in the last decade. 3D processing hardware is now shipped in every computer and mobile device, with the consumer smart phone of today possessing more graphics power than the professional workstation of fifteen years before. More importantly, the software required to render 3D is now not only universally accessible; it’s free. It’s called a web browser.

Figure 1-1 shows an excerpt from 100,000 Stars, a browser-based 3D flythrough simulation of our stellar neighbors in the Milky Way. Using the mouse, you can rotate about the galactic plane and zoom in to a star of interest. Stars are represented with renderings that approximate their apparent magnitude and color. Each star is labeled with its common name; when you mouse over the label, it highlights. Click on the label, and an overlay appears displaying the Wikipedia entry for that star. Click on a hyperlink in the overlay text, and the browser will launch that link in a new tab. 100,000 Stars is a stunningly produced interactive experience featuring beautiful renderings, pulsing animations, a majestic soundtrack, and an artfully integrated 2D user interface.
.I 155
.T
document.155
.W
﻿Virtual environments are seen nowadays as extensions of our physical activities in the city. Are people, however, aware what the digitally mediated cities they live in are? The starting point of my paper is a question of how computer-generated images (CGIs) influence human perception of real space. I am interested in the conflict between a vision and reality, which occurs when an architectural project materialises in a public space and is subsequently rejected by the inhabitants. To explain this conflict, I will use the notion of digital utopias and compare CGIs with the great tradition of “paper” architecture. I will analyse two case studies from a medium-sized Polish city—Poznan. The first case is a redevelopment of the Main Railway Station; the second is a re-design of a local square in Poznan. The analysis focuses on the ambiguity of CGIs used to advertise new investments. The Station in the phase of digital visualisation was appreciated by the Poznan inhabitants but when the project was finally realised, strong criticism of its users followed. The second one provoked public protests already in the phase of visualisation. In conclusion, I state that the concept of agonistic public spaces should be expanded and its virtual dimension should be taken into consideration as well. When dealing with hyper-realistic CGIs, we experience a certain utopia. Confronted with their material execution, we often experience dystopian disillusion which stirs us into action.
.I 156
.T
document.156
.W
﻿As computer-generated imagery (CGI) becomes more and more prevalent in movies, some actors have openly worried that they’ll be replaced by computer programs that don’t age, don’t charge millions of dollars for their services, and don’t argue with film directors. 

So far, they have nothing to worry about. But there is one actor who has become famous for creating two very popular computer-generated characters. 

His name is Andy Serkis, and he's the British actor who played Gollum in theLord of the Rings trilogy. He also played King Kong in the 2005 remake of the classic film of the same name.

Both roles required Serkis to don what’s called a motion capture suit. That’s a tight-fitting body suit that’s outfitted with numerous reflective or magnetic sensors.

ForLord of the Rings, Serkis performed all of Gollum’s movements inside the suit. Programmers then linked these movements to a computer-generated “puppet,” using the sensors as guides. Finally, a team of 18 animators filled in the character’s physical look and facial expressions. 

For King Kong, director Peter Jackson went one step further. Jackson placed 132 digital markers on Serkis’s face, allowing his every expression to be digitally captured and then linked to the face of a giant CGI gorilla. 

Some people have criticized Serkis, claiming that his performances aren’t really “acting,” but he disagrees. To make his Kong as realistic as possible, he spent two months hanging out with gorillas in a London zoo and then traveled to Africa to interact with them in the wild!
.I 157
.T
document.157
.W
﻿This article is part of the Science in Sci-fi, Fact in Fantasy blog series. Each week, we tackle one of the scientific or technological concepts pervasive in sci-fi (space travel, genetic engineering, artificial intelligence, etc.) with input from an expert. Please join the mailing list to be notified every time new content is posted.

The Expert: Abby Goldsmith
Abby Goldsmith is a video game industry veteran, with credits on more than twenty games for Nintendo DS and Wii, PlayStation2, and mobile platforms.  She earned a BFA in Film & Animation from the California Institute of the Arts, where artists train for careers in digital effects, graduating to work for studios such as Blizzard or Pixar. You can find her on Twitter and Facebook.

CGI Is Not Made by Computers
As a 3D animator, I cringe every time an author assumes that a small team of programmers can create elaborate virtual worlds or immersive illusions. This assumption is completely divorced from reality.

Iron man without VFX
Credit: AnimationInsider.com
Computer generated imagery is a misnomer. CGI, or visual FX, are 100% generated by human artists. Always have been, and always will be–unless computers surpass the technological singularity. The impressive visuals in Hollywood films and video games are not created by programs. Programmers wrote the software tools–Adobe Photoshop, for instance–but the actual visuals are created by hundreds of artists working for several years. Those artists have traditional training in painting, sculpture, or animation. They’re often underpaid and overworked. Most have aspired all their lives to work in games or film.

Animation Team
Credit: BuildaBetterPhotograph.com
During the Early Renaissance in Italy, artists such as Botticelli and Donatello pioneered new realism techniques, imbuing their art with dimensions of reality. The iconic art of the Middle Ages passed out of fashion as Da Vinci and Michelangelo competed for large scope projects to impress the mass audiences of their day.

ceiling sistine chapel
Ceiling of the Sistine Chapel
A Renaissance-era visitor to the Sistine Chapel might well imagine that the artist used uncommon paints and special paintbrushes, or that he channeled God while painting. We seem to be undergoing a similar era now. Visually spectacular games such as “Skyrim” and films such as “Lord of the Rings” look too authentic to have been created by human hands. Those backgrounds and creatures are more detailed than anything painted on a canvas. So audiences, unaware of high-end artist training grounds such as the Gnomon Workshop, assume there must be a secret ingredient.

They attribute the hyper-realistic otherworldly scenery to “computers.”

elder scrolls skyrim

When non-industry people ask about my job, they seem flummoxed. They resort to saying, “Um, so you draw on a computer?” I give up and say, “Pretty much,” but I’m wary, because they probably imagine something alien to what I actually do. 3D animation has more in common with sculpture and puppeteer work than painting. When you see Spider-Man swinging between skyscrapers, or King Kong roaring in chains, you can bet that a 3D animator made those characters move in a realistically convincing way.

The Matrix Dodge This
Dodge This (Credit: Wikia)
The otherworldly backgrounds in films are, indeed, painted with a blend of photography, digital enhancements, and traditional painting techniques taught for generations. Costumed actors and sets are then composited onto the background. It’s called digital matte painting.

Matte painting graphics
The Last Samurai (matte painting)
Computer code lacks an imagination. Code can generate graphics based on data, but such generated imagery will look nothing like live action footage. Code cannot visualize spaceships or dragons. Code can simulate aspects of visual elements, such as lighting and fur and physics . . . but software cannot put together the whole shebang and create something from it. That’s up to human artists with creative minds.

So it will remain. Unless computers pass the singularity.

I Robot
I, Robot (Credit: WittyBadger.com)
If you write about virtual reality or immersive entertainment, please remember that every element in your digital world must have been sculpted or painted by human artists. Hyper-realistic visuals require a massive team and years of hard work. Only the final render looks like magic.
.I 158
.T
document.158
.W
﻿The Art of Walt Disney author Christopher Finch tells the story of the pioneers of CG films: producer/directors like George Lucas, Steven Spielberg, and Ridley Scott; and John Lasseter and Ed Catmull, founders of Pixar.

Computer generated imagery, commonly called “CG,” has had as big an impact on the movie industry as the advent of sound or color. Not only has it made possible a new kind of fully animated movie, but it also has revolutionized big-budget, live-action filmmaking. The CG Story is one of determined experimentation and brilliant innovation carried out by a group of gifted, colorful, and competitive young men and women, many of whom would become legendary in the digital world.

George Lucas, Steven Spielberg, and Ridley Scott embraced the computer to create believable fantasy worlds of a richness that had seldom if ever been realized on screen. Their early efforts helped inspire a revolution in animation, enabled by technical wizardry and led by the founders of Pixar, including John Lasseter and Ed Catmull, who would create the entirely computer-produced worlds of Toy Story and subsequent Pixar films. Meanwhile, directors like James Cameron used the new technology to make hybrid live-action and CG films, including the extraordinary Avatar. Finch covers these and more, giving a full account of today’s most significant CG films.
.I 159
.T
document.159
.W
﻿Have you ever been thumbing through a magazine or scrolling through your Facebook news feed and seen an advertisement for a product where the product looks almost too perfectly placed or lighted? Odds are, it’s a 3D Computer Generated (CG) image.

CG ads have been around for a long time, and is used by companies both large and small. The benefit? It allows you to properly display your product in a controlled, highly editable surrounding without the need to worry about purchasing high-quality cameras or lights, or having to worry about outside factors affecting the scene. It also allows for abstract concepts like Lego's Jurassic Park seen here:

Lego-Jurassic-Park.jpg

 

or some fresh cocobella in-the-moment actions:

cocobella.jpg

 

And this only goes for your traditional image-based ads...

Let’s not forget about computer generated videos.
3D animations used in advertising allows for impossible views and angles of your product, or showing exactly how it works for its intended application. They can give you a sense of scale or magnification that you simply can’t get with your typical camera, or can simulate interaction with your product without the need for a suitable location or actor.

What’s next for the use of 3D in advertising? As we can see here from big companies like Nike, I’m betting holograms. They're a great way to get your message across in a much more impressive - and informative - fashion than the 2-dimensional methods we've been using.

 



 

Sure, it may sound like sci-fi, but it’s a real and legitimate tech solution that has been gaining huge traction and practical application in the tech sector, more so over recent years at big tech conventions like the Consumer Electronics Show (CES); see here:

 



 

And the future outlook only gets brighter. With Microsoft’s recent announcement of the Hololens, the possibilities become endless. Imagine opening your cupboard or fridge and you notice that you're out of your favorite snack or ingredient. Now imagine browsing a list of the nearest retailers that sell that product. You're in the middle of comparing prices between competitive brands when a notification pops up about one of the two options you've narrowed it down to. The article mentions a recall because of a defective batch. In a matter of minutes, you've saved yourself from possible health risks, loss of money (and time) - all without even leaving your kitchen!



 

Granted, this scenario is years down the road, but being able to anticipate and adapt with the times is what's going to make your life and business flourish in this new wealth of tech innovation. Now all we need is a droid for the household to help us deliver our holographic ads of hope.



 

Technology is becoming more and more integrated with our everyday lives, and it's very unlikely to slow down. A mere 15 years ago, we didn't have Facebook, Twitter, Instagram, etc. Social Media itself existed as chat rooms, message boards, and around the water cooler at work. Now it's in the palm of our hand via smartphones, on our wrist via smart watches, and even integrated with headsets like Google Glass. The breadth and scale to which the industry itself has grown has been heavily affected by the accessibility brought about by all of these innovations; and with new methods of which to view and access that information, we're on the brink of a whole new vast array of accessing and utilizing that information.
.I 16
.T
document.16
.W
Computer animation/Getting started
Introduction
Making animations on a computer can be relatively cheap, horrendously expensive, or anywhere in between. Your requirements will depend on what exactly you want to do (more on the different types of animation in chapter 4), but it's safe to say most hobbyists can get involved with minimal outlay.

Hardware[edit]
Most of the equipment here you will already have, or can pick up cheaply. Unless you plan to make broadcast quality animation, don't worry about going for the cheaper models as the differences at the lower end of the market are negligible.

A PC

For any sort of graphics work, the faster your PC's processor the better. Also, the more memory it has in terms of RAM and hard-drive space the better. Any computer bought within the last year or two should be able to handle the majority of animation tasks comfortably however.

If you have money to burn, you might want to consider increasing the RAM in your PC to its maximum amount as this will greatly enhance your user experience when working with large files. Another upgrade which is always worthwhile if you do a lot of graphics work is a bigger hard-drive as the files you generate build up quickly.

For certain types of animation such as machinima or 3d, you may want to consider upgrading your graphics card to the best you can afford. For most animation purposes, any relatively modern graphics card will do, there is no need to go for the staggeringly expensive model on the bleeding edge.

A Digital Camera

An absolute essential. Probably the easiest way to get a source image to modify without having to worry about copyright implications.

A digital camera, as opposed to a film or video camera, uses an electronic sensor to transform images (or video) into electronic data. Modern digital cameras are typically multifunctional and the same device can take photographs, video, and/or sound.

In 2005, digital cameras are starting to push traditional film cameras out of many markets. Shrinking device sizes have recently allowed miniaturized digital cameras to be included in multifunctional devices, such as cell phones and PDAs. There is no particular need to go for the most expensive model, but it does not hurt to get the best resolution you can afford.

Wikipedia has related information at Digital camera


A Scanner

Not essential, unless you have a lot of images on paper you would like to work with on your PC. A scanner is a device which reads in an image and converts it to electronic data, and in appearance it is usually a flat panel similar to the top of a photocopier.

Those who prefer to sketch with pen and paper can find that a scanner is a useful addition to their workstation, enabling them to transfer their doodles and rough sketches to the PC for processing. Only those who need to scan intricately detailed or overlarge pieces of work should consider buying an expensive model.

Wikipedia has related information at Image scanner

A Graphics Tablet

A graphics tablet (or digitizing tablet) is a computer peripheral device that allows for a relatively simple method of inputting hand-drawn graphics or art into a computer in real time. They typically consist of a large flat surface for drawing on, and an attached "stylus" for drawing on the surface, originally as a part of the electronics, but later simply to provide an accurate but smooth "point".

Graphics tablets sometimes take a little bit of getting used to, but the fact that they are usually more sensitive and intuitive than a mouse means most serious electronic artists swear by them. Although these can be picked up pretty cheaply, it is best only using the budget models to try out tablets for the first time, and to quickly upgrade if you plan to be using one often.

Wikipedia has related information at Digitizing tablet

Sound Hardware

Most animations require some sort of soundtrack, and you may need to create some of the sounds yourself. Sounds are input and output from a sound card or sound chip (which may be part of your PC's motherboard, or a separate card), and it is likely that the sound card which came with your computer will be suitable for your purposes.

The sound card will have an input for a microphone, a line-in, and a joypad or MIDI keyboard. A microphone is a handy thing to have for recording sound effects and voice tracks, but the budget models should be sufficient for this. The line in socket is used to record audio from an external device such as an ipod or cassette deck and requires a cable with a headphone jack at either end to use.

A MIDI keyboard can be useful if you are at-all musical and capable of creating your own music tracks. These are basically mini piano-style keyboards that interface with your PC and use the PC's software to generate sound, which is then output through the PC's speakers.

Wikipedia has related information at Sound card

Wikipedia has related information at MIDI

Software
This list is in no way intended to be exhaustive, and splits the required software into a few broad categories of which a few representative examples are given. Where possible, any free or Open Source Software(OSS) available is highlighted.

Image Manipulation Software

This is what you use to transform the images you work with, moulding them to fit the requirements of your animation, and modifying them to create the key elements. Any decent application will allow you to play with the size, colouring, and content of your images. It will allow you to splice them together into montages, to split them into their component parts, and much, much more. Whichever piece of software you use, taking the time to learn how to use it well will pay dividends in terms of the time it takes you to make an animation, and the animation's quality when it's done.

The market leader and industry standard is Adobe Photoshop, which can be an expensive purchase for a beginner. There are cheaper alternatives such as Paint Shop Pro available, and a reduced price version of Photoshop (with consequently reduced functionality) called Photoshop Elements is also on the market.

The leading OSS for image manipulation is The GIMP, an excellent and powerful alternative to commercial equivalents. The only problem with the GIMP is its non-standard interface which may prove daunting to beginners.

Animation Software

The leading software in 2D computer animation is Adobe Flash. This is the program that is commonly used to create animations for the Internet in SWF format, also known as "flash cartoons" or "flashtoons." It also has its own built-in programming language called Actionscript that can be applied to its animations.

3D Animation

For those looking to start in CG animation, the leading opensource alternative is Blender, frequently updated, and has an excellent user base to help newbies and pros alike. No program can be more highly recommended than Blender 3d. There are many Wikibooks on Blender.

There are many types of 3D animation software available. Some, like Maya, 3D Studio Max, and Cinema4D, are available from various sources for a commercial-size price. Maya, for example, can cost thousands for the higher-end versions - but it may be worth the money, as many professional CG companies use it.

Sound and Music Software

.I 160
.T
document.160
.W
﻿Last week the powerful voice of the ad industry Sir Martin Sorrell, chief executive of WPP, the world’s most successful advertising company, made an announcement that was welcomed widely across the industry. 

The company reported unexpectedly good end of year financial results, a signal to industry that we may have weathered the worst of the recession and that after battening down the hatches for the past two years it’s now time for agencies to invest in growth.

As agencies shake off the repercussions of recession, there is the incumbent pressure to rebuild quickly and increase profits, and in tandem with this will always be the need to invest in the latest technology.

It has been reported that within WPP new media currently accounts for 27 per cent of revenues, but that WPP will increase this to at least a third within four years. (Source: City AM, March 8, 2010)

With the high costs of an average advertising campaign it is clear that companies will remain cautious for sometime when signing off marketing budgets.  The growth of digital marketing is both an advantage and a hindrance.

New technologies such as advances in CGI can dramatically cut the cost of creating ad campaigns.  The advantages mean a reduction in the costs involved of shooting on location, saving companies thousands on overheads.

But the average online experience and expectations from many clients are now vastly higher, meaning that companies need to ensure that they are up to date with the latest technology.

3D has become a craze in the UK and overseas with the mainstream success of movies such as Avatar and Alice in Wonderland, and the trend is set to continue for consumers with the introduction of 3D televisions.

News that Samsung are teaming up with Dreamworks to produce exclusive 3D versions of movies for home television demonstrates that organisations are recognising and seizing this opportunity. 

However the use of CGI technology in marketing has had less cut through and is perhaps not as much on the radar of some marketers in the UK as in the US.  The availability of Computer Generated Imagery offers a smart alternative for marketers who are focussing on the cost benefits of various marketing solutions.

CGI, the application of computer graphics for special effects, can be used as much for adverts, tv and printed materials as it can for movies, enabling the development of computer generated effects, and replicas of products or humans that are nearly indistinguishable from real life.

The momentum CGI has gained in the US is looking set to continue in the UK now as marketers and brands understand its use and validity within the marketing life cycle.

CG assets are created using CAD data before a product is put into the initial stages of production, and can be used for almost any industry whether it’s virtual cars, crisps, celebrities or houses.

While the flexibility of CGI technology enables the models to be transferred across print, broadcast and online marketing campaigns, it is the interactive nature of the product that gives it that elusive edge.

CG assets can turn a casual interest in a product into sales and make a serious difference to a company’s bottom line, allowing companies to create virtual customisers so that consumers can engage with their products before production has even begun. 

The beauty of CGI technology is its flexibility.  While it can hold its own as a standalone marketing technique or product, it can also be used in conjunction with the more traditional methods to achieve even higher cut through in a crowded marketplace. CG models can be seamlessly inserted into an existing campaign.

As budgets are being scrutinised more closely than ever, the cost benefits of CGI become significant; as once a digital model is created it is a multi-platform asset that can be easily used and modified without having to foot massive production bills.

This lifecycle also helps avoid commonplace minor differences or inaccuracies that can typically apply across the different mediums in a marketing campaign.

CGI is exciting and reassuring.  Simultaneously it satisfies the desire for organisations and agencies to be avant-garde in their approach, whilst reassuringly smart in their cash flow management.
.I 161
.T
document.161
.W
﻿Audiences were able to get lost in <i>Mad Max: Fury Road</i> because the film still had a lot of real components to it.
Audiences were able to get lost in Mad Max: Fury Road because the film still had a lot of real components to it.
Movies have come a long way over the past 20 years. In the early days of CGI, filmmakers could only superimpose a computer-generated component onto a real scene, as in Terminator 2: Judgment Day. Today, they're able to generate entire sequences using computers, as in Avatar or King Kong.
What's wrong with that? Movies saturated with CGI can become too 'glossy', say some animators, and audiences are seeing right through it. 
The experience of being lost in a movie is called "suspension of disbelief": we watch a fantastical movie like Batman Begins and suspend our judgments about it being totally implausible. But what happens when CGI saturation pushes beyond what we're prepared to suspend? We're looking at you, Avengers: Age of Ultron.
The last three Star Wars movies, including 2005's <i>Star Wars III: Revenge of the Sith</i>, were criticised for an over-reliance on CGI.
The last three Star Wars movies, including 2005's Star Wars III: Revenge of the Sith, were criticised for an over-reliance on CGI.
Melbourne's RMIT University digital design lecturer Mark Lycette says there's "a backlash brewing" over special-effects overkill.
"CGI now it too perfect. Even if the films are grimy, it's not really real. A human knows what real dirt is and it's very easy to see fakery," Mr Lycette says.
"A lot of what you're seeing is the machine starting to dominate the creative process."
Part of the reason why this year's Mad Max: Fury Road was such awe-inspiring viewing for many people was because it struck the right mix of CGI with real vehicles, props and landscapes.
Too many filmmakers are struggling with that balance, says Mr Lycette.
"The danger is that technicians become obsessed with the tool and everything is invested in the process and not with the outcome. They lose touch with the goal and the message of the movie.
"In the end, because they don't have connection with it, the audience struggles to have to have a connection with it too."
A video uploaded to YouTube a week ago explaining 'The WETA Effect' has already been watched more than 700,000 times.

The phrase is named after Lord of the Rings director Peter Jackson's Weta Digital special effects company, which is responsible for films such as the 2005 King Kong remake.
Wary of the effect of overkill, some filmmakers are reverting to more traditional approaches to creating on-screen spectacle. 
An example is the new Star Wars film, due out in December, which will ditch an overload of CGI in favour of more "practical building".
Mr Lycette warns that CGI however, is here to stay. 
Just as the first computer-animated feature-length film, Toy Story, helped audiences become comfortable with a new species of animation, audiences and filmmakers will grow accustomed to films pumped-up with special effects.
"The younger generation brought up on this stuff are very much trained visually to be comfortable with it.
"It's the older people and anyone who wasn't brought up with it who struggle with it."


Read more: http://www.smh.com.au/entertainment/movies/the-weta-effect-how-cgi-and-special-effects-saturation-is-ruining-movies-20150703-gi4kws.html#ixzz47XCuOSPz 
Follow us: @smh on Twitter | sydneymorningherald on Facebook
.I 162
.T
document.162
.W
﻿Are the best computer animators only as good as the technology they use, or does natural talent distinguish their work from the rest? The question has been debated online this week after a new super-realistic computer-generated video appeared on YouTube.

At first glance, the minute-long commercial for Silestone kitchen worktops looks like slick, well-timed slow-motion footage of fruit falling in a shiny kitchen. It’s only when the peppers and pears smash like glass on the counter that it becomes clear these are not real fruit.

Alex Roman, the graphic designer who created the ad, dismisses suspicions that the shots aren’t pure computer-generated imagery: “Yep, it’s all CG. I tried to put some live-footage shots but I ran out of time so CGI did the trick.”

Although computer imagery is now common in blockbuster films – it was used, for example, to create the fantasy world of Pandora that was the setting of Avatar – it is usually created by large teams using special, often bespoke equipment. Roman, however, used off-the-shelf software and worked with just one assistant to produce the advert – and did it in a mere 10 weeks. Last year he also gained internet acclaim for his realistic, entirely computer-generated film Third and Seventh.

“This kind of talent is very exciting because you see there’s so much more to be done,” says Angus Kneale, creative director at the New York offices of The Mill, a visual effects studio. “People always say everything in CGI has been done before. This shows that’s not true.”

Raw talent?
Kneale believes what makes Roman so good is “sheer, raw, talent”. For instance, he uses tricks such as reducing the depth of focus to draw attention to certain details, which also reduces the need to carefully reproduce every last blemish on each piece of fruit in view.

Whereas most studios would need a team of people to accomplish such a project, Roman is “a master of all disciplines”, Kneale says. “Normally for that kind of quality you would need a team 10 times that size.”

Sofronis Efstathiou from the National Centre for Computer Animation in Bournemouth, UK, however, is not convinced. Although the work is impressive, he says it’s more to do with computer power than any new skills. “It’s obvious we can do quite photo-real CGI shots and no one can tell the difference. That’s been around for three or four years now.”

Kneale and Efstathiou agree on one thing, however – squeezing this level of realism from off-the-shelf software is impressive. For example, Roman used the popular Adobe Premiere package for editing the video and a special piece of rendering software – a favourite of architecture firms – to create the lighting.

Uncanny valley
Kneale says that Roman’s techniques could certainly be applied to feature films. So if the process is so quick and easy, could an artist like Roman use their skills to create a new breed of realistic, but entirely CGI movies?

“[This video] is very beautiful and very organic,” says Efstathiou. “But with characters it’s different.” Even the most sophisticated computer-generated actors still seem slightly unsettling – often attributed to the “uncanny valley” phenomenon, in which unfamiliar imperfections in an otherwise super-realistic caricature unnerve the viewer. It may seem paradoxical, but the less realistic caricatures of conventional animations can create characters that a movie audience engages with.
.I 163
.T
document.163
.W
﻿To understand the many issues in today’s modern computer graphics, you need to know how developed computer graphics from its beginnings to this day.

1950's - the first graphic displays, military applications

1962 - the first graphics station (sketchpad) consisting of a monitor, light pen and software for interactive operation constructed by Ivan Sutherland

1964 - research team working on the algorithms in computer graphics employed at the University of Utah (including Ivan Sutherland, James Blinn, Edwin Catmull)

1965 - the first commercial graphics  station: IBM 2250 Display Unit and the IBM PC 1130

1969 - beginning of a group SIGGRAPH (Special Interest Group on Graphics) in the organization of ACM (Association for Computing Machinery) gathering of IT professionals

1974 - creation of graphics laboratory at the New York Institute of Technology

1980 - Turner Whitted published article about creating realistic images, beginning of method of ray tracing

1982 - TRON, the first film that uses computer graphics. The first completely computer-generated scene in the movie Star Trek II: The Wrath of Khan

1983 - development of fractal techniques and their use in computer graphics. Fractals are used for example in the movie Star Trek II: The Wrath of Khan

1984 - work of C. Goral, K.Torrance, D.Greenberg and B.Battaile and proposing a new approach for visualization – the method of radiosity

1988 – the first film sequence with morphing in Willow

1989 - the first character created using 3D graphics in the studio Industrial Light & Magic (ILM)

1993 - dinosaurs in Jurassic Park – the first complete and detailed living organisms generated digital technology

1995 - Toy Story implemented complete using computer graphics, the first photo-realistic hair and fur computer generated

1999 –  the first character of the complete human anatomy in a computer-generated studio ILM

2001 - photon mapping as the development of ray tracing method

2009 - film Avatar – 3D cinema revolution

2009 - decision to create specialty Modern Computer Graphics for Applied Computer Science at the University of Science and Technology in Cracow

Summary
The beginnings of computer graphics were related to the military industry, due to the very high cost of equipment. The development of new graphics techniques has forced the film industry requires realistic special effects. Currently, computer graphics is used in many areas of lif
.I 164
.T
document.164
.W
﻿3D computer animation is less common in anime than it is in the West; they don't have a Pixar or a Dreamworks. So where is 3D animation used in anime, how has it developed, and how is it best applied?
AnalysisGamesArtVideoEditorial
by hoyvinglavin64
Feb 24, 8:57 PM | 9,427 views
Look at the major American animated films being released this year and you'll find almost all of them are 3D computer animation (Laika's Kubo and the Two Strings being a rare stop-motion exception). In contrast, 2D hand-drawn animation still makes up the majority of Japanese anime. Computers are still part of the production process. Almost every anime since 2000 has used computer coloring (Sazae-San was the last hold-out to switch from traditional cels to digital paint in 2013). The use of full 3D CGI, however, is much more limited due to a mix of budgetary issues and aesthetic tastes. Backgrounds and machines are frequently modeled and animated digitally, but anime with 3D CGI character animation are much rarer, and with a mixed success rate.

The '80s: The Birth of 3D Animation
The first usage of 3D computer animation in an animated film was in the 1983 movie Golgo 13: The Professional.



...the technology wasn't quite there to pull off the effect they wanted. To be fair, this was VERY early in the development of computer animation. Tron, the first movie to utilize CGI for longer than a few seconds, had just come out the year before. But Tron's visuals have aged better than Golgo's helicopter because it worked with the limitations of early CGI, setting the action inside a video game and going for a relatively abstract style.



The stylistic influence of Tron can be seen in 1984's Lensman movie, which featured computer-animated spaceships.

The '90s: Major Advances

CGI remained a rare novelty in anime throughout the '80s and into the early '90s. In 1995, however, the same year that Toy Story, the first fully-CG animated film, was released, Japan had its own technical ground-breaker in Ghost in the Shell. Considered one of the most impressive mixes of traditional and computer animation at the time, the 3D effects haven't aged as well as the hand-drawn work (in 2008 Production IG released a reanimated version to raise the 3D animation quality to that of the 2004 sequel), but Ghost in the Shell made 3D CGI viable for anime production. Soon TV anime such as Escaflowne and Cowboy Bebop would include 3D CG background effects.



Gonzo made a name for itself spending big budgets on anime with CG backgrounds and mechanical effects, starting with the OAV series Blue Submarine No. 6 in 1998. They even called themselves "Gonzo Digimation" up until July 2004, after the premiere of Samurai 7, at the time the most expensive TV anime ever made due to its extensive 3D mecha animation. Budgets fell at Gonzo since, and they're no longer considered the cutting edge of animation technology.



Even the traditionalist Studio Ghibli experimented with 3D effects. 1997's Princess Mononoke used computer animation to deal with the complicated tentacles of the cursed boar gods. They'd continue to integrate 3D CG elements into their films, most notably the castle in 2004's Howl's Moving Castle before Miyazaki decided to shutter the studio's CG department during the production of Ponyo.

The 21st Century: Common Uses of 3D CGI


So how is 3D CGI best used in anime? As this making-of video for the 2004 film Steamboy shows, it create extremely convincing backgrounds and vehicles that blend in with hand-drawn characters while allowing greater freedom of camera movement.


As CGI becomes cheaper, effects animation can achieve more complexity, allowing for 3D mecha battles like those in 2010's Mobile Suit Gundam Unicorn. "Cell shading" rendering provides cartoony outlines and sharp colors that allow the 3D visuals to match with the 2D animation.


Increasingly, cell-shaded doubles of traditionally-animated characters are used in anime for more complex action or dance sequences, such as this number from 2013's Love Live.

Fully Computer-Animated Anime


Fully computer-animated anime remain fairly rare. Japan's 3D animation talent is primarily focused on video games, so it makes sense many 3D computer-animated anime have been connected to video games (in the case of 1999's cheap and fascinatingly bizarre Gregory Horror Show, the anime came before a video-game, but it felt like watching a first-person video game cutscene minus the interactivity). Square attempted to get into the filmmaking business with the 2001 American co-production Final Fantasy: The Spirits Within, which attempted photorealistic rendering of human characters but fell short, falling into the Uncanny Valley for many viewers, and ended up a bomb.


2005's Final Fantasy VII: Advent Children, in contrast, went for a similarly detailed more stylized look with designs closer to traditional anime, and was better received. Films such as 2009's Oblivion Island and 2014's Stand by Me Doraemon have also translated traditional anime designs into full 3D to acclaim.


Some 3D CG anime go further in attempting to replicate the look of traditional anime with full cell-shading. The various movies of Appleseed have been done in this style, while the 2014 Netflix series Knights of Sidonia is probably the current most prominent example of a fully cell-shaded anime. But does Sidonia and other cell-shaded anime sometimes go too far in attempting to imitate traditional animation? The most controversial issue is frame rate. Traditionally-animated anime tends towards a lower frame rate, but various drawing techniques and modulation of frame rate make the more limited animation flow naturally. Shows like Sidonia and this season's Ajin also use a lower frame-rate, but due to the nature of 3D modelling aren't able to utilize the same techniques that lessen the choppiness of traditional anime and thus appear unnaturally choppy. If 3D computer animation is to grow in Japan as it has in America, its best bet is to embrace the individual strengths and work around the weaknesses of its own medium rather than merely to slavishly imitate 2D animation and pale in comparison.
.I 165
.T
document.165
.W
﻿In a recent interview with Gamasutra, Tim Sweeney, the founder of video game development company Epic Games, said ultrarealistic graphics in games aren't so far off.

PlayStation 3
The PlayStation 3's graphical prowess doesn't necessarily make games more appealing.
Don Reisinger/CNET
Within 10 to 15 years, Sweeney said, "completely realistic lighting, with real-time radiosity, perfectly anti-aliased graphics, and movie-quality static scenes and motion" will reach the video game industry. The only issue keeping developers from creating visuals that look close to real life, he explained, is computing power.

But will ultrarealistic visuals make video games more appealing? I believe game appeal is determined by more than meets the eye.

Multiple metrics
Most video game reviewers list "graphics" as one key factor in judging a game. If a title for the Xbox 360 looks as if it belongs on the PlayStation 2, chances are that the game won't get high marks.

But there are a number of other metrics. Does the game have solid controls? Is it fun? How's the story line?

Gaming bifurcation
We also can't forget that gamers are generally broken into two basic groups: the hard-core gamers who want epic story lines and realistic visuals; and the casual gamers who want fun, simple titles that aren't so realistic. (Some gamers like both epic and casual games, of course, though they judge them differently.)

Casual gamers are dominating the industry right now. Nintendo's Wii and DS are easily beating their more powerful competitors. And Apple's iPhone is quickly becoming many consumers' go-to device for casual handheld gaming. Meanwhile, the graphical leaders--PCs, Sony's PlayStation 3, and Microsoft's Xbox 360--are trying to catch up. That might tell us that realism in gaming isn't the most coveted feature. It seems that many gamers want casual fun.

And we can't forget that developers might not want ultrarealism either.

Developer costs
One of the biggest issues developers face is the cost of creating games. They're expensive and getting more costly each year. The amount of time, effort, and cash that would be required to create an ultrarealistic title might not be in the budget for many companies. Simply put, developers have a limited amount of time to get a game on store shelves. The more realistic the game's visuals are, the more time it will take to create it. A developer needs to determine how many resources it can afford to put into a game, such that it turns a profit.

Much more goes into a game than the way it looks. The story does matter. The controls are important. And in the end, it needs to be fun.

So as games become more realistic, and we all wait to see what developers will create next, it's difficult to see how realism translates into more appeal. A bad game with beautiful visuals is nothing more than a pig wearing lipstick.

Bring on the beauty. But be sure to bring on compelling stories too. Looks can only go so far.
.I 166
.T
document.166
.W
﻿Technology keeps transforming all aspects of the cultural resource industry, providing ever more tools to identify and evaluate historic properties. Computer generated imagery is the application of computer graphics to create still images and video. CGI is an effective tool to illustrate a variety of proposed design alternatives with a range of stakeholders and assess potential effects on historic properties for Section 106 consultation.

Taliesin, a nationally significant property in south-central Wisconsin associated with Frank Lloyd Wright is listed in the National Register of Historic Places, designated a National Historic Landmark, and a World Heritage Site candidate. Resources that contribute to the historic district include numerous buildings and structures and approximately 490 acres of the surrounding landscape that inspired Wright.

The use of CGI was critical in selecting designs to minimize adverse effects for two bridge improvement projects. At issue were the required beam guard and end treatments and the effects it would have on the view shed of the surrounding landscape. Numerous visualizations were completed from various vantage points to illustrate various types and colors of beam guards and end treatment options and the associated landscape work at each bridge location.

CGI provided the National Park Service, the Wisconsin State Historic Preservation Officer, Taliesin Preservation Inc., and local historical society with realistic visualizations for a range of beam guard designs under consideration and select an option that minimized adverse effects on the historic district to the greatest extent possible.
.I 167
.T
document.167
.W
﻿Computer generated images (known as CGI) have become very popular over the past two decades, and their importance and use will increase even further in the future because of their wide applicability in various fields. In the area of movies and films in general CGI has become an essential tool for filmmakers to bring their visions to the screen, be it by creating computer generated characters, props, sets, or just simplifying the process of image and sound editing. Film production ("Filmproduktion") has been made faster and more efficient in the postproduction phase, offering an unprecedented level of freedom and quality.

The success of 3D computer animation and CGI in general started in the early 90s, when software bundles and processing power got more affordable even for smaller companies, and since then it turned into an accepted art form by itself. Over the years the technology evolved further and further, lowering the barrier between art and technology, and even allowing these two extremes to blend seamlessly.

Creation of 3D graphics

The creation of CGI and computer animation requires the use of specialized software products. Several bundles have established on the market, and it is mainly a question of personal preference which one to pick. After all the biggest factor in creating convincing digital worlds is the artist himself, whereas the software is merely the tool to transfer his creativity onto the screen.

As graphics software became more user-friendly and intuitive, the process of creating CGI started to resemble its real-world counterparts, like painting, sculpting, photography and filmmaking. The area of computer animation for example requires the same steps of "real world" filmmaking, with the addition of modeling sets, props and characters first. Bringing a mass of "digital clay" into shape to form a convincing character (or any other object or location to be shown, for that matter) is the initial step. Then cameras, lights and other entities are arranged in the virtual space, and animated if necessary. Computer animation might be called the digital successor to the classic Harryhausen-type stop-motion animation, although many other ways of animating virtual objects and characters (like physical simulation or motion-capturing techniques) have evolved over the years. The last step is called "rendering" and describes the process of collecting all information of the scene and light setup to process and output the final image through the lens of a virtual camera, either in the form of still frames, or a series of frames which create the illusion of movement.

Television, film production and commercials

Computer animation and three-dimensional visualization ("Visualisierung") is widely used in television, commercials and film production. The "small screen" has proven to be the perfect field for experimenting with newly developed technology and concepts, and many artists working in the area of television and commercials have made their way to the movie business. With software bundles getting cheaper and more accessible, independent artists and filmmakers seized the opportunity to create their own films and short films, a development, which gave the visual quality of films an enormous boost in the mid 90s. In the area of film production computer animation slowly started replacing hand-made models and puppets, and even the genre of animated films has gotten a digital counterpart.

The area of commercials has grown into other branches like industrial documentations ("Industriefilm") and corporate video ("Imagefilm"), and besides entertainment computer animation is also used in the fields of education, interactive media ("3D Online") and military application.

Scientific visualization

Computer animation produced to present meteorological data, medical imaging, industriefilm, architecture and technology.

Product design and engineering

Designers and engineers use special CAD (computer aided design) software for designing, developing and manufacturing consumer and industrial products. Product visualization extensively uses modern graphics technology and with the help of computers, designs can be rotated, cut and manipulated even before getting manufactured. This greatly helps engineers visualize the product that they are designing.

Copyright information.... This article is free for reproduction but must be reproduced in its entirety; live links & this copyright statement must be included.

.I 168
.T
document.168
.W
﻿Social, Ethical, and Legal Issues in Computer Graphics

Recognizing the importance of computer science an inquisitive being might ponder the changes it has brought to society: life-style, legal and ethical issues, and knowledge advancement. Contemplating these subjects in computer graphics can lead to many interesting discussions.

Changes in life-style

Few would quarrel with the statement that computers have brought changes in our lifestyle. Whether or not these are good or bad is however a contentious subject. There are several contributions graphics has made that have changed the way we live.

The use of computer generated effects in movies is one area where graphics has had a significant role. Synthetic actors are forming guilds ;o) Computer art, although it has not replaced the palette and chisel, is becoming a medium that artist are exploring and creating significant new work.

Some are predicting that virtual reality will become the dope of the brave new world. Will be plug in and tune out or turn on using computer generated images and sound in the not to distant future?

Of course, we can not get by without discussing sex, more specifically pornography which is rampant on the Internet and supported by techniques developed by the computer graphics community.

Computer graphics have also played a fundamental role in improving medicine and diagnosis of illnesses.

Legal Issues

One legal issue that has arisen recently and is related to computer graphics is Microsoft's Antitrust trial. The government claims Microsoft stifled Intel's work on signal processing and graphics software and attempted to leash Apple's Quicktime. The Findings of Fact from the Microsoft Antitrust Trial at URL http://www.usdoj.gov/atr/cases/f3800/msjudgex.htm discusses these issues, in particular check out paragraphs 94-110.

On a separate track, attorneys have begun to use computer simulations with graphical recreation of crime scenes to provide better explanations to juries. There are several legal issue that can arise by using graphics in this way: How accurate are the simulations? Have they been enhanced (perhaps speculated graphic violence or audio) to project a particular point of view? Who controls the content of these simulations?

Ethical Issues

From the very beginning (Whirlwind and SAGE) computer graphics has been used by the military to prepare for or defend against war. Modern weaponry depends on computer generated images.

Violence in computer games is another issue that has been in the news. Shooting as schools and violent acts by youngsters have cause many to speculate that playing violent video games has been a leading cause of these violent acts.

Advancement of Knowledge

Computers have augmented the rapid accumulation of information and an awareness of the world and universe in which we live. This increased understanding is evident in the physical sciences (physics, biology, chemistry, medicine) and social sciences (economics, anthropology, environmental studies). Computer graphics, and in particular, scientific visualization has been critical in furthering our understanding by providing us with pictures, images, and animations that show how events unfold in scientific simulations.

Jim Blinn got his start (well, maybe he was already going) at JPL with his simulations of planetary fly-bys in the late 70's. Other researcher routinely use computer graphics to help verify theories, predict new results, or to make hypotheses.

Problems Related to Ethics

1.
When Fussell and Fournier first discussed the use of fractals in the creation of special effects for movies, Mandelbrot countered that they were not his true mathematical fractals, but crude approximations. How do you respond to the slogan ``if it looks good, do it'' that describes how many computer graphics effects are not based on good science but good viewing?
2.
Should a computer programmer be held responsible for the development of a program that is used in medicine and leads to the mis-diagnosis of an illness? Write a paper on your opinion.
3.
What is your view of censorship on the Internet? Write a paper discussing the issue.
4.
Based on your reading of the findings of fact in the Microsoft antitrust trail and other research, write an essay that debates the issues related to Intel's work on signal processing and graphics software or Apple's Quicktime product.
5.
What is your opinion on violent computer graphics games? Write a paper discussing the issue.
6.
Should graphics simulations be allowed in trials? Defend your views.
7.
Explore how computer graphics are used to advance science and engineering. Write a paper on the subject.
8.
As a computer graphicists how would you feel if your inventions or code were used by the military?
.I 169
.T
document.169
.W
﻿« Newer story Older story »
"No-one has realised" that most homeware
catalogue images are renderings
Flip
27 November 2013 | 35 comments
Categories: InteriorsNewsSlideshows

News: the images in most kitchen, bathroom and bedroom catalogues are computer-generated but "no-one has realised", according to a leading CGI artist (+ slideshow).

Pikcells CGI renderings for catalogue images kitchen

"Many furniture manufactures are using this medium to put together their catalogues and such," said Richard Benson, creative director at digital imagery studio Pikcells. "The technology can now make these wonderfully realistic images as good as photography, and in some cases better."

Pikcells CGI renderings for catalogue images kitchen

He added: "Most kitchen, bedroom and bathroom companies now use CGI to create their marketing material and no one has realised."

Pikcells CGI renderings for catalogue images kitchen

Last summer flat-pack furniture giant Ikea announced it was starting to use digital images in its catalogues and online galleries, predicting that up to a quarter of all its images would eschew traditional photography by this year.

Pikcells CGI renderings for catalogue images kitchen

But Benson said that things have moved faster than even Ikea predicted. "It's not just Ikea," he said. "We design a lot of the [digitally created] spaces ourselves for some of the world's biggest homeware brands."

Pikcells CGI renderings for catalogue images kitchen

Benson said the rapid advances in digital image-making were leading to the mass closure of photography studios that specialised in interior and product shoots for brands. "It's quite a big deal as lots of photography studios have been uprooted," he said. "Over the past five years, there's been a few studios that have really come to the end of their time doing room sets and have seen CGI coming through and packed up shop and called it a day really."

Pikcells CGI renderings for catalogue images kitchen

Other photography studios have embraced CGI and turned themselves into digital studios. He added: "We've been brought in to produce what the photographer was doing anyway. The end if the same but the means is different."

Pikcells CGI renderings for catalogue images kitchen

He explained that rendered images offer clients greater speed and flexibility than photographs, plus lower costs. "With photography, you're always going to be restricted by what you can build and what materials you can use and what furniture you can get a hold of, whereas with CGI there are massive 3D libraries now where you can buy really high quality digital models and textures and drop them straight into your images."

Pikcells CGI renderings for catalogue images kitchen

Computer renderings also allow sets to be re-used and adapted easily, Benson said. "In photography, people build massive sets and then they just throw it all in the bin afterwards, whereas we can reuse the sets over and over again. They're just stored in the computers so we can pull them out and make quick changes and reissue images."

Pikcells CGI renderings for catalogue images kitchen

Car brands have been using computer-generated imagery for advertisements for years, he added: "A lot of the adverts you see on TV [involve] CGI cars," he said.

Pikcells CGI renderings for catalogue images kitchen

Magazines try to avoid publishing CGI images, Benson said, but they often published them unknowingly. "We've had loads of our stuff in magazines," he said, including a recent interior that Pikcells developed from scratch for wood and laminate brand Kronospan. "A kitchen from the Fresh project was featured in Grand Designs in the future kitchen section and I don't think they knew it was CGI."

Pikcells CGI renderings for catalogue images kitchen

Leading architectural visualiser Peter Guthrie spoke to us last month about how architectural renderings are now "indistinguishable from photos," and Benson says that producing renderings for catalogues requires even higher photo-realistic qualities. "In the work we produce, the images have to be really photo-real as they are sitting alongside existing photos in many catalogues," he explained. "Architecural visualisation doesn't generally have this issue. The expectation is lower as most people realise it's CG, because what they are looking at is not built yet."

Pikcells CGI renderings for catalogue images kitchen

An example of this is a Swiss studio that created a computer model of an unbuilt Zurich theatre designed by Jørn Utzon in 1964, to show that the building "could be built now".

Pikcells CGI renderings for catalogue images kitchen

Today, most furniture brands use CGI instead of photography for the room sets in their catalogues, Benson said. "I would say 80 percent of the furniture manufacturers out there are using CGI for kitchen, bedrooms, bathrooms, living rooms, etcetera. It's sort of happened in the last five or six years. It came at the right time, when the software was good enough and when the hardware was affordable enough to process the power needed to render these images."

Pikcells CGI renderings for catalogue images kitchen

Ikea led the way with digital images of its kitchens, which are relatively easy to generate, given that they feature hard, flat surfaces with predictable reflections. However, Ikea has still not mastered the art of creating realistic bedroom images, Benson said, due to the complexity of computer-modelling bedlinen and soft furnishings.

Pikcells CGI renderings for catalogue images kitchen

Even that is changing, with software and processing power now able to create convincing fabrics. "Soft furnishings and fabrics [are] becoming extremely realistic to the point where we've started to use CG bedding and cushions and things," Benson said.
.I 17
.T
document.17
.W
IMAGINE THE IMPOSSIBILITIES.

When most people think of CGI (computer generated imagery), they think movie special effects or flying logos. But CGI can also be used to visualize technical concepts that would be difficult to illustrate in any other way.          

CGI is also a useful way to create very high quality photo-realistic illustrations.  

What is Computer Generated Imagery?

Think of it this way: CGI attempts do virtually with numbers, what a camera does with light. In designing these virtual environments, we create and position models, cameras and lights in a similar way you would in a real studio (even setting things like depth of field or light fall-off). But we can do some strange things that would be impossible in reality. Our world is unbound by gravity or other physical constraints. With such open ended possibilities, imagination and artistry become very important.

 

What can you use it for?

Beyond flying logos, we have used CGI to:

Illustrate medical devices
Demonstrate mechanical processes
Render product prototypes
Visualize a wide variety of complex graphic concepts
Create artwork and book illustrations
How does the process work?

Create the digital 3D wireframe models

Our "sculpting" software tools are one way to create models. We can also work with 3D scanners or existing CAD/CAM files.

Assign visual properties to the wireframe objects

Attributes like highlights, transparency, refraction, reflection and an unlimited array of texture maps can be set.

Animate camera, objects, lights, etc.

This can be as simple as panning a camera across the subject. It can also involve a team of animators (did you stay for the credits after the movie Avatar?)

Render the scene

Our computers can be a set to render multiple frames for an animation sequence or just one very high resolution frame for large format print use. Imagine billboard sized CGI.

.I 170
.T
document.170
.W
﻿Our 3D CGI programme has been training students and preparing them for industry for more than a decade. We offer two main pathways: Modelling & Animation and Architectural Visualisation. Whichever pathway you enrol on the first year is generic to provide a solid base of 3D skills. Architectural Visualisation is intended for students who wish to make photorealistic visualisations of buildings, game environments and virtual set extensions for films. It includes architectural modelling techniques from CAD, texturing, lighting, rendering and post-production for stills and movies. This is a popular pathway and visualisation graduates are highly sought by industry. Our assessment is almost all coursework based and we operate in a studio environment with small groups of typically 12-15 students. Art is taught throughout to encourage creativity and visual communication. There is an individual project element to every year which helps students build a good portfolio for future interviews. We offer excellent facilities with 5 hi-spec computer suites and have cutting edge resources including an inertial motion capture suit, hand-held 3D scanner and 400-core render farm – all of which are incorporated in our coursework and available to students for use in projects.
Our CGI programme prepares students well for industry with experience of deadlines and a strong work ethic and our graduates work in over 100 different companies including many of the big games, visual effects and visualisation houses such as Codemasters, Double Negative, MPC and Visualhouse. With a Foundation Degree in Architectural Visualisation and a good portfolio, graduates will typically find junior positions in the huge number of small / medium sized visualisation companies in the UK and abroad. However your progression opportunities are increased by continuing with our BSc top-up programme which is one year with an optional placement year in industry. Many students who take placements are invited back on a permanent basis after graduating from the BSc top-up.

.I 171
.T
document.171
.W
﻿Computer-generated imagery is ubiquitous and has infiltrated our everyday entertainment experiences. Most major movies, many TV series and an increasing number of commercials routinely use CGI technology. Far from inhibiting creativity, the technology has clearly helped directors, writers and creatives push new boundaries.

ComputerGeneratedWhile all this has been occurring in entertainment, CGI hasn’t yet made the same revolutionary impact on business. Or has it?

CGI has the potential to completely change established marketing practices. To start, digitizing product portfolios instantly optimizes brand design and marketing. Imagine creating a complete computer-generated product portfolio, allowing the client to implement or change any asset or product in the design or marketing process.

For marketers, the benefits of creating photoreal products and blending those images with real-life material, is compelling in terms of cost-effectiveness and creative possibilities. For example, we have digitized every option for every car within Mercedes-Benz’s entire product portfolio. These images are now used across a vast range of marketing materials from advertisements to online showrooms.

CGI product portfolios will also have more prosaic uses. They will enable brand managers in a global fast-moving consumer goods company to curate and manage the vast range of product design variations across markets worldwide. A hair conditioner variant carrying a particular promotion in a certain market will be instantly retrievable.

Virtual designs are also becoming a pivotal part of new product design and market testing, enabling brand manufacturers to experiment much more fluidly with designs and test consumer reactions at a fraction of the cost. Recreating product portfolios virtually requires technologies and data management techniques that are a far cry from those implemented on films. With billions of image variables in a product range, the challenge is as much about data processing as it is rendering.

CGI product configurators are already established in the automotive sector and are infiltrating a far wider range of markets. Giving consumers access to real-time visualization and customization of products through sophisticated configurators could help pivot mass manufacturing processes to mass customization.

CGI visualization could stimulate a far more profound shift in the world of brand manufacturing. As CGI production software becomes accessible to consumers, it could create a revolution in grass roots design with the consumer able to dream up sophisticated products, design them, and collaborate to test whether there is a market for them.

CGI branches out into many different elements of a consumer’s daily life, whether they know it or not, and here we are beginning to see how the relationship between consumer and CGI could really evolve. The impact of CGI on the consumer is far more than the visual delights of Hollywood; its effects in the worlds of marketing and business are clearly going to make waves
.I 172
.T
document.172
.W
﻿Pc-generated imagery (CGI)  is the application of pc snap shots to create or add to images in painting, written media, video video games, films, TV techniques, advertisements, as smartly as simulators. The visible scenes can possibly be dynamic or static, and can possibly be two-dimensional (2D), while the name “CGI” is mainly commonly used to seek advice from 3-D laptop snap shots used for developing scenes or distinctive effects in films and television. They can definately also be utilized by a home consumer and abridged jointly on products such as Windows Film Maker or iMovie. The phrase laptop animatronics refers to dynamic CGI rendered as a movie. The phrase virtual global refers to agent-primarily based, interactive environments. Computer photographs program is used to make pc-generated imagery for films, etc. Availability of CGI software program and improved laptop speeds have allowed private artists and small businesses to create skilled-grade films, games, as neatly as exceptional artwork from their individual desktops. This has caused an On line subculture with its own array of international celebrities, clichés, and specialized vocabulary. The evolution of CGI led to the materialization of digital film making in the Nineties the place runs of the simulated camera don’t seem to be constricted by the laws of physics
.I 173
.T
document.173
.W
﻿Robin Wright is standing in the middle of a huge geodesic dome of LEDs and cameras, giving her very last performance. As she sobs bitterly, her every move and micro-expression is scanned. Later an artificial version of the actress will be created to take her place in all of her future films; the real Robin Wright will be redundant.
Princess Bride fans needn’t panic just yet, though. The scene is from Ari Folman’s new film The Congress – a trippy, dystopian vision of a future in which artifice has displaced reality. But it is a future that may be closer than we think.
Virtual characters in films are nothing new. The first – a computer-generated knight – appeared in The Young Sherlock in 1985, and since then we’ve seen everything from artificial extras in Titanic to detailed motion-capture characters such as Gollum in The Lord of the Rings. And while some virtual human faces still creep us out (Polar Express, anyone?), a few have graced our screens without us even realising. Brad Pitt’s reverse-ageing process in The Curious Case of Benjamin Button, for example, was created not with prosthetics but with computer-generated imagery (CGI).
READ: How do you teach a computer to speak like Scarlett Johansson?
“Very few people watching that film even knew that [CGI] was going on,” says Darren Hendler, digital effects supervisor at Digital Domain. “We are at the point where we can create a digital version of an actor that is indistinguishable from the real person.”
Related Articles
The best films in cinemas now 24 Apr 2015
Watch Robin Wright in The Congress 14 Aug 2014
There are plenty of reasons to welcome the technology. Eventually, it could democratise movies, allowing anybody to make a film using a cast they have created. There are also financial advantages, says Professor Nadia Magnenat Thalmann, who has pioneered research into virtual humans for the past 30 years. “On some films it costs a fortune to hire real actors,” she says. “We’re able to make virtual actors look great – and as soon as we can automate the process, there will be a cost-benefit analysis. If it’s cheaper, second-rank actors will be done more and more by computer.”
According to Hendler, some actors are already embracing the process and having themselves scanned. “If they’re in a movie later on where they need to be younger, they already have that snapshot,” he says. “They are starting to archive their digital selves.” But they’re also wary. Tom Cruise, who was scanned for his role in Oblivion, had his data hand-delivered to his house and all other copies destroyed. “The more experienced actors will start to have more control over their contracts with the studios; more say over how their final digital likeness looks and how it is used,” says Hendler.
But if Folman’s vision becomes a reality, films might even be cast using digital versions of actors who have long since died. It is already possible to create fairly convincing virtual versions of actors who were never scanned, using old footage and performance doubles. And, a CG version of Paul Walker has been created to complete Fast and Furious 7, after the actor died part-way through filming.
There are also developments that could make real actors, even in their digital forms, completely redundant. “The big trend is to make virtual humans conscious of their environment and intelligent,” says Magnenat Thalmann. If successful, film-makers will one day be able to create virtual actors who respond to their direction autonomously.
Luckily for the acting community, this technology is nowhere near fruition. “I think the top actors have nice days in front of them,” says Magnenat Thalmann. “Because, although I’ve pioneered this field of virtual humans, I have never seen one that is realistic that can also act.”
Hendler, meanwhile, thinks any virtual character will be useless without a human driving the performance. “More and more we’re finding that we have to rely on actors to create anything that’s moving and believable,” he says. “The motion-capture techniques are getting better all the time and I think we’ll always rely on the capture of an actor, because that’s what an actor does. We can’t just create a performance out of thin air.”
For now, it seems, Folman’s dystopian fantasy will remain just that.
.I 174
.T
document.174
.W
﻿Although her looks indicate otherwise, Saya is not your typical Japanese schoolgirl. Her parents, Teruyuki and Yuki Ishikawa, have big dreams for their beautiful daughter. They want her to play a character in a movie they are self-producing. Where will she find the time with all her schoolwork? Not to worry. Saya is only as real as the pixels on your screen. Her soft cheeks, lush, black hair and hazel-brown eyes are all computer-generated imagery.


Teruyuki and Yuka 3d CG Japanese schoolgirl

Computer graphics have improved so drastically in recent years that it’s becoming difficult to tell the difference between real life and renderings. But given a close look, I’m pretty confident in discerning one from the other. And when I first saw Saya I was convinced she was real. Only now, after looking at her revealing, skinless mock-ups, do I start to pick up on Saya’s subtle non-humanness.

Her creators, the Ishikawas, are a husband-and-wife duo who, together, are Tokyo-based freelance 3D CG artists. Saya was gently brought to life in their spare time as they attempted to balance commercial work and personal projects. According to the artists, the hardest part was achieving the moist, soft and translucent skin of girls this age. The hair, they add, is not up to their expectations.

Teruyuki and Yuka 3d CG Japanese schoolgirl

A counterpart to Saya is also in development and both of them will be put to motion in the duo’s self-produced film. So we have that to look forward to
.I 175
.T
document.175
.W
﻿Last night, 17th April 2012, at a concert in Coachella, California, the rapper Tupac appeared on stage in a special performance alongside Dr. Dre and Snoop Dogg. The problem is that Tupac died in 1996.
What appeared to audiences as a live performance from the renowned rapper was in fact a very realistic computer-generated projection of him performing and appearing to interact with the audience, alongside Dr. Dre and Snoop Dogg, who were actually there in the flesh. This use of computer-generated imagery, which has been described by experts as similar to a 19th century magician’s illusion, is now set to change the limits of entertainment and broaden its boundaries. It has already been used at a Black Eyed Peas concert, where two of the group members were unable to be present and were instead projected, using a hologram-like image, on to the stage. Now, experts claim this technology is set to change the boundaries of communication, as they have already managed to successfully project live images of people, not just pre-recorded ones. For example in a news broadcasting studio, correspondents who are thousands of miles away could appear to be reporting live from within their home studio.
Before the technology has a chance to alter our expectations of entertainment and communication however, it may need to find a way to become more economically accessible; MTV news have reported that the company that created the Tupac ‘hologram’ charge between $100,000 and $400,000. There are also possible ethical issues involved, especially as projecting such realistic images of people who have been dead for years may be deemed not just insensitive but even offensive.
.I 176
.T
document.176
.W
﻿Learn about the education and preparation needed to become a graphics engineer. Get a quick view of the requirements as well as details about degree programs, job duties and necessary skills to find out if this is the career for you.

Show Me Schools
View 10 Popular Schools »

Essential Information
Graphics engineers use computer hardware and software to represent and manipulate data and content for interactive video games or other applications. Most employers require candidates to hold a bachelor's degree in a field related to computer engineering. Prospective graphics engineers should also be familiar with programming language and 3-D math.

Required Education	Bachelor's degree in computer or software engineering or related field
Other Requirements	Knowledge of programming and 3-D math
Projected Job Growth (2012-2022)*	23% for applications software developers
Median Salary (2014)*	$95,510 for applications software developers
Source: *U.S. Bureau of Labor Statistics

Job Description
Graphics engineers create integrated graphics and visual effects systems that are used in the design and development of software applications, such as video games and operating systems. In terms of occupational focus, they are most closely associated with computer hardware engineers and software developers.

In particular, graphics engineers write code in various programming languages to create a visual user interface for systems software or end-user programs. They may also consult with art directors, graphic designers and other related professionals to provide them with the computer tools and software they need to produce motion graphics and visuals.

Job Duties
The job duties of a graphics engineer can include the creation and implementation of asset pipelines, including the architectural frameworks needed to optimize CSS style sheet languages and JavaScript. They also create, document and test computer codes and systems for animation, audio, memory and streaming features, among other areas.

Graphic engineers use application programming interfaces (API) like Microsoft's Direct3D and OpenGL to build 3-D engines and rendering systems for 2-D and 3-D visuals. They may also script with Maya Embedded Language (MEL) or work with Adobe After Effects, a digital motion graphics program used for 2-D animation, color correction and image adjustment in film and television.

Professional Requirements
Education
Specific degree programs in graphic engineering are not available, but several programs include relevant coursework, such as a bachelor's degree in computer or electrical engineering, computer science or software engineering. Undergraduate and graduate programs in computer or electrical engineering may include topics in circuitry and digital systems design. Software engineering programs at both the bachelor's and master's levels may provide training in computer architecture and organization, computer and human interaction, data structuring and math modeling.

Graphics engineers in particular should have four years of coursework in C/C++ programming languages and training in 3-D math. Degree programs specific to game development and interactive design that lead to a bachelor's or a master's degree are also available. These programs include courses in animation, modeling and rendering, design aesthetics and user-centered design. Training in the use of new media, such as digital audio and video production, may also be included. Depending on the program, graphics engineers may pursue related coursework in narrative content development and scripting.

Required Skills
In addition to a sense of creativity and attention to detail, graphics engineers should have an in-depth knowledge of computer capabilities and programming languages. The ability to anticipate game user needs and work as a member of a team to solve problems related to the design and development of software are also important.
.I 177
.T
document.177
.W
﻿Located within the Toho Studio, which is adjacent to the prestigious residential area of Setagaya, Tokyo, Picture Element Inc. (Picture Element), is a post-production company that combines live-action images with computer-generated (CG) imagery to create visual effects (VFX) for movies, television dramas, and advertisements.

"We only started using the FARO Laser Scanner Focus3D in 2013, but as of May 2014, we have since used it for five films,” explained Mr. Tetsuo Ohya, President and Technical Producer of Picture Element, who has over 30 years of experience in the filmmaking industry. “It is now essential to our work in CG modeling, synthesizing live-action with other types of images, and incorporating CG imagery into computer-animated movies.”

“We used the Focus3D for producing about 20 cuts in the movie, Kiki's Delivery Service,” revealed Mr. Toshiya Harada, Production Manager of Picture Element. “We also scanned the entire Kobe Fruit & Flower Park to create a 3D model as a backdrop for the movie, Miracle Debikuro's Love and Magic, which is currently in production.”

Point Cloud Data for A Variety of Video Productions

Data scans from the Focus3D have been used in a variety of video productions. In Kiki's Delivery Service, one of the scenes featured a CG model of a black cat named Gigi, which appeared on-screen, walked onto a real table and stone steps, then jumped off-screen. Point cloud data was used to precisely match live-action and CG imagery. The actual scene had to be measured for the CGI to match up, but curved surfaces – which were the stone steps in this case – could not be measured manually. “Scanning with the Focus3D enables us to match CG imagery of the black cat to the live-action in a precise manner,” noted Mr. Naotaro Takahashi, Digital Imaging Technician & VFX Supervisor of Picture Element.

Mr. Harada continued, “There was another scene in Miracle Debikuro's Love and Magic that showed the fruit park decorated with Christmas lights. We scanned everything at the scene with the Focus3D, including the buildings, the park, and the fountain. With that data, we created a 3D model for the video projection mapping in VFX.”

For the project at the fruit park, several separate scans had to be performed as one of the buildings in the park was U-shaped. Using the Focus3D, 12 scans were taken from various locations around the building, which were eventually stitched together to form a single set of point cloud data. 

The entire site, ranging from the terrace to the four locations around the fountain, was then scanned to create a total of 18 sets of point cloud data. As the Focus3D had a small form factor and was lightweight enough to be carried around easily, the project could be completed in just a short period of time. Mr. Harada commented, “We used the Focus3D for this project and we operated the device easily, measuring at distances of up to 120m with no issues.”

Two suites of software, FARO SCENE and Geomagic Studio, were used to process the point cloud data and create the 3D model.

Shooting in a Remote Location with Scan Fragments

In another live-action movie, Attack on Titan, the Gunkanjima (also known as Battleship Island) in Nagasaki was chosen as the film location. The island used to be occupied by coal miners but it has since become abandoned and uninhabited. Numerous scans were taken for use in the movie, and the Focus3D was instrumental in the acquisition of data for scene building later on.

1
Creating a 3D model of the film set with the FARO Laser Scanner Focus3D.

“Access to this site was restricted and shooting times were limited,” said Mr. Ohya. “As the structure of the buildings and terrain was complex, we could not think of any method other than to use the Focus3D under such conditions. We basically scanned everything that was on the island, because we had not decided where and how we wanted to shoot on location. Based on the point cloud data collected, we examined the fragmented shots and used the data to recreate miniature models or CG imagery.”

In other words, the point cloud data collected by the Focus3D was used as a 3D storyboard. The device’s the ability to record detailed information of a site in 3D, as well as the ability to examine scenes from various angles, are some of its unique benefits.

On a film set, the ceiling of the building may not always be suitable for a shoot. In such cases, the desired look can be synthesized into the scene in post-production using CG. As the shape of the ceiling changes with camera movement in 3D, the CG ceiling can only be synthesized realistically if a high-accuracy scan of the scene was acquired with the Focus3D beforehand.

A Chance Encounter with the Focus3D

The Focus3D is now essential to the post-production work that is done at Picture Element, but it was a scene from the DNA investigation themed movie, Platinum Data, that led the company to its discovery.

Mr. Ohya recalled, “In this movie, set in futuristic Japan, there was a scene where a laser scanner was used for forensics in the police investigation of a crime scene. The Focus3D was brought in merely as a prop on set. As video production professionals, we were more intrigued by the Focus3D than the film set. Subsequently, we actually tried the device by scanning the set. Upon checking the point cloud data, we discovered that it was a practical solution for us. That was when we decided to introduce it into our workflow.”

2
Today, the FARO Laser Scanner Focus3D is indispensable to Picture Element.

He continued, “For us, the challenge was to see how fast, accurate and easy it would be to take measurements. I knew that a laser scanner would be useful, but we did not think we could afford to spend 20 million yen for a device like this. It was almost by luck that we discovered the affordable Focus3D.”


.I 178
.T
document.178
.W
﻿ALGORITHM ENGINEERING FOR PROBLEMS IN COMPUTER GRAPHICS

This project deals with algorithm engineering problems of computer graphics. It covers the issue of modelling graphics hardware and 3D-scenes as well as the development, analysis, implementation and experimental evaluation of rendering algorithms. The project is part of the research cluster Algorithm Engineering and is funded by the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG).

Project description

Algorithm Engineering – development of adequate models of hardware and realistic input, to couple the theoretic design and analysis of algorithms closer to implementation and experimental evaluation – in computer graphics is a challenging task.

Computer graphic algorithms are strongly supported by the used graphics hardware. This makes it necessary to integrate the properties of the graphics card into the model of the hardware.
Depending on their field of application, "typical" 3D-scenes show very different characteristics, like density, overlapping factor or fill rate.
As consequence, an analysis of the running time solemnly depending on scene parameters is not very meaningful; running time has to be expressed by a function of several parameters which describe both, the scene and hardware characteristics.
Objective

The intention of this project is to develop, analyse and implement rendering algorithms for virtual 3D-scenes and to evaluate them experimentally. Therefore we want to combine theoretical and experimental development and analysis as described above. We aim to gain detailed methods for running time estimation, which allow reliable efficiency comparisons between different algorithms. We will particularly concentrate on occlusion-culling techniques (computation of hidden parts of a scenes), as their efficiency does highly depend on hardware and scene characteristics. This makes them especially applicable for our analysis. As a long-term goal we consider the development of algorithms which are adaptive in sense of autonomous adapting to the characteristics of the available hardware and a given scene
.I 179
.T
document.179
.W
﻿Features

Presents a model-based control technique where the control system design (PID-based) is derived from a data driven process
Describes the data-driven model estimation technique using the system identification methodology on the rendering process, which provides better accuracy
Introduces the concepts of how control systems work with real-time computer graphics
Offers knowledge and skills in designing and implementing solutions based on this book
Discusses a practical solution to solving a challenge in resource allocation and the trade-off between quality and speed in interactive computer graphics rendering
Summary

Consumers today expect extremely realistic imagery generated in real time for interactive applications such as computer games, virtual prototyping, and scientific visualisation. However, the increasing demands for fidelity coupled with rapid advances in hardware architecture pose a challenge: how do you find optimal, sustainable solutions to accommodate both speed of rendering and quality? Real-Time Rendering: Computer Graphics with Control Engineering presents a novel framework for solving the perennial challenge of resource allocation and the trade-off between quality and speed in interactive computer graphics rendering.

Conventional approaches are mainly based on heuristics and algorithms, are largely application specific, and offer fluctuating performance, particularly as applications become more complex. The solution proposed by the authors draws on powerful concepts from control engineering to address these shortcomings. Expanding the horizon of real-time rendering techniques, this book:

Explains how control systems work with real-time computer graphics
Proposes a data-driven modelling approach that more accurately represents the system behaviour of the rendering process
Develops a control system strategy for linear and non-linear models using proportional, integral, derivative (PID) and fuzzy control techniques
Uses real-world data from rendering applications in proof-of-concept experiments
Compares the proposed solution to existing techniques
Provides practical details on implementation, including references to tools and source code
This pioneering work takes a major step forward by applying control theory in the context of a computer graphics system. Promoting cross-disciplinary research, it offers guidance for anyone who wants to develop more advanced solutions for real-time computer graphics rendering.
.I 18
.T
document.18
.W
What is CGI Animation
CGI ANIMATION OR COMPUTER-GENERATED IMAGERY ANIMATION
is the use of computers to establish computer animated graphics for special effects on motion pictures and video game graphics. CGI animation is applied not only in films like “Toy Story” and “Shrek,” but also in virtual reality, theme parks, and scientific search. For those looking for an occupation or those who simply want to acquire a new hobby, CGI animation is an interesting, thrilling field with lots of room for expansion and development. It calls for costly devices and software. Considering that technology is ever evolving, you have to keep pace with new development if you want to excel in CGI animation.

What is CGI animation exactly? It is simply an approach that uses software to simulate the animation tools of the past. CGI animation has various segments that include two-dimensional, three-dimensional and web animation. Computer Generated Imagery involves creating multiple frames of a drawing and designating key-frames, with a couple of clicks of the mouse. This is the most popular form of CGI animation that we are knowledgeable with. Maya, Lightwave, and 3D Studio Max are the industry standard tools that are used to build character models, environments, and textures.

The method to generate an animated character begins with a model. (See the 5 steps in CGI Animation) Compared to 2D, the animator must now lift the image off the paper and begin to see it in a three-dimensional space. A human model may be initially formed in clay, with all the details of texture and form. Then this model is duplicated by the animator with the 3D software tools. The work is not as uncomplicated as it sounds though. The animator still has to create the animated character or scene, either commonly by hand drawing one image or creating it from scratch with the computer. The main difference is instead of thousands of drawings, you can now use a handful which are duplicated with your software program. You can then manipulate the images to form the animation.

We have all enjoyed watching ‘donkey’ in the Shrek movies or loved the character of ‘Woody’ in the Pixar movie, The Toy Story. However, not many of us know the behind-the-scenes story of these animated movies. The use of computer generated imagery or CGI animation in movies, television, and commercial media, has met with increasing excellence over the forty years of its growth and usage. However, the resounding success of these animated graphics, has also increased some interesting questions related to its techniques, popularity and its significant limitations.

CGI Animation Definition and The Strategies

A subset of the broad field of animation, CGI or computer-generated imagery, can be defined as the use of computers for making transferring images. Using certain 3D animation software tools like Maya, 3ds Max or Blender, the first step of CGI animation, requires producing a ‘wireframe’ or a geometric model of the object. Now, the surface appearance of the object has to be determined. This involves providing color, texture, reflectivity and transparency to the objects in question, with the help of tools known as ‘shaders’.

The final step in the animation process requires the computer rendering of the full scene. This involves the calculation of the color of the pixels in the scene, which determines the shading, texture mapping, reflection, refraction and photo-realistic rendering. This may sound easy, but given the millions of pixels in a high-definition scene, providing the realistic animal movements, skin, hair, and fur, is still quite a complex task. Not to mention the problems areas of introducing features like liquids, gasses and complex surfaces, like the texture of the face and the clothing.

A basic process of adding movement to the objects, is by repeating an image, displayed on the computer screen and repetitively changing this new image, that is similar to the previous picture, but slightly advanced in the time domain. Thus, using persistence of vision, the impression of smooth motions is presented by drawing the pictures at 12 fps (frames per second). In a computer generated image, this is attained by altering the values of the segments of the skeletal model over time, making the character move from frame to frame. There are a number of strategies for achieving that realistic motion, such as key-framing to motion capture.

Impact of CGI Animation

More affordable than most of the other animation strategies, like construction of miniatures or the use of actors or other contributors to the project, CGI animation is increasingly being used for producing high quality visual effects and realistic images. The accessibility to the CGI software tools, in the recent years, has enabled individual artists and small production units to come up with content without the use of actors, costly set pieces, or props. While 2D CGI was first used in 1973, in the movie Westworld, it has been increasingly used over the years, in popular movies like The Jurassic Park and the Star Wars series. It was in the year 1995, that the first fully computer-generated feature film, Toy Story was produced.

The Future of CGI Animation

Although people have increasingly taken to the animated bugs, monsters, and animals, it is the production of a photo-realistic animation of humans, that continues being out of grasp for CGI animators. Technological change is an inescapable part of life, and therein lies the ambiguous future of CGI animation. To replicate the complex human emotions and actions as a 3D animation, stays the goal for all animators. However, comprehensive humanistic realistic look, where there is no setting apart between a certain film pattern that is CGI or created using real actors in front of movie cameras, seems an unattainable ambition. However with the rapid development of the personal computers, that has reduced their rendering time quite dramatically, and the images having become more realistic, CGI animation is here to stay. CGI Animation is the future especially in motion pictures; basically for everything.
.I 180
.T
document.180
.W
﻿Abstract

We present two efficient image-based approaches for computation and display of high-quality soft shadows from area light sources. Our methods are related to shadow maps and provide the associated benefits. The computation time and memory requirements for adding soft shadows to an image depend on image size and the number of lights, not geometric scene complexity. We also show that because area light sources are localized in space, soft shadow computations are particularly well suited to image-based rendering techniques. Our first approach---layered attenuation maps---achieves interactive rendering rates, but limits sampling flexibility, while our second method---coherence-based raytracing---of depth images, is not interactive, but removes the limitations on sampling and yields high quality images at a fraction of the cost of conventional raytracers. Combining the two algorithms allows for rapid previewing followed by efficient high-quality rendering. 

Summary

Soft shadows from area light sources can greatly enhance the visual realism of computer-generated images. However, accurately computing penumbrae can be very expensive because it requires determining visibility between every surface point and every light. The cost of many soft shadow algorithms grows with the geometric complexity of the scene. Algorithms such as ray tracing, and shadow volumes perform visibility calculations in object-space, against a complete representation of scene geometry. Moreover, some interactive techniques precompute and display soft shadow textures for each object in the scene. Such approaches do not scale very well as scene complexity increases.

We demonstrate two efficient image-based techniques for rendering soft shadows that can be seen as logical extensions of shadow maps. In both methods, shadows are computed in image space. Therefore the time and memory requirements for adding soft shadows to an image are dependent only on image complexity and the number of lights, not geometric scene complexity. Neither algorithm computes per object textures, so texture mapping is not a bottleneck for us. This independence from geometric scene complexity allows us to efficiently compute soft shadows for large scenes, including those which have complex patterns of self-shadowing.

We also show that soft shadows are a particularly good application for image-based rendering approaches. Since area light sources are localized in space, visibility changes relatively little across them. The depth complexity of the visible or partially visible scene as seen from a light (and stored in our shadow maps) is generally very low. Further, shadow maps rendered from the light source sparsely sample surfaces that are oblique to the light source. However, these surfaces are less important to sample well, because they are precisely the surfaces that are dimly lit.

Our contributions are the two algorithms summarized below which represent two ends of a spectrum. These algorithms can be combined in an interactive lighting system; our fast layered attenuation map method can be used to interactively set the viewing transformation, and position the light source and geometry. Our coherence-based raytracing method can then be used to quickly generate final high-quality images.
.I 181
.T
document.181
.W
﻿A (Spotty) History and Who's Who of Computer Graphics

Matthew Ward, WPI CS Department
Introduction

The impetus for this project occurred in a recent advanced graphics class, when I mentioned a particular algorithm attributed to Jim Blinn. One student innocently asked "who is Jim Blinn?" Well, after a moment of shock, I came to realize that many people working in graphics really don't have a perspective on the history of the field or who the key players are/have been (this is true, I'm sure, in most disciplines). Thus, I decided to create a brief Web-based history of the computer graphics field, which hopefully will evolve and become more complete in time. I freely admit that the information contained is not guaranteed to be correct, and welcome any additions, corrections, and embellishments.
The Events

The 1960's

Computer Graphics term coined by William Fetter, Boeing (1960).
First computer animated film (Two-Gyro Gravity-Gradient Attitude Control System, by Edward Zajak, Bell Labs) (1961).
First computer animation language (MACS), by Larry Breed, Stanford University (1961) [Thanks to Larry Tesler].
First public performance of a computer animation, by Larry Breed and Earl Boebert, Stanford University (1961) [Thanks to Larry Tesler].
First video game (Spacewar) developed by Steve Russell at MIT (1961).
Sketchpad, by Ivan Sutherland, MIT - first extensive interactive drawing program (1963).
First computer model of a human figure, by William Fetter, Boeng, for use in the study of cockpit design (1964).
Computer animation language (BEFLIX), by Ken Knowlton, Bell Labs (1965).
Jack Bresenham develops efficient algorithm to scan convert lines (1965).
First computer-generated art show, Stuttgart (1965).
Ivan Sutherland creates first head-mounted display (1966).
Ralph Baer develops first home video game (Odyssey) which allowed users to move points around a screen (1966).
Scan-line HSR algorithm developed by Wylie, Romney, Evans, and Erdahl (1967).
Ray tracing invented by Appel (1968).
First frame buffer built (3 bits), at Bell Labs (1969).
Area subdivision algorithm developed by Warnock (1969).
The 1970's
Intensity interpolated shading developed by Gouraud (1971).
Goldstein and Nagel perform first ray tracing using Boolean set operations (the basis of Constructive Solid Geometry) (1971).
First 8-bit frame buffer (with color map) built by Richard Shoup, Xerox PARC (1972). Evans and Sutherland started marketing frame buffers in 1973-74, with first ones sold to NYIT.
Depth-sorting developed by Newell, Newell, and Sancha (1972).
Westworld debuts - first significant entertainment film which employed computer animation (1973).
Ed Catmull pioneers texture mapping on curved surfaces (1974).
Sutherland and Hodgman develop a polygon clipping algorithm (1974).
Phong Bui-Tuong develops specular illumination model and normal interpolation shading (1975).
Jim Blinn introduces environmental mapping (1976).
Frank Crow develops solutions to the aliasing problem (1977).
Jack Bresenham develops efficient algorithm to scan convert circles (1977).
Jim Blinn introduces bump mapping (1978).
Cyrus and Beck develop parametric line clipping algorithm (1978).
First synthesis of rendering transparent surfaces, by Kay and Greenberg (1979).
The 1980's
Turner Whitted creates a general ray tracing paradigm which incorporates reflection, refraction, antialiasing, and shadows (1980).
TRON released by Disney films, containing 15 minutes and 235 scenes of computer generated images. Companies involved were MAGI, Triple I, Digital Effects, and Robert Abel and Associates (1982).
Octrees introduced as a mechanism for geometric modeling by Meager (1982).
Silicon Graphics is founded by James Clark (1982).
James Blinn wins first SIGGRAPH Computer Graphics Achievement Award (1983).
Particle systems introduced by William Reeves (1983).
Radiosity introduced by Goral, Torrance, Greenberg, and Battaile (1984).
Liang and Barsky develop efficient clipping algorithm for rectilinear clipping regions (1984).
Pixar is bought from Lucasfilm by Steve Jobs (1986).
Tin Toy wins Academy Award for best animated short film (1989).
The People

James Blinn - pioneer of texture mapping and light reflection on curved surfaces; planetary fly-bys, educational animations at JPL (1977-88).
Jack Bresenham - developed efficient algorithms for scan converting lines and curves.
Loren Carpenter - helped develop use of fractals in graphics, major contributor at Pixar.
Ed Catmull - invented z-buffer and techniques for displaying curved surfaces (1978), invented texture mapping. Developed animation program TWEEN. First president of Pixar (spun off of Lucasfilm in 1986), long-time collaboration with Alvy Ray Smith.
Robert Cook - developed stochastic sampling, for use in antialiasing and motion blur, invented shade trees.
Frank Crow - innovations in anti-aliasing and shading algorithms (1977).
Charles Csuri - did early work in analog transformations on images, created Computer Research Group and Advanced Computing Center for Arts and Design at Ohio State University, co-founded Cranston-Csuri animation firm (1982-87).
William Fetter - coined term Computer Graphics (1960); first to develop a computer model of a human form (1964).
Pat Hanrahan - developed RenderMan with Bill Reeves. Prolific contributor to the graphics field, winner of 1995 SIGGRAPH Computer Graphics Achievement Award.
Ken Knowlton - created the first computer animation language (1965).
John Lasseter - writer and director for Disney, Lucasfilm and Pixar. VP of Creative Development at Pixar.
Nelson Max - pioneer in scientific and mathematical visualization at Lawrence Livermore Labs (1977 - present).
A. Michael Noll - innovations in stereography and multidimensional visualization. Helped coordinate first computer-generated art show (1965).
Heinz Otto-Peitgen - significant contributor to mathematical visualization, including work in fractals.
Alvy Ray Smith - major contributor at NYIT and Lucasfilm/Pixar, directed The Adventures of Andre and Wally B., long-time collaboration with Ed Catmull, VP at Pixar, now at Microsoft.
Ivan Sutherland - developed Sketchpad in 1963, first head-mounted display in 1966, co-founder of Evans and Sutherland.
Edward Zajak - created first computer animation film in 1961.
The Companies

Robert Abel and Associates - innovators in early commercial animations, including sexy robot in Brilliance and lead-in to Amazing Stories (1971-86).
Digital Effects - pioneering computer animation production house, formed by Judson Rosebush and others in 1978.
Digital Productions - animation firm founded by John Whitney Jr. and Gary Demos, explored use of supercomputing for animation.
Evans and Sutherland - one of the first computer graphics companies, founded in 1968.
Information International, Inc. (Triple I) - produced much of early publicly seen animation in 1970's. Talents included Gary Demos, John Whitney Jr., Frank Crow, and James Blinn.
Pixar - The former computer graphics group from Lucasfilm (not to be confused with Industrial Lights and Magic, which is the special effects group). Purchased by Steve Jobs in 1986, headed by Ed Catmull and Alvy Ray Smith, later joined by Loren Carpenter, William Reeves, and John Lasseter, responsible for genesis effect in Star Trek II, The Adventures of Andre and Wally B., Luxo Jr., Red's Dream, Tin Toy (Academy award, 1988), and Toy Story. Also created Renderman, which won an Academy award in 1993.
MAGI - early player in computer animation field, formed in 1966 by Phillip Mittelman. Known for using solids and ray tracing rather than polygonal models.
Pacific Data Images - founded by Carl Rosendahl in 1980, PDI is one of the most successful computer animation production studios to date. Locomotion is one of their more impressive projects.
Ray Tracing Corporation - first company to use ray tracing for television and film production (1982). SLOW rendering back in the 80's operating on a Convex/XP vector processor (later acquired by Cray). Became multimillion dollar company. Eventually purchased in late 80s for military uses of ray tracing (radar, sonar). [entry courtesy of Greg Passmore]
Silicon Graphics, Inc. - founded in 1982 by James Clark, SGI has long been the leader in producing low-end to high-end graphics workstations and supercomputers.
.I 182
.T
document.182
.W
﻿Computer graphics: Less computing time for sand
Date:
September 4, 2015
Source:
Karlsruhe Institute of Technology
Summary:
Computer graphics today can produce amazingly photorealistic images. Many motives, however, require very long computation times. Researchers have now developed a process, by means of which granular objects made of e.g. sand, snow or sugar can be computed more quickly.
FULL STORY

A digital sandcastle consists of millions of grains. Its photorealistic presentation by a computer now becomes more computation-efficient.
Credit: KIT / Disney Research
Computer graphics today can produce amazingly photorealistic images. Many motives, however, require very long computation times. Researchers of KIT, Disney Research, Zurich, and Cornell University have now developed a process, by means of which granular objects made of e.g. sand, snow or sugar can be computed more quickly. It was presented recently at the ACM SIGGRAPH 2015 International Conference for Computer Graphics in Los Angeles.

"Objects of granular media, such as a sandcastle, consist of millions or billions of grains. The computation time needed to produce photorealistic images amounts to hundreds to thousands of processor hours," Professor Carsten Dachsbacher of the Institute for Visualization and Data Analysis of KIT explains. Materials, such as sand, salt or sugar, consist of randomly oriented grains that are visible at a closer look only. Image synthesis, the so-called rendering, is very difficult, as the paths of millions of light rays through the grains have to be simulated. "In addition, complex scattering properties of the individual grains and arrangement of the grains in a system can prevent classical acceleration techniques from being used. This makes it difficult to find efficient algorithms," doctoral student Johannes Meng adds. "In case of transparent grains and long light paths, computation time increases disproportionately."

For image synthesis, the researchers developed a new multi-scale process that adapts simulation to the structure of light transport in granular media on various scales. On the finest scale, when only few grains are imaged, geometry, size, and material properties of individual discernable grains as well as their packing density are considered. As in classical approaches, light rays are traced through the virtual grains, which is referred to as path tracing. Path tracing computes light paths from each pixel back to the light sources. This approach, however, cannot be applied to millions or billions of grains.

The new process automatically changes to another rendering technique, i.e. volumetric path tracing, after a few interactions, such as reflections on grains, provided that the contributions of individual interactions can no longer be distinguished. The researchers demonstrated that this method normally applied to the calculation of light scattering in materials, such as clouds or fog, can accurately represent and more efficiently compute light transport in granular materials on these scales.

On larger scales, a diffusion approximation can be applied to produce an analytical and efficient solution for remaining light transport. This enables efficient computation of photorealistic representation in case of bright and strongly reflecting grains, such as snow or sugar.

The researchers also succeeded in demonstrating how the individual techniques have to be combined to produce consistent visual results on all scales -- from individual grains to objects made of billions of grains -- in images and animations. Depending on the material, the hybrid approach accelerates computation by a factor of ten up to several hundreds compared to conventional path tracing, while image quality remains the same.
.I 183
.T
document.183
.W
﻿This chapter discusses the mathematics of linear, affine, and perspective transformations and their uses in OpenGL. The basic purpose of these transformations is to provide methods of changing the shape and position of objects, but the use of these transformations is pervasive throughout computer graphics. In fact, affine transformations are arguably the most fundamental mathematical tool for computer graphics.

An obvious use of transformations is to help simplify the task of geometric modeling. For example, suppose an artist is designing a computerized geometric model of a Ferris wheel. A Ferris wheel has considerable symmetry and includes many repeated elements such as multiple cars and struts. The artist could design a single model of the car and then place multiple instances of the car around the Ferris wheel attached at the proper points. Similarly, the artist could build the main structure of the Ferris wheel by designing one radial “slice” of the wheel and using multiple rotated copies of this slice to form the entire structure. Affine transformations are used to describe how the parts are placed and oriented.

A second important use of transformations is to describe animation. Continuing with the Ferris wheel example, if the Ferris wheel is animated, then the positions and orientations of its individual geometric components are constantly changing. Thus, for animation, it is necessary to compute time-varying affine transformations to simulate the motion of the Ferris wheel.
.I 184
.T
document.184
.W
﻿Computer Generated Imagery

Computer generated imagery (CGI) is used to create photo-realistic images and video using 3D software.  It can be used to illustrate concepts that would normally be impossible to capture on film, for example a product that has yet to be built, mechanical processes or biological processes at a cellular level.  The 3D visualisation created can be as simple as animated logos or as complex as video games

Character
Computer Generated Imagery
or augmented reality projects.

Computer generated imagery is more cost effective than traditional photography as

there are no travel costs, props or lighting to worry about.  At Darkside Studios, we have green screen facilities to place objects or people ‘on location’ without having to leave the studio.  The joy with CGI is that your project is not restricted by reality, there are no limits to what can be created.

Computer generated images are created starting with 3D wireframe models.  Next, properties such as highlights, transparency, and reflection are assigned to the wireframe models.  We then animate the image using camera, objects, lights, and so forth.  The last step is to render the scene.  This technology is used to create fantasy images and computer game graphics as well as special FX for use in movies.  It is easily translated into prototype product mock ups, architectural walkthroughs, and marketing communications.

Using CGI is a dynamic way to market your business and helps you to get your messages across persuasively and with clarity.  3D animation can be used to show unique benefits of a product or how it works.  We can insert digital assets into a particular environment or background for illustrative and creative purposes.  Contact us today to learn how Darkside Studios could help you.
.I 185
.T
document.185
.W
﻿J. Michael Stracznski, the creator of Babylon 5 which is the first TV program to use computer generated graphics, will speak at MIT (Massachusetts Institute of Technology). His encounter with computer graphics began in the early 1990’s when Ron Thornton, Foundation Imaging’s visual effects director, started working with the Commodore Amiga and New Tek’s Video Toaster, an add-on graphics card. The creators of Babylon 5 discarded the miniature, physical, static models of Star Trek for new possibilities.

The July 1994 issue of Compute!  magazine discusses the graphics used in Babylon 5. By today’s standards, it seems primitive, but it was innovative in its time. Each episode of the series used an average of 6,000 frames of computer graphic animation from Foundation Imaging. They used 24 Amiga 2000s, 16 of which were dedicated rendering engines. They had 32 megabytes of RAM, a Fusion-40 accelerator and the Toaster. The Amigas were connected via a Novell network and sent data to a 12 gigabyte 486 PC file server. They later upgraded to Pentium and Alpha-based systems.

Before the Web as we know it came to be, Straczynski hawked his upcoming show over the Internet on USENET, GEnie and Compuserve systems. Babylon’s space station was located in “Grid Epsilon” at coordinates of 470/18/22, which was a reference to GEnie and the original forum’s address on the system’s bulletin boards. Warner Bros started an official website for the TV series.

Straczynski is a writer and producer of science fiction (Babylon 5 and Twilight Zone), mysteries (Murder She Wrote), and movies (Changling, and Ninja Assassin which is coming in November, 2009). Babylon 5 portrayed themes relevant to modern and historical social issues, with subliminal undertones. The subconscious, religion, and even substance abuse and its impact on human personalities, all found a place in the stories.

Various armed conflicts took place on an interstellar scale. The entire series begins following a war caused by a misunderstanding brought on by first contact which brought the human race to the brink of extinction.

In 1997, Straczynski said that what he wanted to do was “examine the issues and emotions and events that precede a war, precipitate a war, the effects of the war itself, the end of the war and the aftermath of that war. The war is hardware, the people are at the center of the story.” These issues are still of importance today. Bablyon 5’s space station was built with the intent of fostering peace through diplomacy.

A video game exists based on the stories, and a new book authorized by Straczynski titled “Across Time and Space: The Chronologies of Babylon 5” is scheduled for release next week. His lecture,  hosted by the Comparative Media Studies Program at MIT, will take place May 22. 
.I 186
.T
document.186
.W
﻿An overdue "Hurrah!" for computer generated imagery in film and TV.
Aug 7, 201562 views3 Likes0 CommentsShare on LinkedInShare on FacebookShare on Twitter
I spotted this short paean to computer generated visual effects on Twitter earlier this week. It’s premise is that CGI visual effects are actually good for movies, and that it’s only considered to be a bad thing because we only tend to notice bad CGI, whilst most CGI (the good stuff) is invisible – there are some overdue nods to superlative digital environments in there, including those for TV e.g. Game of Thrones.



I’ve been generating CGI since 1995, which is a bit like the time in the middle ages, at the cusp of the renaissance in the context of computer graphics history. Back then I was constantly having to justify that what I was doing was art/design/creative/valid, and we are still fighting similar battles now. I too get frustrated with the bad and unnecessary CGI, but equally, I still love to see the good stuff – particularly so when I don’t spot it until it’s pointed out to me later on by the likes of Cinefex, or via VFX breakdowns on the web.

This visual essay makes the point that CGI is great for some things e.g. environments, crowds, vehicles, etc, but not (yet) great for others – digital characters are still something of a work in progress. It also rightly asserts that many films and TV shows wouldn’t have happened without superb, affordable CGI. A good example being Game of Thrones. All tools have their place and value, whether they are practical or digital. So, I’d like to say a huge thank you to Rocket Jump Film School for articulating what I believe, so passionately, and far more eloquently than I am able in this short video.
.I 187
.T
document.187
.W
﻿3D animation is a process that involves taking fully 3D objects (whether they are physical or digital) and making them animate and move. Most 3D animation today is done using CGI (computer-generated imagery). From something as simple as a short cartoon to something as complex as a feature-length film, a 3D animation is a complicated piece of art that takes lots of practice and skill in order to properly execute. The most famous company that creates CGI animations is Pixar Animation Studios. Founded in 1985, they created the very first all-CGI movie in 1995, Toy Story, and they have made a dozen full movies to date. Pixar created an entire business out of the art of 3D animation.

Although Pixar began CGI animation, they weren’t the first ones to do 3D animation. The first type of 3D animation is actually stop-motion/Clay-mation. This process, done as early as the 60’s, involves taking real-life objects (typically clay models of characters) and making them animate in real-life. This is done by posing the model, taking a picture, change the pose of the character slightly, and then taking another picture. This is done until you have dozens of different pictures. When stringed together, they form a smooth animation that brings the intimate objects to life. Some of the most notable stop-motion animations include Gumby, Shawn the Sheep, and Wallace and Gromit, created by Aardman. Aardman continues to have success with their animations. Most recently, they co-developed the film Arthur Christmas with Sony Pictures.

This type of animation is very rewarding to do, but is a very time-consuming process. It takes several hours of poses and photographs just to get a few second’s worth of film. It also requires that the hundreds of shots that are taken have the same lighting, colors, and camera angles, or else the animation will look inconsistent and choppy. Although stop-motion animation isn’t used as much as it was from the 60’s to the 90’s, it is still used to this day, most notably in TV shows such as Robot Chicken. If you have the patience for it, stop-motion animation is a fulfilling and entertaining hobby.

A booth for Aardman Animation, who frequently uses stop-motion animation.

Despite the success of stop-motion animation, many companies and artists have moved on to created 3D animations using computers, referred to as CGI Animation (meaning Computer Generated Imagery). CGI, when used in feature-length movies and short cartoons, usually refers to 3D animation, and not 2D animation. There are countless different programs out there for creating animations on a computer. Some of the most notable ones include Adobe Flash (for 2D animation), Blender (a freeware program for making 3D models), and Renderman (a professional 3D program developed by Pixar, creators of the Toy Story and Monsters, Inc. films.). Which program you decide to use all depends on the specs of your computer and on what you are wanting to do with your animations.

Films have been using CGI in their films for over two decades. Although it has been used in films since the 1980s, it wasn’t used in large quantities until 1995, when Pixar Animation Studios released the first all-CGI film ever made, Toy Story. This ground-breaking film is about Andy and the adventures that his various toys have as they spring to life. Many of the toys are ones that exist in real-life, including Mr. Potato Head and Slinky-Dog. The character models and animations were considered to be very complex for its time, with detailed lighting, various textures, and a wide variety of facial animations. After this film was made, several other films were created using only computers. Some of the most notable CGI companies include Pixar (who has made over a dozen films), DreamWorks (who created the Shrek and Kung-Fu Panda series) and Blue Sky (who makes the Ice Age films).

The gates to the offices of Pixar Animation Studios.

In the early 00s, several cartoon shows began to move towards CGI animation. One of the first ones was Jimmy Neutron, a cartoon show on the Nickelodeon channel. It was based on the CGI movie of the same name. These kinds of cartoons can be produced to air on a weekly basis. Similar to 2D animation for TV, short-cuts are taken in order to keep the costs down. Characters have simplified animation (such as stiffer movement and mouth flaps that don’t necessarily match the dialogue). Also, things such as fur are either simplified or nonexistent in TV CGI. One example of this is in The Penguins of Madagascar (a spin-off of the Madagascar movies). The main movies use several characters that have fur, such as lemurs and monkeys. But when those characters appear in the Penguins cartoon, simplified character models are used. These eliminate most of the fur on the animals, and instead give them a much smoother body and shape. Although they aren't as detailed, using these character models reduce many of the costs that it would take to animate fur.

3D animations are becoming more and more popular. Dozens of films each year are made in CGI. Many cartoon shows are completely made in 3D. Advertising, especially TV commercials, are aided by CGI. 3D animations are quickly turning into the most popular form of animation.

For an article on the process of CGI animation, click here.
.I 188
.T
document.188
.W
﻿veryone knows the magic of CGI from those beloved summer blockbusters: epic explosions, mythical creatures, and flying cars come to life on the big screen because of computer generated imagery. But did you know CGI is also used extensively in TV, video, display, and print ads? Chances are, CGI is behind that glossy print ad for an expensive face cream, or the TV commercial for a sleek new car. As a marketer, how can you use CGI to create your own “blockbuster” campaigns – without breaking the bank?
CGI is not reserved for advertisers with big budgets. In fact, using CGI to create killer ad campaigns can cost less than traditional photo and video shoots. If you haven’t started using CGI for your marketing yet, here are the top five reasons you should start now:

 

02_Heartbeats_C2_white_061213_Cam_2
Image courtesy of Transparent House.

 

1. Costs Less than Photo Shoots
When it comes to showcasing your product in marketing materials and ads, you have two options: photography or CGI. A professional photo or video shoot will provide you with great images of your built product, which can then be photoshopped into different ads. However, If you’re unsatisfied with the final images, an expensive reshoot is required. Plus, if you change the look of your product even slightly, you’ll also need a new shoot. On the other hand, CGI provides photorealistic images of your product (built or unbuilt) that can be quickly inserted into multiple campaigns, including print and digital ads, videos, websites, and TV commercials. Using computer generated 3D modeling, your product images can be altered, manipulated, rotated, and updated on the fly. Change a small feature on your product before going to market? No problem. With CGI, just update the image in a matter of minutes.

As a marketer looking to wow customers with beautiful images, you no longer need to blow your budget on expensive photo shoots. CGI can replace high-end cameras, huge crews, and set pieces at a fraction of the cost.

 

BPWNW8~U
Image courtesy of Transparent House.

 

2. Even Better than the Real Thing
CGI has gotten so realistic – as we know from the all-too-authentic monsters seen in movies – you won’t be able to tell the difference between a photo and CGI. In fact, CGI often looks better than the “real thing”.
With CGI, you can highlight your product’s best features. Have you ever seen a TV commercial for a big juicy cheeseburger that makes your mouth water? CGI is what makes the meat look juicy, the bun appear fresh from the oven, and the sauce drip at the perfect moment. And those dancing phones flying across the screen? Those are not filmed by tossing phones into the air; again, that’s CGI. Your creativity is the only limit to what you can accomplish with CGI. You can show the best version of your product in the most enticing and exciting way.

 

H6P4VF~C
Image courtesy of Transparent House.

3. Flexible and Adaptable
You want to see your product everywhere and your budget shouldn’t limit the reach of your campaigns. With CGI, you can show your product from all angles, in different colors, and in all variations without having to book multiple photo shoots. Need to create slightly different versions of your campaigns for different markets? That’s no problem, because once the 3D model is completed, it’s easy to adapt it. You can insert different versions of the image into any type of digital, video, TV, or print campaign. CGI slashes marketing budgets since you don’t have to create new visual content for each individual campaign.
CGI also saves marketers time when creating future campaigns. When new iterations of your product come to market, simply update your CGI images. The CGI model of the first version can be manipulated quickly and inexpensively into version 2.0 and beyond. Again, no need for a new photo or video shoot.

 

CCOFD3~C
Image courtesy of Marvel Cosmetics. Produced by Transparent House.

 

4.  Not Just for Marketing
CGI is great for marketing and advertising campaigns, but you can use it for far more than that. In fact, CGI is a valuable tool all along the product development lifecycle – from conception, to design, prototyping, manufacturing, and beyond. With CGI, you see your product “come to life” long before it’s built. CGI models can be used during the design study phase to explore different possible iterations of the product. Then, during communication with the manufacturer, you can use your CGI model for prototyping and product finalization. You could even use a CGI model to pitch venture capitalists for funding before your product is in production. With CGI modeling, your product design, development, and production teams will have a huge headstart over the competition. As a marketer, you, too, will have a big advantage: the ability to show exactly what your product will look like and how consumers will use it before it’s even available.

 

MQUUPE~S
Image courtesy of Transparent House.

 

5. Static or Animated: Endless Options
CGI is more than static images. When you choose CGI, you can use the 3D model for animations, mobile apps, videos, product tours on your website, and even virtual reality (VR). By placing CGI images in a VR environment, you allow customers to test drive your product via an immersive, life-like experience. VR places your customers into a virtual scene where they experience the product as if in a real-life showroom – and with the rise of cardboard VR devices that cost just a few dollars, more people will expect to interact with products in the realm of VR before they buy them.

.I 189
.T
document.189
.W
﻿Computer vision is a booming research area at the moment and now we have a successful return to a method that was proposed very early on - analysis by synthesis.
Researchers at MIT have created a language, Picture, based on Julia that makes it much easier to write programs that use probabilistic reasoning for 2D and even 3D based computer vision. Their work is to be presented at the Computer Vision and Pattern Recognition conference  in June.
The team's idea also makes use of analysis by synthesis, which is the general principle that to analyse something one approach is to find a mechanism that reproduces it. In the case of vision this is effectively inverse graphics. If you take a 3D model and render it then each of the pixels in the image has a determined color and brightness. Inverse graphics works the other way and attempts to find a 3D model that will produce the pixel intensities in a given image. By finding the right model you can understand what the system is looking at - a cube, tilted at 45 degrees, say. 
Inverse graphics sounds simple in theory, but in practice there are many 3D models that could have given rise to the pixel arrangement and so you need to use a statistical approach to find the best model. 
Picture is a probabilistic language that allows you to apply a standard template to a range of reverse graphics problems. 
 
 
The scene language is used to describe the object you are looking for as a parametrized 3D model. For example a face is two eyes set symmetrically about a nose with parameters that give the size and separation of the eyes. The scene is then rendered and compared to the observed image. To make the comparison faster, a representation layer is used to convert both observed and generated image to a smaller set of features. These features can even be based on the output of a neural network applied to both images.
An inference engine is where the learning happens. This uses some sort of adjustable representation of a probability distribution - either a Markov Chain Monte Carlo (MCMC) sampler or something more complicated like a Helmholtz machine. 
This is a very general approach and the language allows different applications to be put together in just a few lines of code. Of course, behind the scenes a lot of code is doing a lot of work. 
Three demonstration tasks were tackled.
The first was constructing a 3D model of a face given only its 2D image. Once you have the 3D model you can generate views of the face from different positions, orientations and lighting conditions. 
 
The second task was estimating 3D human pose. Given a set of photos work out how the body is positioned in 3D. 
The third task was to reconstruct a 3D CAD model of a solid from a 2D image. 
In all cases the system seems to work as well as the best alternative methods.
What is interesting about this approach isn't really how successful it is. It is that we have a simple language that allows the expression of complex analysis by synthesis models. It is also that analysis by synthesis takes us well beyond the simple discrimination tasks that neural networks have been proved to be good at.
When you have a model that can reproduce the 2D image you have an understanding of the scene that is much superior to just a classification into "dog" or "cat". 
The neural network is an example of an early approach to AI that didn't work originally due to the lack of powerful machines and so too is analysis by synthesis. Perhaps the two could be put to work together. It might even be the approach that eliminates the sensitivity of neural networks to small perturbations in the input that causes them to classify visually identical images as different things, as described in The Flaw Lurking In Every Deep Neural Net . 

.I 19
.T
document.19
.W
Since the 1990s, the use of CGI, or computer generated imagery, has exploded in both animated and live-action films. There's a constant debate between film critics and fans about whether it's better to film using a green screen and later superimpose a CGI background or to film on a real set. In the final analysis, CGI has both pros and cons.

Advantages of CGI

First, CGI enables filmmakers to create fantastic effects that would cost too much to produce physically, and the process takes less physical space. CGI, when used to create film sets, allows directors to express artistic visions that would have otherwise been impossible or prohibitively expensive. An example is James Cameron's 2009 film "Avatar." The rich jungle life of the planet Pandora, by definition, doesn't match anything on Earth, and it would have been easy for an effects team to physically make something that would have looked unbelievable, detracting from the impact of the film.

Depending on a film's genre and desired tone, the use of CGI can help or hinder. If a director wants a film's environment to feel bright and shiny, CGI can get the job done. It's easy to create objects or people that look perfect with CGI, but not as easy to create a realistic landscape that is dingy or run-down environment.

CGI can also allow for spectacle, such as the massive spaceship battles in the "Star Wars" films, the dinosaurs in "Jurassic Park" or the giant robots fighting in "Transformers." Before CGI, the film industry had to rely on stop-motion, puppetry and various practical effects, such as matte finishes, painted backgrounds and fabricated sets.

Disadvantages of CGI

For all its advantages, CGI can be a hindrance, especially when used to create humanoid characters. For example, an effect called the Uncanny Valley notes an audience's acceptance of a robot or another creature as it approaches human-like appearance and behavior. If it's obviously not human, the audience can be endeared. If it's too close to human but just a little off, there is a negative reaction that puts people off the film. It is very difficult to make a truly realistic human figure using CGI, especially with exacting details such as hair.

Another problem with CGI is that it requires actors to act against a green screen rather than against a visible backdrop. Actors frequently use the existence of the set to help get themselves into a character role ,and trying to act against a green screen makes it difficult to get into character. Also, glitches in CGI can be noticeable and can ruin immersion when played on the big screen. For example, improper character animation can lead to clipping issues where one part of a body goes through another and reminds the viewer they're simply looking at computer-generated images.

Overuse of computer-generated imagery often leads to an audience feeling that the film lacks authenticity. For example, a common complaint levelled against the "Star Wars" prequel trilogy was that Lucas's overuse of CGI caused him to neglect other aspects of the films to the detriment of the series. The acting, dialogue and story are frequently criticized, as are the abundance of CGI aliens. Over-reliance on CGI can also lead to sloppy production. Saying, "We'll just fix it later in editing," can lead to lazy filmmaking and plotting, and it allocates a greater workload to the CGI artists. If a movie has an abundance of CGI effects and is on a tight schedule, the filmmaking team can feel pressured and make mistakes. Inserting computer effects is often better used to enhance existing footage. If a film involves zombies, a normal makeup team might create some of the zombies using actors, while CGI could be used to insert additional zombies with grievous injuries to the scene to ramp up the intensity. Filming the same scene totally in CGI would likely lessen the dramatic and visual impact.

Like anything else in filmmaking, CGI is a tool. It can be a valuable asset when used properly. However, improper use or over-reliance on it can hurt the finished product far more than it helps. Knowing when to use CGI greatly increases the visual effect of a film on the intended audience. No matter how far image-editing capabilities advance, the human element of film cannot be replaced. This includes filming on location, using physical effects and giving actors something to act against. After all, a story is far stronger when it incorporate as many elements of truth as possible.

- See more at: http://www.themovienetwork.com/article/pros-and-cons-cgi#sthash.CuBdPOHI.dpuf
.I 190
.T
document.190
.W
﻿In real life, we see images in three dimensions because our left and right eyes see slightly different images that, when combined by the brain, deliver a picture that has depth. In old-fashioned 3D cinematography – the sort where your glasses had red and green coloured lenses – a pair of closely-aligned images with different tints gave the impression of depth by fooling the eyes. But modern 3D films have developed new techniques to drag them out of their B-movie past, and Avatar takes things a step further by using both computer generated imagery and advanced stereoscopic filming methods to create the illusion of reality.

So far, most successful 3D movies have been entirely animated – and Cameron, too, has used computer generated images to build his virtual world. Avatar's footage is built from around 70% CGI, including the female lead, a blue alien played by Star Trek's Zoe Saldana. As a result, the cast donned motion-capture suits – essentially, leotards covered in sensors that feed the movements of the body back to a bank of computers – and acted out their scenes on a "performance capture" stage six times bigger than anything used in Hollywood before.

Cameron also attempted to crank up the realism by improving the way the suits captured the actors' facial expressions, using a skull cap with a camera enhancement that closely monitored their eyes, mouth and other small movements.

Motion capture makes 3D much easier, not just because it allows film-makers to add the special effects later, but also by letting them position the "camera" (actually a viewpoint from inside the virtual world), wherever they want. If the director wants to shift the angle to the left or right, it's done with a click of the mouse and the computer then works out what it would look like. In most ways, the technique is more closely aligned with the way that high-end computer games are developed rather than traditional Hollywood productions.

One major advance with Avatar's setup was the creation of a virtual monitor that allowed the director to see the motion capture results in real-time, as they were filmed, instead of waiting for the computer to render the images.

Cameron spent much of his own time and a significant amount of money upgrading the systems used for Avatar, but he hasn't just used 3D for the computer-generated portions of the film: new techniques were also created for the live action parts.

Working with long-time collaborator Vincent Pace – founder of a camera equipment outfit in Los Angeles – Cameron developed a filming rig that is more advanced than anything that has gone before. The setup consists of a number of stereoscopic cameras that each use a pair of lenses built to mimic human eyes – positioned close together and able to move a little in order to focus on objects that are nearby or far away. That allows the cinematographer to capture two images simultaneously, which align perfectly with and provide the illusion of depth.

Filming is just one element of creating a 3D movie, however. The other part – which most people are more familiar with – is viewing it in the cinema. Here Avatar is less revolutionary. Although most of tomorrow's trailers will be shown on the giant, high resolution Imax screens, the audience will be using the same technologies used for recent 3D films such as Bolt, Coraline and Polar Express. Viewing not only requires a digitally equipped cinema (sometimes with a silver-coated screen to boost the brightness), but also that stalwart of three dimensional cinema: a pair of special glasses.

But instead of old fashioned coloured lenses, modern 3D films require audiences to wear polarised glasses – where each lens lets through a slightly different kind of light. This means that your left eye and right eye can see different images shown simultaneously on the screen – and not only are they less headache inducing than in the past, they look much more like ordinary specs too.
.I 191
.T
document.191
.W
﻿AVATAR was a visual feast thanks to its CGI characters exhibiting lifelike characteristics and expressions. Although animation played the major role in getting the look of the movie just right, the job was made significantly easier through the use of innovative filming techniques. This article looks at the innovations that James Cameron used when making AVATAR.

Guest post by Karishma Sundaram

James Cameron is known for his revolutionary filming techniques, and each time he makes a movie, the bar is raised a little more. The case is certainly no different with AVATAR which was created with a combination of live action filming and computer generated imagery (CGI) to create a visual masterpiece. There was also use of live backgrounds, interspersed liberally with computer-generated ones.

The filmmaking was a carefully planned, step-by-step process, starting with live action filming, and then going back and forth between that and CGI, to finally arrive at the finished product. According to Cameron, only 40% of the film was live action, while the rest was entirely CGI and miniatures.

Motion-capture Photography

The filming first began with the non-critical parts of the movie. This was done in preparation for the animation work, as the two were combined at a later stage.

The second stage included the use of motion-capture photography. This meant that the actors played their roles in front of a camera, used specifically to capture their movements and expressions. This captured imagery was then taken into an animation studio and applied onto the CGI characters of the Na’vi.

The revolutionary part of this technique was the special augmented reality camera that the director used. Although the actors interacted with thin air during scenes with animated backgrounds, the director was able to use the special camera to view the captured footage on a screen with the animated background already in place. Therefore, as the actors played out their roles, Cameron was able to direct their movements while referencing the animated background.

The technique significantly reduced effort, on the parts of the actors, as there was no requirement to break the flow repeatedly. Also with the augmented reality camera, the director had the freedom to change the background as often as he chose to, adding an incredible level of flexibility to the filmmaking process.

Interaction Between CGI and the Actors

When live action actors interacted with CGI characters, the technique used was slightly different. A small camera was used instead of the augmented reality camera and in addition to the HD 3D cameras. This device, dubbed Simul-cam, is actually a combination of both technologies, and produces a similar working environment as the augmented reality camera. The actors and the CGI characters were able to interact easily with each other, as the director is able to see the actors in the virtual environment and direct them accordingly.

Facial Expressions

One of the most truly incredible parts of AVATAR was the realistic expressions on the faces of the CGI characters. This was accomplished through the use of skullcaps, fitted tightly over the actors’ heads, and an attached camera positioned directly in front.

The camera captured the visual representation of the expressions, while the skullcaps recorded the movement of the facial muscles. Using both sets of data in conjunction, animators were able to transfer the expression perfectly onto the CGI counterparts.

In the extended footage of the movie, the crew commented on the most difficult scene of the whole movie: the one were Neytiri, as a Na’vi, and Jake Sully, as a human, are actually touching onscreen. The logistics of that scene included calculating the shadows of both characters as they related to each other. While this is difficult in the case of just CGI, the combination of live action and CGI made it even more arduous.

Sponsored by . Return to the world of AVATAR in stunning full HD with the .
.I 192
.T
document.192
.W
﻿Research papers on computer-generated imagery can be ordered custom written from Paper Masters to focus on any aspect of the technology. Have our writers produce a model research paper on CGI and its uses across a wide variety of media.

If you’ve been the movies recently, chances are you’ve seen computer-generated imagery (CGI), perhaps without even consciously realizing it. Computer-generated imagery uses computer graphics to create pictures in the following:

Visual arts
Video games
Television
Film
Commercials
Most of the time, CGI refers to 3-D images such as special effects. Computer-Generated Imagery

Computer-Generated Imagery - Avatar

One of the most obvious and groundbreaking uses of computer-generated imagery was James Cameron’s Avatar, which overlaid computer imagery onto the actors. Other notable examples of CGI in film include Gollum in Peter Jackson’s Lord of the Rings trilogy, and the recent Planet of the Apes films.

Filmmakers use CGI in order to achieve high-quality images and effects that not only look realistic, but also provide substantial cost over physical effects, such as miniature models, or hiring lots of extras for crowd scenes. With CGI, a single artist can produce effects that used to require expensive props and sets.

The decreasing cost of CGI now allows individuals to create professional-grade works of art from their home computers. Even more importantly, computer-generate imagery is being used in the courtroom, allowing for the recreation of crime scenarios or crime scenes, which provide better visualization for jurors. Studies have found, however, that many such CGI recreations unfairly sway jurors to believe that the particular scenario recreated is the truth.
.I 193
.T
document.193
.W
﻿I found a very insightful article in the September 2006 issue of ‘Media Magazine’. It discussed the ideas of developing Computer generated imagery in films becoming the USP of films, and that producers are caring less about plots and more about visual effects. It also brings up points about Computer generated creatures like Gollum (The Lord of the Rings) and how the realism of some CGI characters are improving. “It’s the filmmakers responsibility for those two hours at least to make us fear and believe they are real.” And when will CGI develop so much that audiences have to question what is real and what’s not. “CGI is rightly associated with big budget Hollywood, due to its big budget needs. However, as the craft becomes more advanced, it becomes cheaper and therefore more accessible.” This quote explores the idea of CGI being fought over by film companies, and how different companies try to rival eachother with the best, most realistic and advanced visual effects for their new films.  I found this source very useful in finding out more about Computer generated imagery as a business and art, and some films mentioned like ‘The Lord of the Rings’, and ‘King Kong’ are possible films I could look at also.
.I 194
.T
document.194
.W
﻿Whether or not you think face recognition technology is creepy, it’s clear that tech companies around the world are continuing to invest in building better imaging intelligence.

From Microsoft’s How Old Bot to Facebook’s newest app that browses your phone’s gallery for photos of your friends and IKEA’s catalog of computer-generated images, tech in the photography realm is getting smarter than ever – and with Facebook’s latest research development, it’s about to get that much harder to tell photos apart from what’s real and fake.

So. Much. Tech.
Some of the biggest names in tech are coming to TNW Conference in Amsterdam this May.
LEARN MORE
Yesterday, the folks at Facebook’s Research team released a study which highlights its artificial intelligence robot that can generate photographs by looking at pictures of various things and learning its appearances. It’s similar to how humans learn to perceive objects – for example, once you’ve seen an airplane, you’re able to recognize other airplanes pretty easily.


fb imaging ai
In the experiment, Facebook’s AI robot was able to auto-generate 64 x 64 pixel photos that displayed a scene that was life-like enough to convince nearly half of the volunteers they were real.

“Around 40 percent of the samples generated by our class conditional LAPGAN model are realistic enough to fool a human into thinking they are real images,” the research states.

The AI robot works in two parts: One neural network generates an image based on a random vector, while a second network analyzes the produced photo for realism. Over time, the team plans to let the bot create larger images with higher accuracy.
.I 195
.T
document.195
.W
﻿Computer Generated Imagery (CGI) is proving to be an invaluable tool for many companies. The ability to create images using 3D software provides many benefits over traditional photography.

Whilst photography remains the most suitable option for capturing certain images, CGI offers a level of flexibility that can’t be beaten. Many leading car manufacturers and technology companies now turn to CGI instead of photography, utilising its many benefits.

Imagine that you’re preparing to launch a new product. To market your new product you have a new website in the pipeline, brochures and flyers set to go to print, an e-shot and poster campaign primed and ready to promote your product to the masses, but….. the product itself is still being produced on the other side of the world. By using CGI, a true to life image can be created ahead of the physical product. This enables your marketing activity to be taking place without suffering any delays or holdups!

CGI can also be used to create images of concepts and prototypes for market research purposes. It can be integrated with other visual effects to transform a picture. It really does offer a raft of imagery possibilities.

CGI gives added flexibility enabling images to be adapted to showcase all angles. Making changes to a label or colour scheme are simple and straightforward with no need to setup another photo shoot – adding further flexibility as product ranges grow and develop. Imagery is clean, precise and of the highest quality.

Whilst many images still require photography, especially lifestyle shots, CGI in an amazing option with many benefits. Photo shoots can be dependent on many variable factors – weather, lighting, location and more. It can be costly to rearrange or overcome challenges. CGI removes all that risk.

Here at Fever we are working with many of our clients to produce computer generated imagery, showing just how effective this tool can be. Initial costs are not dissimilar to photography costs, so it is an option that should be considered by any business.

We have websites and brochures well underway in preparation to promote products that are yet to be come off the production line. Ensuring that all marketing collateral is prepared ahead of a launch date, means no delays or costly downtime – just a smooth transition to promote products the second they are ready to be supplied.

Check out these examples of CGIs used as an alternative to photography in product marketing:

.I 196
.T
document.196
.W
﻿If you’ve been following my blog and would like to know more about creating photorealistic 3D CGI renders, you can go straight to the source with these books from Amazon:


Crafting 3D Photorealism: Lighting Workflows In 3ds Max, Mental Ray and V-Ray	
Light for Visual Artists: Understanding & Using Light in Art & Design	
Color and Light: A Guide for the Realist Painter

Digital Lighting and Rendering	
Photorealism: You Can Do It	
Digital Texturing and Painting

Elemental Magic, Volume II: The Technique of Special Effects Animation: 2 (Animation Masters Title)	
The HDRI Handbook 2.0: High Dynamic Range Imaging for Photographers and CG Artists	
Physically Based Rendering: From Theory To Implementation
Posted in Ambient Occlusion, Chromatic Aberration, Colour, Dirt, Fresnel, High Dynamic Range Imaging, Hue / Saturation, Linear Workflow, Noise, Photorealism in 3D CGI Imagery, Reflections, Research, Shadows, Sub Surface Scattering, Volumetric Lighting	| Tagged 3d books, photorealism, photorealism books, photorealism research, photorealistic, rendering books, rendering research	| Leave a reply
Volumetric Lighting
Posted on January 6, 2013
In the 3D renders below I have taken a 3D image that I had previously created and tried to improve it by adopting the techniques discussed in this blog. The main focus was to improve photorealism and experiment with volumetric lighting.

When comparing the two images it’s astonishing to think that I was pleased with my original render. It goes to show just how much I’ve learnt since starting the MA.

As mentioned above, I was using this 3D image as a vehicle for experimenting with volumetric lighting. In the improved image, I have applied many of the theories already discussed in this blog, such as adding noise, depth of field, there’s now some dirt at the bottom of the wall and dust on the shelf, but the biggest difference is the addition of atmospheric dust. You can now see the visible light penetrating the right hand side of the image, it is obscuring the model’s rear leg and creating some streaks of light/shadow as it hits the top of the model’s shell.

 Original Render Improved Render
What’s even more important in the improved render is the consideration that’s been given to the narrative. The diagonal lines, camera angle, and use of warm and cold lighting help to achieve what I had originally intended. It seems that the study of character development and cinematography have had as much impact on the improved render as the study of photorealism in 3D and CGI.
.I 197
.T
document.197
.W
﻿Computer-generated imaging creates entire new worlds
Naviya Singla Mar 27, 2016        
EMAIL PRINT
 
Credit: Courtesy of Karter, via Flickr Creative Commons

If you’ve seen the trailer for The Jungle Book, the latest reimagining of the classic book, set to be released on April 15, I suggest you watch it again. Keep in mind that the movie was created with just one actor in an empty room. The rest of the movie was filled in by Computer Generated Imagery (CGI). Consider any other animated or partially animated movie, like The Incredibles, Jurassic World, or Avatar. All were created using CGI. While movies are a common example of this technology put to work, the applications of CGI are varied. Video games, virtual reality programs, theme parks, and even research ventures utilize CGI to display things that can’t be visualized otherwise.

This article will focus on three dimensional CGI animation from a cinematic perspective. CGI is an umbrella term that is used to refer to any image created using computer software. One can create both 2-D and 3-D images using this technology. The major difference between the two is that 3-D CGI is used to create an entire world, system, or animation, whereas 2-D CGI works with image manipulation, often overlaying one image with others. 2-D CGI often involves creating several renderings or frame generations of a particular scene or object and then modifying them further to fit the expected outcome.

Maya, SOCK, Blender, and Lightwave are some examples of software that can be used to produce CGI. Most commercial CGI films use a similar process to movies without CGI: For any movie, the first task is to script it. Without having a clear idea of where story is going to go, or what the characters are supposed to do, the movie may turn into a bizarre, incoherent melting pot full of plot holes. After the script is written, the animator creates the “storyboards,” which are basically several simple renderings of the same scene to get an idea of what works and what doesn’t. These storyboards progress into a formal layout, wherein the entire movie is “completed.” At this stage, none of the characters have features, mouths or faces.

Their outlines and movements are the only data that exist at this stage in the process. Sometimes, this is also when the “voicing over” takes place. This sequential arrangement of the chosen scenes from the storyboard can be referred to as the “layout.” It is just the rough draft of the entire movie. Layout is also done because it is much easier to make changes when the piece is unfinished rather than later, when one would have to work excessively on the details of the scene that has to be modified.

After the layout has been approved by the directors and other parties involved in the animation, the details are filled in. The characters are given physical features, hair, and other sophisticated appendages. Hair animation is often left for the end because it is the hardest and most nuanced bit to actually animate. This is also when the lighting of the scenes is adjusted; the characters and objects are given shadows, illumination, and the like. From a production point of view, that is how animation takes place.

From a slightly more technical perspective, the animation process involves a lot more work than one might think. Most motion animation requires some kind of data about how an object moves. This data can be obtained using several different kind of models, one of which is called the articulate model. This model is a type of skeletal system that defines the joints where motion is possible and in what directions. It determines what movements can be made and limits them to certain points of articulation, just like in a regular skeleton.

Another model for collecting movement data is the deformable object, which is often used to animate things that don’t have clear joints. These include clothes, water, and hair. Usually, animation involves using a hybrid model that combines several kinds of models together. Flip-books are representative of the method of keyframing to generate motion. As the name suggests, keyframing involves defining the frames at several instances in time and contracting them into one film. Another method, usually associated with CGI is to use motion-capture. This involves fitting live actors with certain special equipment, which relays movement data to computers to be rendered and animated on the big screen.

Movie-making is an intense process, and recognizing this process and all of the hard work that goes into it can enhance a movie-watching experience.
.I 198
.T
document.198
.W
﻿Photorealistic Rendering in Computer Graphics

Proceedings of the Second Eurographics Workshop on Rendering

Editors: Brunet, Pere, Jansen, Frederik W. (Eds.)
About this book
Photorealistic rendering strives to generate images from computer modeled scenes with an image quality as close to real life as possible. A major issue in rendering is simulation of local and global light reflection in a scene. Both ray tracing and radiosity algorithms capture only some of the possible light reflection phenomena. Recently developed two-pass algorithms combine the ray tracing and radiosity approaches and are able to capture the whole range of light reflection. This book is a collection of papers discussing the latest developments, including a new range of improvements, in stochastic sampling strategies, radiosity form factor calculation, and parallel processing for ray tracing and radiosity. A number of papers on rendering applications in interior design, lighting design, and remote sensing conclude the volume. The contributions are revised versions of papers originally presented at the Second Eurographics Workshop on Rendering, held in Barcelona, Spain, in May 1991. The book fully reflects the state of the art in rendering and presentsa wide variety of novel techniques. It will interest researchers and students in computer graphics, as well as designers who want to apply rendering techniques for realistic simulation in lighting design, interior design, and architecture.
.I 199
.T
document.199
.W
﻿Photorealism is the holy grail of computer graphics. In movies, whether artists are recreating tigers and raging oceans for Life of Pi, or building giant monsters and battling robots for Pacific Rim, the goal is to create something that looks real.

Even when realism isn’t the principal aim – as in Despicable Me 2 or Monsters University – the studios are looking for something to take their film to the next visual level, whether that’s through natural textures, realistic fur or sumptuous lighting.

Photorealism is just as important for games. It might not mean much in an artsy independent game or an iPhone time-waster, but for racing games, fantasy adventures and hard-hitting action titles, the more realistic the graphics, the easier it is to immerse the player in the game’s world. Each new hardware generation, GPU and game engine takes us one step further.

Studios are looking for something to take their film to the next visual level, whether that’s through natural textures, realistic fur or sumptuous lightingStudios are looking for something to take their film to the next visual level, whether that’s through natural textures, realistic fur or sumptuous lighting

Games and movies face two sides of the same problem. The offline computer graphics (CG) used in movies – where scenes are set up then rendered frame by frame – have produced photorealistic effects for more than a decade. However, this approach is slow and expensive, and makes it awkward to tweak scenes or try different styles or angles.

Game developers, on the other hand, must balance their desire for photorealism with the need for interactivity. A high-end PC could produce Pixar-quality graphics, but not at a playable speed.

Both groups need something that can create photorealistic results in real-time. Amazingly, this might be just around the corner.

Approaching photorealism

Tim Sweeney, the brains behind Epic Games’ hugely successful Unreal Engine, told the UK’s Develop conference in July that “we’ll be able to render environments that are absolutely photorealistic within the next ten years”.

At this year’s Game Developers Conference, Epic unveiled a demo for the upcoming Unreal Engine 4, showing movie-quality animation running on a single Nvidia GeForce GTX 680.

Meanwhile, Mark Cerny, PlayStation 4’s architect, told delegates at Develop that “we are at the point in the PlayStation 4 generation where we’ll forget sometimes that we’re looking at CG, rather than captured video”. This doesn’t mean it will be indistinguishable, but “at times we’ll be able to forget”, he said.

Pixar-quality cartoon rendering in real-time is also on its way. In 2012, Unity Technologies revealed The Butterfly Effect, a short film running in real-time in the Unity engine with Nvidia GPUs. Using techniques traditionally reserved for offline rendering, its visual quality is hard to distinguish from the work being produced by Hollywood CG studios.

Butterfly Effect
According to Sean Tracy, US engine business development manager for Crytek, the time for real-time photorealism is now. In February, Crytek launched Crysis 3, and its CryEngine 3 graphics engine is now powering key games for next-generation consoles and more serious simulations.

“We’ve considered our technology able to achieve photorealism for quite some time,” claims Tracy, even if “the distinction of being photoreal or not is mainly subjective, and heavily dependent on the quality and talent of artists working within a particular piece of technology.” He believes CryEngine provides the tools artists need to create photorealistic graphics. The rest is up to them.
.I 2
.T
document.2
.W
What is CGI Animation? [Technology Explained]
Have you ever found yourself sitting in the theater, watching a Pixar film, and contemplating what it is about CGI animation that makes for some of the best children’s movies?
The evolution of this field of graphic design didn’t happen over a very long, extended period – but instead over a couple of decades. In fact, the rapid advancement of computer processing power is primarily what served as a catalyst for the explosion of CGI animation. But what is CGI animation, exactly?
If you’re a computer graphic design artist, this post may not be for you. However, for those of you out there who are curious about this fascinating form of animation – read on for a brief history of the world of animation, and how computers completely transformed the art form.
What Ever Happened to Plain Old Cartoons?
Most of you can likely name at least one or two of your favorite childhood cartoons. Maybe it was Scooby Doo, the Flintstones or even the Jetsons. Maybe you’re a bit younger (or not) and you still enjoy your Saturday morning cartoons.
However, most of the older folks out there probably started noticing that more and more cartoons look just a little bit different – just a little bit more real. What is it about CGI animation that gives the characters and the overall imagery more realism? The answer to that requires some history.

The history of animation is both nostalgic and sad. Many decades ago, animators were traditional artists who drew pictures by hand. Traditional animation consisted of a whole team of animators who would draw and color images on “cels” – transparent sheets that were placed on top of a background image to create a multi-layered frame.

In this way, segments of an image could change from frame to frame without the entire picture being redrawn. You can see an example of layers in the image to the left. The blue arrow points to the background, the green arrow to the layer with two characters, and a red arrow pointing to the third layer with an image of a flying paper airplane. By manipulating the drawings in each layer from frame to frame, animators would create what many adults today remember as the traditional cartoon.
Many movie fans may remember the hype surrounding the digital remastering of old films such as Star Wars, where computer animation was used to digitally enhance the film. The first stages of CGI animation included 2D animation. This simply involved computers doing what animators had been doing for decades – creating multiple frames of images each second in order to generate the visual effect of animation.
The difference in this case was that as the field of computer graphic design advanced, the images gradually became much more advanced than most cartoon animators could manage by hand. The simplest form of this type of animation can be seen in the animated GIF files that became wildly popular on the Internet throughout the late 1990’s.
These images were created by packaging together a series of static images switched from frame to frame by a time delay defined by a control script within the GIF file itself. The time delay on most animated GIFS are pretty long, so it doesn’t provide for very fluid motion, but the concept of “animation” is still there.
The picture below is an example of one such completed animated GIF.
Now, all of this is grade school level compared to the impressive level that 3D CGI animation technology is at today. How did we get from 1990’s computer animation to the sort of iMax 3D cartoons you love to watch? The simple answer is processing power. With today’s amazing CPU processing capabilities, computer animators are now able to create a 3 dimensional “model” to start with.
This model is only somewhat like it’s 2D counterpart, except now computers have the ability to not only modify large parts of a 2 dimensional image as “layers” – they can calculate and modify very small sections of an object within a 3D world. Because of the level of programming and processor power required, this sort of animation was available only to the largest movie production companies who could afford the computer systems.
Mobile_in-content_300x250_02 /1065821/Mobile_in-content_300x250_02
However, today your own desktop computer can handle it – and there’s even free software like Blender, which Aibek covered in his article on 4 apps for a graphic designer on a budget, and Simon described one of the video games called Yo Frankie! which was created with the Blender engine. I installed the software on my own desktop and within 30 minutes the tutorial taught me how to create the start of a snowman character within a virtual 3D world.
The concept of today’s level of 3D CGI animation is an evolution from basic cartoon animation into a simulated world that seeks to represent realism as accurately as possible. It does this by slicing up the world into the smallest segments possible, and then controlling how those tiny parts of real world objects move, react and change based on the other objects and conditions within that 3D world.
I remember watching The Polar Express when it was first released and thinking to myself how dead the characters looked. When they spoke, their tongues lay still like dead fish and their eyes were often expressionless. I actually thought, at the time, that computers would never be able to realistically simulate the real world, or at least a real person. But, you know what, while researching this article I came across this video of “Emily,” a digitally recreated face of a real actress. I have to say, I was very impressed and I think you will be as well.
.I 20
.T
document.20
.W
CGI and its benefits to film, television and video games
The letters CGI stand for Computer Generated Imagery, and refers to any visual image, whether static or moving, that has been either completely created by a computer system, or at least partly created or embellished by computers. CGI has been one of the most significant markers used to identify the developments in technology, the advances in the hardware, and the developments in software systems and those who use them.

When the idea of using images that have been created on a computer was first introduced to us in television and film, it was fairly obvious which bits were real, and which bits had been added in or replaced using a computer. Sometimes reality and the computer images were combined in a single picture, but more usually they were quite separate. However, as technology has advanced so far and achieved so much in recent years, the use of CGI has massively increased the quality of image that is seen by the viewer, to the point where today it is very difficult, and often impossible, for anyone but the experts to be able to distinguish between what is real, and what is not.

For film and television companies it is often the case that either certain shots or images can only be generated on a computer, simply because they don't exist in reality - such as living, breathing dinosaurs, or a spaceship flying into a black hole - these have to be done on a computer if they're going to be used at all. To a large extent, this capability has determined the actual content of films and programs, with producers using these tricks to embellish the storyline.

The other reason they're used is either down to cost or safety. If a building is going to explode, having a CG model of the building and having the computer create an explosion effect will still look realistic, but can be filmed from any angle, edited and adjusted over and over to get it just right, and with absolutely no danger to anyone. To do the same thing in reality would cost a fortune, be almost impossible to do repeatedly because of time and cost, and real explosions always have the possibility that someone could be injured.

So what does CGI have to do with computers? Often video games and computer games are developed alongside films and television programs, and this can often result in models and scenes being developed for the program at the same time as for the game. This results in a computer or video game which is genuinely seamless when compared to the program. It is this use of CGI across the media, and this seamlessness which increasingly means that video games are an extension of the film or program - that broadcast media is now becoming inclusive and active, rather than a mere passive opportunity.
.I 200
.T
document.200
.W
﻿2D Two dimensional  [To be expanded]
3D Three dimensional  [To be expanded]
4D Four dimensional  [To be expanded]
ANIMATIC A more advanced storyboard using proxy models to rough out basic animation and camera shots. (Film industry term)
ANTI-ALIASING Over-sampling methods for avoiding the unwanted visual effects or artefacts caused by limited display resolution. These aliasing effects include ‘jaggies’ (stair-casing along diagonal lines), moiré effects, and temporal aliasing (strobing) in animated scenes.
ALPHA CHANNEL A view of an image that represents the presence and degree of opacity of objects. The channel associated with each pixel determines the degree of opacity of that pixel using a greyscale range. In video production, the alpha channels used to determine layer masking (mask channel).
ANIMATION The process of developing the actions (poses, timing, motion) of objects. Animation methods include key-frame animation, path animation, non-linear character animation, and motion capture animation. Animations are sequences of frames.
ASPECT RATIO The proportions of an image expressed as the ratio between the horizontal and vertical dimensions. Because pixels are not necessarily proportional, the aspect ratio is independent of the number of pixels in the X and Y directions. For example, both NTSC and PAL television screens are 4 x 3 (aspect ratio 1.33). However, a CCIR601 NTSC image is 720 x 486 pixels, while a PAL image is 720 x 576 pixels.
ATMOSPHERE In rendering, the environment that surrounds the objects in a scene. For example, the simulation of fine particles (fog, smoke, or dust) in the air. When an object is photographed in the real world, it is usually within an atmosphere (for example, air) and can be surrounded by other background objects.
AXIS One of three vectors (X, Y, and Z) that define the three dimensions of a scene. Often defined as local space, object space, origin axis or world space.
BEZIER CURVE In modelling, a curve with at least four control points available to control shape of the curve. This term may also refer to a NURBS curve.
BEZIER PATCH In modelling, a parametric surface, approximately rectangular, that is quilted together with other Bezier patches to form a large, curved surface. The shape of a Bezier patch is controlled by 16 control points distributed uniformly over the surface. Also known as patch surface.
BITMAP Image comprising pixels (as opposed to vector artwork such as EPS).
CAD Computer Aided Design. Designing 2D and 3D work using a computer as a tool.
CAMERA Like a real-world camera, the 3D camera frames the view of a scene by tracking, tumbling, panning, and zooming. Unlike a real-world camera, the 3D camera does not automatically capture lighting, motion blur, and other effects - these effects must be explicitly created and tuned for realistic output.
CAUSTICS Light pattern created by specular reflection or refraction of light, such as the patterns of light on the bottom of a swimming pool, or light through a glass of wine.
CARTESIAN COORDINATE A mathematical representation of Euclidean space. Every point can be described by three coordinates (X, Y, Z) representing the position along the orthogonal X, Y, and Z axes. The point (0, 0, 0) is called the origin, which is the global centre of the 3D world.
CG Computer generated. Design output via a computer.
CGI Computer generated Imagery. Design output via a computer.
CODEC Abbreviation of “compressor/de-compressor”. This is the term used to reference the way that software programs handle different movie files, such as Quick Time, AVI, etc. The CODEC can control image quality, and can assign the amount of space given to the movie file.
COLOUR DEPTH The number of bits used to represent a colour. For example an 8-bit image uses 2^8=256 colours. The bits build up the three primary colours red, green and blue. The following table indicates the number of colours an image can have.
8-bit = 2^8 = 256
16-bit = 2^16 = 65536
24-bit = 2^24 = 16 million
32-bit = 2^32 = 4.3 billion (inc alpha channel)
Also see Floating Point, or HDR images.

COMPOSITING (‘COMPING’) The process of combining two or more images to form a new image. In video, compositing is the process of combining two or more video sequences to form a new video sequence.
CMYK Cyan/Magenta/Yellow/Black. The four ink colours used in 4-colour process printing.
DEPTH CHANNEL The distance of objects from the camera. Also known as Z-depth or Z-buffer channel.
DEPTH OF FIELD (DOF) A photographic term for the range of distances within which objects will be sharply focused. 
(Objects outside of this range appear blurred or out of focus)
DEVICE ASPECT RATIO The aspect ratio of the display device on which you view the rendered image. The device aspect ratio represents the image aspect ratio multiplied by the pixel aspect ratio.
DIFFUSE Surfaces reflect (or scatter) light, and colour in many angles. This type of surface causes light and colour to spread freely.
DYNAMICS A branch of physics that describes how objects move using physical rules to simulate the natural forces that act upon them. Dynamic simulations are difficult to achieve with traditional key-frame animation techniques, but new technology lets you set up the conditions 

.I 21
.T
document.21
.W
Animation and CGI (Computer Generated Imagery) in Cinema
What are the Pros and Cons of Computer Generated Imagery (CGI)?
For the Pros, Computer can make some roles play in the film and these roles are not existing in the real world although it is performed by some actors in the "backstage", for example, the apes in the Rise of the Planet of the Apes.
Indeed, it can help the author to have a great creativity in a film script. It is because author don't need to have misgiving about the authenticity and feasibility of the characters when he or she creates it. That means all the imagined can come true in the film. Most importantly, CGI make hyperrealism. We can enjoy it so much.
As for the Cons of it, as we all know, the movement, facial expression and gesture are all presented by the real actors behind the scenes. Actors don't need to show their face and appearance, so no audience would know who they are without casting information. It is not fair for them because actors also strive for the best performance. When the film is being famous, the actors may not obtain the same benefits.
Also, CGI may not be as real as the normal role because of the hyperrealism too. We never see the characters which are made by digital technology, we would not believe that these characters are existing in the world as it is not a real thing.
Will Computer Generated Imagery (CGI) makes actors obsolete? Yes or no? Why?
 I think that CGI will not make actors obsolete. The main reason for that is that CGI  is unlike real actors although it can make a dynamic or lively characters. For example, CGI often used to make some 3-dimensional graphics in the science fiction film. However, people would think it is an imagination or a fake graphical image because of hyperrealism. It is ironic that when people are weary of hyperrealism, they would like to choose the real actors again, not the CGI. 
So, I think CGI would not make actors obsolete and replace it. They can exist simultaneously.
Should digital characters be nominated for acting awards competing with humans?
 As I mentioned before, all the motions of CGI are presented and performed by real actors through digital technology. It really involves the acting section. So, I think digital characters should be nominated for acting awards in the above situation.
On the other hand, some digital characters are created by scanning clay model and used in an animation. These digital characters are not existing in the real world and so they are inanimate. Actually, digital characters can be infinite if people have an inspiration to create more and more. It can be said that it is an imagination for human. Actually, acting awards should be rewarded for someone who are good at acting and making a breakthrough as well as contribution for the film industry. Thus, I don't think this type of digital characters should be nominated for acting awards.
What are the advantages and disadvantages of motion capture?
One of the advantages of motion capture is that it can make the charcaters more dynamic and lively in their performance. It can give an enjoyment for the audience who love watching animation.  
In addition, motion capture can help to express the psychological states and personal feelings if characters have a natural and suitable motion.
However, motion capture may have a sense of exaggeration. When actors want to show one action, they would portray themselves deliberately. It may destroy the whole unity of motion capture, so that audience may think the motion capture is so strange.
Moreover, motion capture may draw the audience's attention and then audience may not concentrate on the content of the movie. There is a loss when paying attention on motion capture excessively.
Should animation strive for photorealism?
I don't think that animation should strive for photorealism.
It is because animation acn be a space for our imagination. To me, I regard animation as a form of recreation. It can help us release daily life pressure. Sometimes, photorealism may be too rigid and even static. If it strive for photorealism, we may lose one enjoyment or pastime.
.I 22
.T
document.22
.W
Computer animation
Computer animation, or CGI animation, is the process used for generating animated images. The more general term computer-generated imagery encompasses both static scenes and dynamic images, while computer animation only refers to the moving images. Modern computer animation usually uses 3D computer graphics, although 2D computer graphics are still used for stylistic, low bandwidth, and faster real-time renderings. Sometimes, the target of the animation is the computer itself, but sometimes film as well.

Computer animation is essentially a digital successor to the stop motion techniques used in traditional animation with 3D models and frame-by-frame animation of 2D illustrations. Computer-generated animations are more controllable than other more physically based processes, constructing miniatures for effects shots or hiring extras for crowd scenes, and because it allows the creation of images that would not be feasible using any other technology. It can also allow a single graphic artist to produce such content without the use of actors, expensive set pieces, or props. To create the illusion of movement, an image is displayed on the computer monitor and repeatedly replaced by a new image that is similar to it, but advanced slightly in time (usually at a rate of 24 or 30 frames/second). This technique is identical to how the illusion of movement is achieved with television and motion pictures.

For 3D animations, objects (models) are built on the computer monitor (modeled) and 3D figures are rigged with a virtual skeleton. For 2D figure animations, separate objects (illustrations) and separate transparent layers are used with or without that virtual skeleton. Then the limbs, eyes, mouth, clothes, etc. of the figure are moved by the animator on key frames. The differences in appearance between key frames are automatically calculated by the computer in a process known as tweening or morphing. Finally, the animation is rendered.

For 3D animations, all frames must be rendered after the modeling is complete. For 2D vector animations, the rendering process is the key frame illustration process, while tweened frames are rendered as needed. For pre-recorded presentations, the rendered frames are transferred to a different format or medium, like digital video. The frames may also be rendered in real time as they are presented to the end-user audience. Low bandwidth animations transmitted via the internet (e.g. Adobe Flash, X3D) often use software on the end-users computer to render in real time as an alternative to streaming or pre-loaded high bandwidth animations.

Explanation
To trick the eye and the brain into thinking they are seeing a smoothly moving object, the pictures should be drawn at around 12 frames per second or faster.[1] (A frame is one complete image.) With rates above 75-120 frames per second, no improvement in realism or smoothness is perceivable due to the way the eye and the brain both process images. At rates below 12 frames per second, most people can detect jerkiness associated with the drawing of new images that detracts from the illusion of realistic movement.[2] Conventional hand-drawn cartoon animation often uses 15 frames per second in order to save on the number of drawings needed, but this is usually accepted because of the stylized nature of cartoons. To produce more realistic imagery, computer animation demands higher frame rates.

Films seen in theaters in the United States run at 24 frames per second, which is sufficient to create the illusion of continuous movement. For high resolution, adapters are used.

.I 23
.T
document.23
.W
The Advantages of Using CGI in Commercial Photography
Shadowlight Group
Posted on November 21, 2013 by Shadowlight
Computer generated imagery (CGI), created at Shadowlight CGI, compliments the commercial photography industry. Shadowlight offers the unique ability to mimic the detailed look of a photograph, including the desired technical accuracy, texture and color of an object or scene, making it an adaptive tool for a variety of projects.

Save on Shipping, Logistical and Construction Costs

The organization of a photo shoot, including product manufacturing and logistics, travel, location contingencies and material costs shipping, as well as construction, can be cost-prohibitive in certain situations. CGI allows for entire sets to be mocked up and created on a computer screen, saving you the material costs associated with a traditional photo shoot.

Visualize a Prototype or Space Before it Exists

In the event that you do not have a physical product to photograph, CGI allows you to visualize prototypes as well as create image assets for marketing materials prior to the product launch.  With CGI, you can digitally create your products, even if they haven’t made it beyond your R&D department. Once your product has been rendered, it is completely interchangeable with existing photography or used in environments created with CGI.

You can also use CGI to help plan the design of facilities and showrooms before construction begins. A rendered image can help manufacturers, architects, designers and engineers save thousands of dollars by visualizing the space prior to constructing it.

Easily Manipulate Images to Target Different Markets

Through CGI, a full digital scene can be designed to create residential and/or commercial images that are as imaginative as you are – limitations due to size, location, architectural design and material are a thing of the past. Because CGI scenes are never taken down or disposed of, existing scenes can be repurposed months or years later and manipulated to show products or spaces with different options, such as color, product, space, design or backgrounds. This allows you to target different markets with other options that may be more appealing to that segment, without needing to rebuild the set.

It Looks as Real as the Real Thing

When done well, consumers can’t tell the difference between a real photo and a computer generated image. Can you? Take a look at the two photos below – do you know which is one is CGI and which is from one from our studio?

The answer is the first image is CGI.

Shadowlight offers photo-realistic computer generated renderings so lifelike that neither you nor your consumer can tell the difference. Take a look at our CGI gallery.
.I 24
.T
document.24
.W
The 4 Advantages of CGI Animation
THE ADVANTAGES OF CGI ANIMATION
With the attention of CGI Animated motion pictures as “Lord of the Rings” and “Jurassic Park”, the success of computer animation have been brought dramatically into concentration. These days people use computer animation for more than just motion pictures. It has its applications in a range of industries, varying from building renderings to legal animation to space environments created by establishments like NASA. However, regardless of some incredible uses, this type of animation does have its limitations. Understanding when to use hand-drawn work as opposed to computer animation will aid most projects continue to be on course.

Graphics design was a progressive advancement that has occurred in aspects expanded over many decades. The innovation in computer technology is what has led to the development of Computer Generated Imagery (CGI) and  CGI effects.

1. CGI Animated Advertisements

In the production of advertising media, CGI results in invaluable advantages. There are many perks of using an artistic medium in advertisement. For instance, The Advantages of  CGI animation may come in handy in the development of animated advertisements, which are limitless with respect to creativity. In other words, you can build an artistic advert that is not just graphic fascinating but provides the intended message. The combination of targeted advertising alongside web animation is effective as it draws in end-user awareness.

Motifs that are tough to create in reality – for instance, a car on top of a snow-capped mountain – can be made very cheaply and yet look incredibly realistic. The number of photo shoots required is reduced dramatically and the costs are commonly more easy to plan, since following changes can be made without the need for further shoots. There are also no transport costs since all that’s needed is for the “location” to be photographed without the items being advertised actually having to be present at all.

2. Automatized Exhibitions

With CGI animation, it ends up being less complicated to comprehend the usefulness of Adobe-Flash as it permits you to merge several learning styles into your project. For instance, the perks of CGI animation involve a visual presentation to an enormous crowd, supplementing a feature or an article. In fact, you can use CGI animation to illustrate an association between a variety of strategies.

3. More Effective Translation

CGI makes possible for filmmakers to build great effects that would cost too much to produce physically, and the process requires less physical space. CGI, when used to create film sets, makes it possible for directors to express imaginative visions that would have otherwise been inconceivable or prohibitively costly.

Conception and comprehension of new graphics and any idea from your imagination is conceivable using CGI. In practical conditions, you can use CGI animation to breathe life into animate objects and legendary living animals as well as out of this world landscapes.

4. Highly Effective Marketing Technique

Advantages of CGI Animation may also perform an involved function in advertising and marketing. For example, you can attract more customers by use of imaginative animation on all your plasma screens. On the other hand, you may choose to use visual presentation to display designs in the workplace. CGI animation can also help create high-end commercials and films.

CGI animation needs costly tools and software. Since technology is ever improving, you have to keep pace with new advancement if you want to excel in CGI animation and CGI Effects.
.I 25
.T
document.25
.W
Why are CGI-animated films so costly?

A regular CGI film a-la Pixar- costs an equivalent amount to a live action movie, hundreds of millions of dollars most likely. Budget on a live action shoot goes on physical areas, sets, props, explosions, stunts, etc. But with a CGI motion picture it’s a different story.

When a lot of individuals think of CGI (computer generated imagery), they conclude of a motion picture with unique effects or flying company logos. But CGI animation, in addition, can be applied to imagine complex concepts that would be complicated to explain in any other way.

CGI-animated filmsCGI is also a beneficial method to develop very excellent photo-realistic images. CGI bids do essentially with numbers, what a camera does with light. In making these multimedia atmospheres, we generate and place models, cameras and lights in a very similar way you would in a real studio. But we can do some extraordinary things that would be difficult in reality. Our world is interminable by gravity or other physical restrictions. With such flexible options, imagination and creativity become very essential.

The transformation of this field of graphic design didn’t occur over a very long period, but instead over a couple of decades. In fact, the fast progression of computer processing power is mainly what served as an agitator for the outbreak of CGI animation.

With the arrival and accessibility of new technology, often people erroneously believe that because they have the modern tools to do the job, they also have the proficiency to complete the demands of the project. These kinds of programs demand talent as well as technical know-how in order to create the desired effect. Computer animation is no different.

Any kind of graphics project is time-consuming and demands more abilities than people often comprehend.

So where does all the expense go?

Animation is much more time consuming than a live action shoot. Which is why it often tends to be saved for things that are difficult or very hard in real life (living toys, robots in space, blowing up really, really big things, etc.)

Paycheck.
Talent is a BIG money sucker. Voice talents. Don’t undervalue an A-lister’s salary if you are planning to work with one. At any rate, the team for a CGI movie easily runs way over 200 people, that’s a $20M+ annual budget on mostly geeks pecking on keyboards. “Nerds” work way too hard, and in very long hours, doing difficult things that entails CS, color theory, lighting design, fluid and hair simulation, crowd simulations, 3D modeling, and other things you can imagine and mostly making it all look convincing to not only to its audience, but to their bosses. That kind of know-how doesn’t come inexpensive.

Rendering.
You’re paying for computation “rendering farm”, which means you’re either running a huge cluster of computers with all the connected capital and runtime expense (hardware, electricity, cooling, system administration) or you’re renting time on someone else’s cluster.

You’re also paying the equivalent of programmers to work on the exquisite qualities of 24 frames per second of a two-hour motion picture.

Unless your software is in-house, you’re paying licensing fees. Otherwise, you’re paying real programmers to write rendering software, as well as improve it with new features or bug remedies.

Then you have to update shot after shot until the director is happy with the end result.

Additionally, each movie gets made many times. A lot of systems get built for each film and there are a lot of scenes that are essentially hand-built.

Time.
CGI Animation production takes 3 times longer to film a feature animation than a live-action film. 3D backgrounds are an amazing time sink, too, more than you realize. To design 3D backgrounds would need thousands of man-hours to create and design all the models. Some of it can be generated algorithmically (e.g. the palm trees) and some of it is stock models (the horses) but the buildings and the castle, and all those people’s attire is usually created from scratch.

For a really good CGI production, model creation is one of the most significant expenses. 80-90 hour crunch weeks are not extraordinary in CGI modeling.

Story Board.
Production expenses are very costly for animation, the storyboard is very essential. This must serve as the blueprint for every aspect of the film.

Creativity.
When we think of CGI Animation, we think of geeks or nerds. We incorrectly presume about it. In reality, graphic artists and animators are classically-trained animators and artists. In CGI animation, there’s a ton of genuine, hand-drawn art being done for those productions. This includes character designs and studies which requires a lot of hand-drawn art up-front.

Once you get into the digital realm, it’s still a lot of hand-work. Sure, many things are computerized, but it’s the hands-on task by talented artists, writers, and experts that vault an a-la Pixar CGI Animation production above the rest. These artists and animators and experts all expect to be paid for their labor.

.I 26
.T
document.26
.W
The effects of computer animation on the particulate mental models of college chemistry students.

Modern chemistry concepts have the particulate nature of matter at their core. Chemists explain most phenomena in terms of atomic and molecular models. The lack of understanding of chemistry concepts may be linked to the students' inability to build complete mental models that visualize particulate behavior. With computer animation technology, dynamic and three-dimensional presentations are possible. This study explores the effect of computer animations depicting the particulate nature of matter on college students' mental models of the chemical phenomena. A Particulate Nature of Matter Evaluation Test (PNMET) instrument was used to determine the nature of the students' visualizations and, therefore, their comprehension of the chemical concept studied. Animations were used in two treatment situations: (a) as a supplement in large-group lectures, and (b) as both the lecture supplement and an assigned individual activity in a computer laboratory. These two experimental treatments were compared to a control group. Both treatment groups received significantly higher conceptual understanding scores on the PNMET than did the control group. This increased understanding may be due to the superiority of the formation of more expertlike, dynamic mental models of particle behavior in these chemical processes.
.I 27
.T
document.27
.W
Architectural animation
Architectural Animation is a short architectural movie created on a computer. A computer-generated building is created along with landscaping and sometimes moving people and vehicles. Unlike an architectural rendering, which is a single image from a single point of view, an architectural animation is a series of hundreds or even thousands of still images. When these images are assembled and played back they produce a movie effect much like a real movie camera except all images are artificially created by computer. It is possible to add a computer-created environment around the building to enhance reality and to better convey its relationship to the surrounding area; this can all be done before the project is built giving designers and stakeholders a realistic view of the completed project. Architectural renderings are often used along with architectural animation.
Usage
Commercial demand for computer-generated rendering is on the rise, but three-dimensional scale models are still popular. Typically members of the AIA (American Institute of Architects) and NAHB (National Association of Home Builders) prefer to use 3D animations and single renderings for their customers before starting on a construction project. These professionals often find their clients are unable to grasp the complexity and spatial qualities of large projects without the help of computer generated visual aids. The animations and renderings are usually supplied by small animation studios.
Future
Architectural animation is not considered to be the ambition of most small computer rendering firms because of the man hours and computer rendering time that is required to create so many single still images. Not all studios have the software to assemble and incorporate them into a moving sequence. Some smaller companies specialize in high quality single frame computer renderings. Architectural animations require a larger team of artists and animators than single renderings and a much longer time frame is required to complete an animation project. However, many architectural firms are now using architectural animation because it attracts investors and customers who may not know much about building designs and can prefer visualisation rather than technical drawings to see the buildings look and features. Architectural animation is considered to have a bright future ahead of it as more and more architects and real estate developers are including computer animations in their marketing programs.[3]

Architectural visualization:
3D rendering
3D walk-through
3D demo of city planning
3D demo of landscape planning
Restoration of ancient architecture
Animation:
Rendering
Simulation of product and engineering design
Virtual Reality:
Digital sand-table system for city/community planning
GIS (Geographic information system)
Multifunctional educational system
Simulation and restoration of cultural heritage and ancient architecture
Virtual shopping mall
.I 28
.T
document.28
.W
Skeletal animation
Skeletal animation is a technique in computer animation in which a character is represented in two parts: a surface representation used to draw the character (called skin or mesh) and a hierarchical set of interconnected bones (called the skeleton or rig) used to animate (pose and keyframe) the mesh.[1] While this technique is often used to animate humans or more generally for organic modeling, it only serves to make the animation process more intuitive and the same technique can be used to control the deformation of any object — a door, a spoon, a building, or a galaxy. When the animated object is more general than for example a humanoid character the set of bones may not be hierarchical or interconnected, but it just represents a higher level description of the motion of the part of mesh or skin it is influencing.

This technique is used in virtually all animation systems where simplified user interfaces allows animators to control often complex algorithms and a huge amount of geometry; most notably through inverse kinematics and other "goal-oriented" techniques. In principle, however, the intention of the technique is never to imitate real anatomy or physical processes, but only to control the deformation of the mesh data.

Benefits and drawbacks
Strengths
Bone represent set of vertices (or some other objects, which represent for example a leg).
Animator controls fewer characteristics of the model
Animator can focus on the large scale motion.
Bones are independently movable.
An animation can be defined by simple movements of the bones, instead of vertex by vertex (in the case of a polygonal mesh).

Weaknesses
Bone represents set of vertices (or some other object).
Does not provide realistic muscle movement and skin motion
Possible solutions to this problem:
Special muscle controllers attached to the bones
Consultation with physiology experts (increase accuracy of musculoskeletal realism with more thorough virtual anatomy simulations)

Applications
Skeletal animation is the standard way to animate characters or mechanical objects for a prolonged period of time (usually over 100 frames). It is commonly used by video game artists and in the movie industry, and can also be applied to mechanical objects and any other object made up of rigid elements and joints.

Performance capture (or motion capture) can speed up development time of skeletal animation, as well as increasing the level of realism.

For motion that is too dangerous for performance capture, there are computer simulations that automatically calculate physics of motion and resistance with skeletal frames. Virtual anatomy properties such as weight of limbs, muscle reaction, bone strength and joint constraints may be added for realistic bouncing, buckling, fracture and tumbling effects known as virtual stunts. However, there are other applications of virtual anatomy simulations such as military[3] and emergency response. Virtual soldiers, rescue workers, patients, passengers and pedestrians can be used for training, virtual engineering and virtual testing of equipment. Virtual anatomy technology may be combined with artificial intelligence for further enhancement of animation and simulation technology.

.I 29
.T
document.29
.W
Use of computer animation in industries other media and entertainment
Initially when animations started with paper (2D Animation), people had a perception that it was restricted to only drawing and cartoons. As the industry matured with computers being introduced, the perception changed to flashy, photo-realistic or cartoonish productions for web games, movies, video games etc.

Today, animation has convinced professionals from various fields that it should not be restricted to a skill set, but should be used as a medium of expression or communication. For instance, when you use animation in education, it can used to explain theory and concepts to students in a more convincing manner.

In truth, animation is used in a variety of industries away from the big screen or consoles. Computer animation is a very practical tool with useful applications in a variety of fields. Let us take a look at some industries which use animation, but are not related to the media & entertainment sectors.

Medical Animation
A medical animation is a short educational film, usually based around a physiological or surgical topic, rendered using 3D computer graphics. While it may be intended for a variety of audiences, medical animation is most commonly utilized as an instructional tool for medical professionals or their patients.

Architecture Visualization
Architectural Animation is a short architectural movie created on a computer. A computer-generated building is created along with landscaping and sometimes moving people & vehicles.

Take a look at this video that illustrates the use of animation in architecture:

Mechanical Animation
Using computer modeling and animation to create virtual models of products and mechanical designs can save companies thousands to millions of dollars, by cutting down on development costs. Working in a virtual world can let developers eliminate a lot of problems that would normally require extensive physical test models & experimentation.

Here’s a video that shows how animation is useful in the manufacturing sector:
Forensic Animation
Forensic animation is a branch of forensics in which animated recreation of incidents are created to aid investigators & help solve cases. Examples include the use of computer animation, stills, and other audio visual aids. Check out this video to understand how animation helps forensic experts.
Animation in Education
Animation has recently become a popular tool in classroom teaching and learning. The book, Learning with Animation (2007), notes that the use of animation can actually increase interest & motivation in learning.

Many companies & production houses have started producing training content in the form of animation. As the training & education industry is massive and the content delivered is huge, there is a great demand for content taught with the help of animation.

Similarly animation is also used in various other industries. The scope of a career after doing an animation course is therefore unlimited. With the right skill & training, you can hold a creative job in any industry today.
.I 3
.T
document.3
.W
Next Gen: Have video games finally reached CGI quality?
The next generation of gaming is upon us and with it, it brings yet another substantial leap in visuals, physics, scale and hopefully, artificial intelligence. Sony’s PS4 reveal showcased several games and the vast majority of them exhibited unprecedented visual fidelity . The quality of graphics featured in CGI-animated movies have always been held up as the holy grail for gaming visuals to aspire to but the question remains; have video games finally reached the graphical quality once only associated with CGI?
Final Fantasy Spirits Within is a good point of reference for this topic because of its association with the famous gaming franchise. The visual quality holds up surprisingly well even after 13 years since it debuted in cinemas. So how do video games hold up to this, after so long?
Pitting an old man vs an old man? That’s how we do it on Gameondaily and interestingly, the picture on the right is from Square Enix’s much talked about Luminious engine supposedly running in real time.
Whilst we won’t go through the unenviable task of comparing liver spots on these characters, it does seem, at a cursory glance, that both efoorts are equally matched as far as the static images are concerned. From what we have seen Final Fantasy: Agni’s Philosophy in motion, the way the facial animations operate in motion are quite realistic and even surpass the Spirits Within’s sometimes, awkward body movements.
Beowulf is a far more recent CGI-animated movie, and naturally, the quality of the CGI is superior to the one featured in Final Fantasy Spirits Within. So how will our games fare against it visually?
Capcom’s new I.P, Deep Down boasts some of the most detailed visuals we have ever seen in a video game courtesy of the new Phanta Rhei engine. The facial animations, the shadows and lighting and intricate details of the fire and geography are astounding.
Whilst it may not have featured a partially nude animation of Angelina Jolie, we were still left breathless after witnessing what the Phanta Rhei engine was capable of. The facial details on the characters seemed very life-like and dare we say it, even superior to Beowulf’s facial details….with the exception of Angelina Jolie. You could draw her on MS Paint and we’d still give her the win.
Synonymous with CGI-animated movies is the seminal Toy Story 3. The visuals on show are some of the best in the industry and game developers have been aspiring to reach the standard set by Pixar for a long time. It is safe to say that, if video games can replicate the fluidity of the animations and attention to detail then video games have really reached a visual milestone. At this early stage in the next-generation nothing appears to match this benchmark yet but that is only because of how little we have seen of it. However, we see no reason why games at the latter part of the next-gen cannot match or even surpass the quality set by Pixar.
Sony, rather surprisingly, began their PS4 showcase with Knack. Whilst it may not exactly be on par visually with Pixar’s efforts, or any of the games shown at the reveal, it does offer an insight into what may be in store for us in the future. Many a time, factors such as physics go hand in hand with the visuals on display; CGI animations on a character, for instance, may look particularly impressive because of the manner in which the on-screen character’s hair flows realistically. For video games to truly match up with their CGI-animated counterparts, they do not only have to ensure that the ‘raw’ visual quality is on par but also factors such as physics are spot-on.
Remember that CGI quality isn’t static either; the quality is improving just as dramatically, if not faster than video game visuals. Movies like Avatar are a testament that fact and it appears that it will be a long time until gaming replicates the quality in the latter title, but for the most part, video game graphics have moved forward a long way indeed. As of right now, it is too early to tell simply because we haven’t enough of what the next-generation is truly capable of but early signs are very promising. One can only imagine what developers will be able to achieve once they grow accustomed to the power available to them.
.I 30
.T
document.30
.W
Computer animations used in court colored by bias, researchers say
CHAMPAIGN, Ill. - A courtroom jury views a computer animation of a vehicle accident or heinous crime. Does it help bring a conviction or acquittal? With no clear standards for animations that re-create incidents, the verdict is still out, and, for now, it may depend on which side created the simulation, researchers say.

In a study of 117 undergraduate students, psychologists discovered that movements in a sequence of events, as well as the duration portrayed, in animations such as re-creations of a crime can double an already troubling hindsight bias.

Hindsight bias has been linked to the traditional use of text and diagrams to re-create crimes, and is known to interfere with the ability to make fair decisions because it often leads jurists to exaggerate the predictability of past events.

"Many lawyers assume that computer video animations help clarify the evidence, and, therefore, help jury decisions to be fairer and more closely grounded in the facts," said Neal J. Roese, a professor of psychology at the University of Illinois at Urbana-Champaign. "Our findings indicate instead that a computer animation introduces its own additional bias, making people more punitive and more likely to hand out harsh penalties."

Roese and colleagues suggest that by viewing a computer-animated re-creation of an event, a person's confidence is heightened - but not necessarily accurately. An animation, they say, provides movement as reconstructed by a prosecution, plaintiff or defense witness to reconfirm or heighten a jurist's hindsight feeling that "I knew it all along."

In the study, published in the April issue of the journal Psychological Science, some students viewed computer animations of highway incidents prepared for real court cases by Eleventh Hour Animation of Skokie, Ill. The idea was to compare judgments made in foresight, where an outcome is not known, with hindsight, where the outcome is known. A control group viewed text-plus-diagram re-creations.

One animation, 19 seconds long, showed a car following an 18-wheeler on a two-lane highway. The car attempted to pass but collided with a truck coming from the opposite direction. An 11-second depiction showed a semi-trailer avoiding a slow-moving vehicle that was turning into its path on a two-lane highway; the truck collided with a bus coming from the opposite direction. Both films showed the events from bird's-eye views.

Participants were told in advance that they would see cases in which accidents may have occurred. Some participants viewed the entire re-creations with the accidents shown, whereas others saw depictions that were stopped before the accidents occurred.

Participants seeing the outcome then were told to disregard their knowledge of it and put themselves in the shoes of those who had watched clips that did not show results. All participants estimated the likelihoods of the various outcomes, from no accident at all to the serious accidents that, in fact, did occur. The hindsight, widely observed in past research, was found again.

"Participants who see how an accident happens have a very difficult time disregarding this knowledge and cannot place themselves in the shoes of naïve observers who did not see the accident," Roese said. "This hindsight bias occurred regardless of whether participants watched the scenes in computer animations, or if they read text descriptions of the events."

The findings suggest that when it comes to issues of liability or negligence, judgments that hinge on assessing what defendants know at the time of their actions, rather than what came later, the use of computer animations might be an especially big problem.

"Some courts rule them as inadmissible, many do not," Roese said. "Supposedly an animation is based directly on the available evidence and the laws of physics, and when animations are allowed, it is under the assumption that the video accurately illustrates the event. But the truth is that all reconstructions of evidence contain inherent imprecision."

Animated reconstructions, the authors argue, illustrate far more information about an accident for after-accident observers to consider than the involved drivers ever had when their situation was still unfolding.

Co-authors with Roese were psychology doctoral students Florian Fessel and Amy Summerville; Justin Kruger, a former U. of I. psychology professor now with the Leonard Stern School of Management at New York University; and Michael Dilich of FORESIGHT Reconstruction Inc., a research and consulting firm in Northbrook, Ill., which specializes in vehicle-accident investigation, reconstruction, analysis and safety research.
.I 31
.T
document.31
.W
Admissibility of computer generated graphics and animations
This article revisits the issue of admissibility of computer-generated animations purporting to reconstruct a series of events or an accident. Our discussion is prompted by the Aug. 6 decision of the California Supreme Court in People v. Duenas, upholding the admission of an animation re-enacting the sequence of events in the shooting of a deputy sheriff and offering guidance on why the animation was properly received by the trial judge. The appeal raised the interesting question whether slick animations can so beguile a jury that the demonstrative imagery is unduly prejudicial for that reason.
In 2004, U.S. Eastern District of New York Judge Jack Weinstein issued his visionary opinion in Verizon Directories v. Yellow Book USA,1 favoring admissibility of computer-generated demonstrative exhibits or techniques referred to as "pedagogical devices." Weinstein was confident that judges could control against abuses or inequities in resources and tailor proceedings so that such demonstrative materials would help jurors find the truth. This writer discussed the opinion and admissibility issues in two columns.2

Weinstein defined four categories of such demonstrative exhibits: (1) "static images" (common in courtrooms, such as tables, graphs, maps and diagrams); (2) "animations" (moving pictures in which static images are shown in rapid succession to create the illusion of motion); (3) "simulations" or "re-creations" (detailed and realistic depictions which, in the opinion of the creator, simulate the nature of the events); and (4) "computer models" (compilations of mathematical formulae and expressions integrated into a sophisticated program or series of programs which, then, are translated into graphics explicating the results). To these he added a fifth: "enhanced images," a classification somewhere between static images and animations. While the enhanced image is for the most part static, it can be manipulated by highlighting, enlarging particular areas, presenting side-by-side, split-screen images, printed commentary or transcripts moving in tandem with the image and/or audio.

Courts had recognized them as useful trial aids but the common view was that such pedagogical devices are not evidence themselves. Weinstein forcefully advocated that pedagogical devices be admitted as evidence, subject, of course, to court control against prejudice and manipulation of the viewer's subconscious. Since 2004, computer-generated technology has advanced by huge leaps and bounds. Advances in computer-generated graphics now portray imagery so sophisticated, so authoritative, so evocative that the pictorial details can dwarf the testimonial foundation that justifies its admissibility in the first place. Could jurors be so smitten by the informative power of the pedagogical medium that the graphics could be overvalued? Consider, for example, the special effects presented in many successful movies. Without the visual impact of such well-staged imagery, the dialogue itself often would be flat and ineffective. The viewer's emotions are rabidly excited by the visual cues and it is the imagery punctuating the dialogue, in large part, that moves the viewer.

On Aug. 6, 2012, the California Supreme Court, in People v. Duenas,3 seems to have rejected the "beguilement" argument when it comes to the admissibility of animations illustrating what an expert said had happened.
Reenactment Animation

In a nutshell, here is what happened regarding admissibility of the animation. Defendant used methamphetamine and, carrying a loaded pistol, bicycled past a Los Angeles County Sheriff's Deputy who asked him to stop. Uttering an obscenity and gesturing with his finger, defendant continued riding. The deputy pursued in his patrol car and pulled in front of the bicycle with lights flashing. Defendant fired a shot that shattered the car's rear window and hit the Deputy's right hand. The officer drew his gun and began to exit the patrol car. Defendant walked around to the driver's side and shot the deputy three times. He then fired more shots and fled. The deputy was dead. While fleeing, defendant turned and fired three more shots. Defendant was tried, convicted and sentenced to death.

The prosecution presented Carly Ward (an expert in biomechanics) and her son Parris Ward (who creates computer graphics) to reconstruct the events and the movements of the victim and shooter, and tie these to physical evidence. Following a preliminary hearing and over objection, the jury was shown a four-minute computer animation as to how the shooting occurred. Parris Ward has a background in photography, law, computer graphics and creating computer animations for use in court. He relied on a variety of sources, including police and coroner reports, photographic records, precise measurements he took at the scene, examinations of the patrol car and bulletproof vest, and personal consultations with the coroner.

Before the animation was played to the jurors, Parris Ward told them that the animation "doesn't tell you, because it's from computer, that this had to happen this way"; instead, it is "an illustrative tool for explaining concepts." The trial court gave the jury the following cautionary instruction: "What you're going to see is an animation based on a compilation of different expert opinions. This is similar to the expert using charts or diagrams to demonstrate their respective opinion. This is not a film of what actually occurred or an exact re-creation. It is only an aid to giving you a view as to the prosecution version of the events based upon particular viewpoints and based upon interpretation of the evidence."

The animation was a series of mostly still images drawn to give the impression of three-dimensional space. Although the objects and figures in the images rarely move, the viewer's perspective moves within the images, allowing the viewer to see the objects and figures from different angles. The figures were drawn in generic fashion, their facial features indistinct and expressionless. The viewer's perspective shifts from where the principals were in relation to the patrol car at the various stages in the sequence. Red lines were used as the bullets' trajectories with a number of descriptive words or headlines superimposed over the animation. Interspersed with the animation were actual autopsy photos.

The California Supreme Court observed that courts and commentators draw a distinction between computer animations and computer simulations, citing an annotation titled, "Admissibility of Computer-Generated Animation."5 Animation is merely used "to illustrate an expert's testimony while simulations contain scientific or physical principles requiring validation. Animations do not draw conclusions; they attempt to recreate a scene or process, thus they are treated like demonstrative aids. Computer simulations are created by entering data into computer models which analyze the data and reach a conclusion." In other words, a computer animation is demonstrative evidence offered to help a jury understand expert testimony or other substantive evidence. A computer simulation, by contrast, is itself substantive evidence.6

Courts have compared computer animations to classic forms of demonstrative evidence such as charts and diagrams that illustrate expert testimony. The animation is admissible if it is a fair and accurate representation of the evidence to which it relates. A trial court's decision to admit such evidence is reviewed for abuse of discretion. A computer simulation, by contrast, is admissible only after a preliminary showing that any "new scientific technique" used to develop the simulation has gained general acceptance in the relevant scientific community. In Duenas both sides agreed the contested evidence was an animation, not a simulation.

Opinions Illustrated

The animated reenactment was relevant to the question of defendant's premeditation and deliberation and illustrated the theory of the prosecution's biomechanics expert, Carly Ward, that defendant fired a series of shots from different locations, including one at close range. The California Supreme Court rejected the defense argument that the animation was speculative. Whatever uncertainty might exist as to the actual facts, the animation accurately illustrated the opinions of the prosecution's experts. The trial court's instruction to the jury that this was not a film "of what actually occurred or an exact re-creation" but only a "view as to the prosecution's version of the events," clarified the point to the jury.

The court also rejected the argument that the animation gave the prosecution's case an unjustified "air of technical and scientific certainty." The animation was not likely to beguile the jurors into uncritically accepting the prosecution's version of the events because the animation creator (Parris Ward), the court and the prosecutor all made clear to the jury that the animated film was not an exact re-creation of what actually occurred. Accordingly, the trial court did not abuse its discretion in allowing the demonstrative evidence. An Oklahoma appellate case, relied on by defendant, that held four computer animations to be prejudicial,7 was distinguished because the evidence in that case did not adequately support the conclusions reached by the expert and depicted in the animations. Further, the Oklahoma trial court had failed to give an instruction informing the jury about how it should understand and evaluate the animations.

In complex civil litigation, such as a high-stakes products liability trial, both sides often are armed to the teeth with a variety of demonstrative pedagogicals, animations, simulations or accident reconstructions. Frequently, the computer-generated simulation is depicted in some animated format. In such cases, an arbitrary distinction between a simulation and an animation may be misleading. Such a work product is in reality a computer simulation but is depicted, or perhaps masquerades, as a mere animation. The end product to be shown to the jury is not merely an illustration of the expert's opinion (akin to a diagram). Computer-generated simulations are subject to the GIGO ("garbage-in, garbage-out") maxim. Faulty factual inputs can skew the results and yield "garbage" and "junk science" opinions, no matter how distinguished-looking or sounding the expert may be, and no matter how impressive the computer program may appear to be.

Indeed, some computer-generating reconstruction experts may start out with an opinion they were hired to profess and then perform "trial and error" computer runs, alternating factual inputs until they achieve the desired result. They may take one witness' version of events, for example, and input that data, discounting or ignoring other countervailing versions of the facts observed by others. That type of selective use of limited facts is not only subject to cross-examination and impeachment. The gambit may make the simulation, the computer-generated result and the animation purporting to depict the re-enactment "unreliable." That could justify a "Daubert" threshold inquiry or a motion in limine on whether the computer-generated animation should ever see the light of day.8

Thus, counsel need to be alert to what is being peddled as a mere animation. Diligent pre-trial discovery of all participants in the production of a computer-generated reconstruction (whether labeled a simulation or animation) is necessary. Minimally, such information is needed to cross-examine, to prepare one's own version of an animation and, even, to frame a proposed curative instruction that the court should give to the jury if it is disposed to allow the evidence. Do the computer "runs" generating the imagery properly and reliably reflect the actual facts? Does the imagery in the animation depart from the facts? What critical factual inputs have been neglected or ignored? How would omitted facts alter the result and the image depictions? A slew of other "checklist" questions ought to be developed.

Conclusion

The impressive power of computer-generated pedagogicals to win the hearts and minds of the modern, "techie"-oriented jury is inexorable and undeniable. The dramatic influence of pictorial imagery in our lives outside court mirrors the potential influence that such types of evidence can have inside the courtroom. We are not speaking of mere "trial by cartoon." Some modern animations don't even move the figures, as in Duenas; rather, they move the viewers' perspective within and around the images, allowing views from different angles. The juror is being put in the driver's seat, so to speak. That may not just amount to depiction. Subconsciously, to some extent, the juror may "experience" the reconstructed event. The California decision shows that courts will not obstruct such technology so long as jurors are properly instructed. Thus, it falls upon counsel to perfect his or her advocacy, pro or con, regarding such mesmerizing evidence.
.I 32
.T
document.32
.W
what trial attorneys need to know computer animations vs simulations for evidence
Picture yourself in court getting ready to present a first-rate animation created by a professional litigation graphics company. The opposing counsel jumps up to say, “Your honor, we object to this animation since there is no foundation that it’s identical to what happened, it will confuse the jury, and it does not meet the scientific evidence requirements for admissibility.” How should you respond?

The answer is fairly clear as long as you know the difference between a computer “animation” and a computer “simulation.” A simulation is much more difficult to get into evidence than an animation. This post will describe the difference between the two and why it matters to your case. Additionally, I created a downloadable brief on the subject to provide more legal support regarding these issues. [NOTE: This brief is not legal advice, and no attorney-client relationship is created. Cogent Legal provides this brief only as a sample, and suggests you consult a practicing attorney with respect to any legal issues you may have.]

Animation Or Simulation?

The basic difference is this: If the presentation is used simply to illustrate an expert’s or witness’s description of what happened, that’s an animation and it’s considered demonstrative evidence only; i.e. it shows real evidence, but is not evidence itself. However, if an expert has to rely on a computer model or program to tell him or her what happened, that’s a simulation, and it’s “real evidence” that requires all the levels of foundation and acceptance of methods used by the expert to create the simulation before it can be admitted into evidence.

Animations Show The Expert Opinion

Under both California and Federal law, it is much easier to obtain permission to show an animation to the jury if the sole purpose of the animation is to explain a witness’s testimony in the same way a witness would be allowed to draw on butcher paper in court.

Clearly, a well-done computer animation has the potential to affect and impress a jury more than drawing on butcher paper, but the concept is the same. Rather than take a great deal of time for an expert to verbally explain a theory, an animation (like a drawing) shows the theory, usually in less time than it would take to describe it orally.

The main case in California to address the use of computer animations as demonstrative evidence is People v. Hood (1997) 53 CA4th 965, where the court allowed computer animation to explain the expert’s theories. However, it should be remembered that courts always have the discretion to evaluate evidence under Evid. Code § 352, to make sure it is not more prejudicial than probative, and such decisions are very difficult to overturn on appeal.

Simulations Are The Expert Opinion

Imagine a complex case involving a railroad car that overturns in a canyon and lets out a toxic cloud that rail workers and neighbors are exposed to, and some people on or near the rail car get sick while others do not. Further imagine that the rail company, in defending the suit, hires a battery of experts who create a complicated computer model to show the wind disbursement of the toxic chemicals through the canyon to try to prove that the plaintiff could not have been harmed; they create a computer-generated visualization of the canyon, the plume and the plaintiff’s location, and they use it to calculate levels of toxins at the various locations. Absent the expert having created this elaborate computer model, the expert actually would have no opinion of whether the plaintiff was exposed to excessive levels of toxic chemicals or not.

In California, Sections 720 and 801 of the California Evidence Code control the admission of expert opinion. (See People v. Leahy (1994), 8 Cal.4th 587, 598.) Under §801 and People v. Kelly (1976) 17 Cal.3d 24 (Kelly/Frye test), the admissibility of the evidence will turn on whether it is “generally accepted by experts in the field.” Since the simulation itself is the basis of an expert opinion, such simulation would be required to meet the standard that all such testing and simulating was done in a manner that is generally accepted in the relevant field of science.

In Federal Court such a simulation is required to meet the strict requirements of Daubert v. Merrell Dow Pharmaceuticals, Inc., (1993) 509 U.S. 579, 589. The Supreme Court interpreted Federal Rule of Evidence 702 and found that “the trial judge must ensure that any and all scientific testimony or evidence is not only relevant, but reliable.” The Court gave numerous factors that a party had to meet before any such scientific evidence could be allowed in court.

This strict rule regarding the use of computer simulations actually makes a great deal of sense. If the witnesses is really testifying that she has an opinion because the computer told her how it happened, it becomes absolutely key to know what information was put in the computer and how it was calculated, and whether this method of data collection and calculation is accepted; otherwise, a jury could easily be fooled by the patina of scientific credibility of the computer model.

Conclusion

If you are looking to get an animation before the jury, ask yourself these key questions:

(1) Is it intended to be for demonstrative purposes only (i.e. showing real evidence but not evidence itself)?

(2) Is the animation used simply to illustrate the already-established opinion of an expert or witness, rather than forming the basis of their opinion?

(3) Will showing it enhance the jury’s understanding of a complex issue?

If the answer is yes to all questions, you have a good chance of showing it to the jury as demonstrative evidence. However, if the intent is to provide the expert an answer to a relevant question of the case by simulating some action, the much higher standard of Daubert and Kelly/Fry will be applied, and the chance is much higher it will be excluded.
.I 33
.T
document.33
.W
7 exciting uses of 3D animation today
Recently, animation has come into its own in various industries.  More and more people, however, are finding it a useful tool for a variety of purposes.  Granted, when it began 3D animation was used mainly in the making of movies.  Pixar’s Toy Story came out in 1995, and there have been many offerings since then.  Now the use of 3D animation is branching out into fields as diverse as medicine, business and architecture.
Toy Story was a huge success.  And although the computer played a major part in 1993’s Jurassic Park, computers provided only the dinosaurs, the supplementary characters.  Toy Story was particularly amazing because it set the bar for films that were created entirely on computer.
Since then many more industries have adopted 3D animation as the next major useful tool.  Not only is it an invaluable applied science that can serve multiple fields, but like the discipline of Information Technology, it is also an exciting career choice with great prospects.
Just a few of the industries in which 3D animation is being used are:
– Interior designing
– Architecture
– Stage Shows
– Medicine
– Gaming
– Business
– and of course Filmmaking.
Take interior designing.  With the help of software packages designed specifically for this field, interior designers can see rooms they create right on their computers.  This can give a more accurate idea of how well a design would work in specific rooms, how it can be visualized, etc.  Similarly, architects extend similar technology to the buildings they design, and shipbuilders the same with the vehicles they create.  Carmakers, bicycle designers, computer chip fabricators, and any other field that produces physical and manufactured objects can benefit from 3D animation.
In the field of medicine, 3D animation is a wonderful tool for education and training purposes.  The young surgeon can easily be trained on surgical techniques.  Conceptual information can be easily transmitted; as many people are visual learners, it may be easier to visualize a bodily process happening rather than simply reading about it. Related to the adoption of 3D animation in film making is its use in stage shows.  Multimedia artists such as Amon Tobin, Peter Gabriel and VAST all push the boundaries of what it means to be entertained in front of a stage.  For instance, in 2011 (to 2013) electronic musician Amon Tobin created a show in which computer generated images were mapped and projected on to a cubical object in real space, sitting on the stage.  This resulted in an incredible experience that was very well received the world over.
Another important sector in which 3D animation is used today is gaming, for which many 3D artists are needed to create the assets used in game worlds.  These objects can be seen from any angle, necessitating their intricate construction in 3D-mapped space. The corporate world uses 3D animation for presentations, marketing, education and training, to illustrate trends in markets, and so on.
3D animation can be found everywhere today.  Its effectiveness and strength lies in the fact that it is an widely useful technology that can be used to produce any sort of images: realistic, fantastic, pragmatic, innovative.  The only limit to what it can do is really the imaginations of the animators.  The field has a bright future, a well-established one as well as one that is getting new innovations all the time.
.I 34
.T
document.34
.W
Nebraska animation careers: Employment and salary trends, job opportunities and colleges offering animation programs in Nebraska
From Chadron State Park to the Omaha skyline, Nebraska has provided some of the most breathtaking backdrops for productions of all kinds. Just a few movies shot in Nebraska include Downsizing (coming 2017), Nebraska (2013), Lucky (2011), Elizabethtown (2005), About Schmidt (2002), and Election (1999). Thanks to the Nebraska Film Office, the Eastern Nebraska Film Office, and other organizations, productions such as these are common in the state. These organizations encourage film and video production through contests, training programs, resources, and tax incentives.
Because the state has an active film industry, artists and designers can find opportunities in film, animation, documentary film, television, and other areas similar areas. Besides an active film industry, Nebraska is home to more than 500 technology firms and hundreds of creative agencies that routinely hire animators. The state is also home to several colleges that offer programs for aspiring artists and designers. Just a few include the University of Nebraska system, Creighton University, and Union College.  

Continue reading to find which Nebraska schools offer the best program options for aspiring animators, and what to expect in the areas of employment and salary trends. 

Employment and Salary Trends for Nebraska Animators

As of 2016, Nebraska was home to 11,440 professionals working in Arts, Design, Entertainment, Sports, and Media (ADESM) occupations. They average $42,420, up from $37,800 when the state was home to 11,120 ADESM professionals. Of the 11,440 people working in the creative sector, 80 are salaried animators and multimedia artists averaging $50,240 per year. In 2010, the state was home to 70 salaried animators and multimedia artists averaging $40,440.

Nationwide, the median annual wage for animators and multimedia artists was $63,970 as of March 30, 2016 and overall employment for this group is expected to increase by six percent for the 2014-2024 decade. This is as fast as average for all occupations. It is important to note that many animators and multimedia artists are self-employed. In fact, according to the Bureau, "Independent Artists, Writers, and Performers” has the second highest concentration of employment (not highest employment level) in the nation for animators and multimedia artists.

This means it’s safe to assume that Nebraska has a much larger population of animators and multimedia artists. Further, "Independent Artists, Writers, and Performers” typically earn more than their salaried counterparts. According to the BLS, they average $70,080 per year.

The top five highest paying states for animators and multimedia artists are:

California ($82,810)
Washington ($80,460)
Connecticut ($77,860)
Massachusetts ($74,440)
District of Columbia ($74,230)
The industries with the highest concentration of employment for animators and multimedia artists are:

Motion Picture and Video industries
Independent Artists, Writers, and Performers
Software Publishers
Cable and Other Subscription Programming
Specialized Design Services
The industries with the highest levels of employment are:

Motion Picture and Video industries
Computer Systems Design and Related Services
Software Publishers
Advertising, Public Relations, and Related Services
Other Information Services
The top paying industries for animators and multimedia artists are:

Travel Arrangement and Reservation Services ($85,750)
Other Information Services ($82,940)
Software Publishers ($76,920)
Professional Commercial Equipment and Supplies Merchant Wholesalers ($75,540)
Wholesale Electronic Markets and Agents and Brokers ($74,960)
The states with the highest employment levels for animators and multimedia artists are California, Georgia, New York, Texas, and Washington.

Animation Career Opportunities in Nebraska

As mentioned, Nebraska is home to a variety of creative agencies and technology companies, as well as PR firms, production studios, academic institutions, and other places that may hire animators. Just a few options include:

Agent, Lincoln
Archrival, Lincoln
Bailey Lauerman, Omaha
Bozell, Omaha
Envoy, Inc., Omaha
Heartland Marketing and Communications, Bellevue
InFlight Productons, Omaha
June Advertising, Omaha
Mint Design Group, Omaha
OBI Creative, Omaha
OnPxl, Omaha
Outpost12 Studios, Lincoln
SKAR Advertising, Omaha
Swanson Russell, Lincoln
The Minnow Project, Lincoln
Unanimous, Lincoln
While Nebraska’s largest cities may offer more opportunities, several other cities besides Omaha and Lincoln are worth exploring. Consider Bellevue, Grand Island, Kearney, Fremont, Hastings, and Norfolk.

Nebraska Animation Training Programs

One of Nebraska’s most popular schools for aspiring animators is the Hixson-Lied College of Fine and Performing Arts at University of Nebraska-Lincoln. Here, students can earn a BFA in Film & New Media with a focus in Computer Animation. Another excellent option is Creighton University, Omaha. The school offers a BA in Graphic Design and Media, which highlights animation studies, interactive multimedia, video and still photography, web design, and typography. Another option is Bellevue University, which offers a BS in Game Studies that features game animation coursework. 
.I 35
.T
document.35
.W
Top North American Cities for animation careers
Animation is an exciting, dynamic and growing field—and good thing, because there are plenty of aspiring animators anxiously waiting in the wings to become the next Chuck Jones. But where exactly are all these animators going to be absorbed into the industry? 

Well, animation jobs tend to gravitate towards artistically focused epicenter cities that cater to entertainment sectors—like film and gaming—so living and learning in Bummsville, USA (population: 37) likely won't cut it if you want to be a successful animator.
So where should you live if you want a successful career in animation AND an overall happy life? Well, a number of cities offer exciting career prospects and inspirational atmospheres:

1. San Francisco Bay Area, California
It’s no secret that San Francisco is an artistic hub in the US. It is home to some of the most enduring performing-arts companies in the country, like the San Francisco Opera (the second-largest opera company in the US), the San Francisco Symphony and the San Francisco Ballet. This artsy city is also home to groovy art venues like Beach Blanket Babylon and the Orpheum Theatre, both of which draw a certain type of refined artistic crowd.

But SF isn't just an artsy town, it's also the home of the country's technological innovation sector...Silicon Valley. When San Francisco experienced the tech explosion in Silicon Valley some of its artists saw an opportunity to combine the city's two passions: art and technology, and jumped into animation head first. Shortly after, others jumped on the bandwagon and San Fran became a major hub for some of the country's most artistically talented animators. Some of the world's biggest animation firms, including Lucasfilm and Industrial Light & Magic, saw the burgeoning talent pool and made the city their home base.

What landed San Francisco such a primo spot on this list are its choices. You've got throngs of animation jobs all around the area, and tons of great little cities from which to choose to live. Across the bridge from SF, in Emeryville, you've got Pixar and EA. Down the road in Redwood you've got a DreamWorks and another branch of EA (the area's second largest employer, after Oracle), and there's there Capcom gaming in San Mateo. And the majors aren't the only one putting the area's talent base to work, in recent years a number of pop-up boutique studios have stabilized in the area, providing even more animation employment.

Not only are there jobs-a-plenty in San Francisco, it also has one of the highest levels of quality of life in the country—that is for those who can afford the post-gentrification prices. Real estate prices in San Francisco's core are high, but a great investment—which is why many people head for the hills since the cost of living in nearby suburbs and cities is significantly lower. Many animators choose to stick around San Francisco though, even if the gentrification and the high prices it causes do drive up the cost of living. The cost of living in one of the country's best cities is acceptable to many re-locating animators thanks to the area's cream-of-the-crop talent-seeking employers that have driven salaries sky high—big fish employers from the Dot-Com and Web 2.0 eras that made the city home of their HQs, including: Craigslist, Facebook, Google, Twitter, Zynga, Salesforce.com and the Wikimedia Foundation.  Due to the cost of living and competing local salaries, local animation studios pay a premium for top talent to relocate to the area, with salaries running from the low $90,000 to $110,000—the highest average in the country.

SF has become a popular home for the well-paid employees of major animation studios like Dolby Laboratories, Industrial Light & Magic, Lucasfilm and LucasArts. These career-driven animators have flocked to the city for its laid-back lifestyle, hippy-esque-yet-upwardly-mobile population, year-round warm weather, beautiful nature and never-ending inspiration. 

While studios in the area are always on the look out for the nation's hottest talent, not all talent has to be head-hunted from out of state; there is a large, local talent pool from which area studios can recruit. A pool created from the steady stream of graduates coming from the Academy of Art University (#33 on our list of the top 100 animation programs around the globe) in the heart of SF, Ex'pression College for Digital Arts (#67) in Emeryville, CalArts (#2 on our list) down in Valencia and the Gnomon Institute of Visual Effects (#21) in relatively-nearby Hollywood.

While many of you likely thought LA or NY would steal the number one spot, the quantity of jobs available, the high salaries and chilled-out artistic atmosphere (which is far more suited to wacky animators than Rodeo Drive) earned the bay our top spot. But LA wasn't far behind…
2. Los Angeles, California
LA defines the title World-Class City and is renowned as being the entertainment capital of...well, the planet. What can we say about LA that you don't already know? Dreams are made or broken here—just ask your waiter. And while restaurants are staffed with wannabe actors, animators coming to the city have a significantly better shot at the big time due to all the major players in the industry who call LA and the surrounding area home.

The list of production houses within the LA borders is by far the longest on this list, and includes Disney, MGM, the Motion Picture Corp of America, EA LA (their primary location), Sony Pictures Imageworks, Hasbro, DreamWorks, Acme Filmworks, Acorn Entertainment, Animax Entertainment, Bill Melendez Productions, Fred Wolf Films, Klasky Csupo, Renegade Animation, Rhythm & Hues, the Ebeling Group, Nickelodeon, Prana Studios, Ring of Fire, The Cartoon Network, Film Roman, Warner Bros, Sony Pictures Animation, FOX TV Animation, Bento Box Entertainment, Crest Animation, IM Digital (Image Movers), the ABC Family/Walt Disney, Abby Lou Entertainment, Blur Studio, Inc., Children's Media Productions, Chiodo Brothers Productions, Crest Animation Studios, DIC Entertainment, Digital Domain, Enoki Films, U.S.A, Film Roman, Inc., Foothill Entertainment, Inc., Gracie Films, The Jim Henson Company, Hyperion Studios, Kurtz & Friends, Liquid Light Studios, Live Wire Productions & VFX, Lee Mendelson Film Prodictions, Motion City Films, Multimedia Unsigned Records, Nelvana Communications, Inc., New Hollywood, Orbit Productions, Pacific Data Images (PDI), Pix N Stones Productions, Playground Media (VFX), PorchLight Entertainment, Puppet Studio, Pyros Pictures, Inc., Reality Check, Inc., Rhythm & Hues Studios, Ruby-Spears Productions, Six Foot Two Productions, Sony Pictures Animation, Sony Pictures Television, TLC Entertainment, Threshold Entertainment, TMS Entertainment, Toon Makers, Inc., 20th Century Fox Animation, Universal Cartoon Studios, Wild Brain, Inc., Fred Wolf Films, Mike Young Productions, Inc., and—surprisingly—many more.

The city of angels is a true mecca for animators, with thousands of aspiring animators drawn to the city each year and recruited into the world's top animation studios. And why wouldn't they be drawn here (drawn—get it? A little animation pun)? The quality of life in LA is quite good, although highly varied since the exact level is highly dependent on your chosen neighbourhood, socio-economic status and whom you hobnob with.

Every animator has their reason for residing in the City of Angels, some flock to the city primarily for its available animation jobs, other for the temperate warm weather and beautiful coastlines, while others come to rub elbows with celebs and powerful elite that practically own the city. Others come for the wine. And a select few, for Disney. 

Those lucky enough to score positions with the large animation firms in the area get to work with the top animators and producers in the industry and attend some of the world's best premiers and parties.

Now time for the only major downside of living in and around the animation metropolis: the traffic. Well, the brutal traffic AND sky-high prices. The traffic and high prices are the reasons why many decide to locate to the quiet suburbs, like family-friendly Orange County, Brentwood and Sherman Oaks while others can stand the prices and crowds and opt for the more riveting Silver Lake, Echo Park and downtown core.

Now that we've made our way to talking about money...Quality of life for an animator—or anyone for that matter—in LA comes down to salary and creativity. The lower the salary the higher your spending creativity needs to be. Luckily—animators are naturally creative. Animator salaries in LA can range anywhere from the mid $60,000s to low $100,000s, with the average floating in the high $70,000s mark, a decent salary and definitely liveable, although this salary combined with the overall cost of living means that your first few years in the city will likely be tough. Those who stick it out however, swear there is no better place to work in the industry, and the wages do get better.If you're thinking about relocating try this LA-based relocation calculator.

If you are considering relocating—be warned: transplants aren't the only ones vying for the coveted studio jobs. There is a great pool of local candidates that graduate from the city's many, many, many post-secondary institutions. Many of which focus on the entertainment industry. The cream of LA's animation-education flock are those coming from CalArt's animation program—a program that we ranked #2 on our list of the Top 100 Schools for Animation, Gaming and Design. The Gnomon Institute of Visual Effects (#21) in Hollywood is of course another popular recruiting ground for the majors looking for fresh young talent.
.I 36
.T
document.36
.W
Skills animation employers are looking for
One thing AnimationCareerReview's readers and I have learned throughout our  Interview Series is that animation employers are looking for far more than a technical animation education and a thrown-together, hodge-podge portfolio. Technical skills learned at school must be blended with softer, business-world skills—then combined into a stellar application, portfolio and CV that showcases individual creativity.

To help new animation graduates land jobs in the industry we have put together the best responses from our interview subjects, to show our readers exactly what studio owners and execs are looking for when they hire new animators. So pay attention animation job applicants and adjust your portfolio, cover letter, CV, and interview responses accordingly—especially if you are applying to any of the studios below:

Richard O'Connor, Ace & Sons
Technical versatility, solid draughting skills, intellectual and artistic curiosity.

ADi
Industriousness and teamwork. Curiosity and a healthy ego.

Arthur Kautz, Aniben 
We are looking for creative individuals that have a strong work ethic. Being on time, working as part of a team and realizing that animation is a business is important to us. 

Joe DiDomenico, Applehead Factory Design Studio 
We look for problem solvers. Anyone can learn the software, but few have the ability to think on their feet. At the end of the day, we are paid to come up with creative solutions. A good problem solver beats the rest hands down. 

Joe DiDomenico, Applehead Factory Design Studio 
A level of expertise in a particular field – be it Modeling, Lighting or Production Management - is essential. Equally important is understanding the context of the whole process and ‘owning’ your piece of it. Film-making is truly about the sum of the parts, and in animation, where you are creating every single aspect separately it is essential that you understand where and how your part fits in. Both technically how it fits together, but also how it works emotionally and creatively into the work. 

Glenn Barnes, Big Sandwich Games 
We're a smaller studio, so we value generalists as much as specialists. We might hire an artist to build, say, vehicles, and then move on to a game that doesn't have any vehicles in it. That artist will need to move on to environments, or characters, or whatever it is that needs to get done. 

In short, the answer to you question is: excellence. With an artist, that's easier to measure, just by looking at a portfolio. With a programmer, it gets more difficult, and we have to rely on looking at code samples or on references. Overall, when hiring for any discipline, we want to be sure that the applicant will mesh with the team and with BSG's culture.   

James Rumpf, CartoonGems
The skill that we require the most and seek out in new hires is Flash Animation
skills. 

Andre Lyman, Clambake
When seeking out new employees (and we're constantly receiving resume submissions through our website), we look for individuals with a sense of humor, who are flexible, talented, and possess a strong work ethic. Being a fan of what we do is key, as is drinking beer. (Well, not really.) 

Mark DiGiacomo, Digital Elixir Studios
Due to not being in a major film/production hub, we focus primarily on utilizing contract talent at this stage. We look for creative ability and focus on the details that make their work stand out professionally across the board; We look to good communication skills, both verbally and in writing due to remote working conditions often; We look also to attitude and work ethic/style.

We need to be sure that they can operate like a trusted friend as much as a contractor or employee. This business and the stresses of the work can be so tough, there's no time for unnecessary formality that would translate into a person not being 100% committed to the success of the creative work we're infusing into the business world. 

Jon Gallo, DraftFCB
Aside from the obvious prerequisite skill sets, one of the most important qualities we seek is a collaborative spirit. The creative process can greatly benefit from shared perspectives. Also, a curious nature leads to new learning which, in turn, can enlighten the team. 

Darcy Vorhees, Flaming Medusa
Being pro-active is always good, and professional. Someone who wants to learn a variety of things and who doesn’t have their heart set on only producing one style of animation. Someone who can draw from life yet also be observant and flexible enough to duplicate other styles.  Someone who knows color. The rest depends upon the type of position that is being filled, but these are the basics for any creative position.

Jeremy Gibb, Gibb Animation Studios 
Quite simply, “Do you know good 3d from bad 3d”? As I too often find when looking over demo tapes that it is clear that this person will be a good prospect or not. Usually it takes less than a minute of viewing their portfolio. In addition to that, you must have good personality. No one wants to work along side you for 8-16 hours a day if you’re a negative person. 

Mark Cappello, Invisible Entertainment 
Talent and attitude. A portfolio can only demonstrate half of that equation, and portfolios can be deceiving. We like to hire people with experience because the network of artists in this region and in the country is quite strong in communicating a potential employee’s pros and cons.

When I hire people straight out of school I find they largely need to be retrained, not in terms of the technical skills but in terms of the practical applications of their craft and their attitude and understanding of the ‘actual’ industry. Most graduates have a very rose-colored view of the industry and they tend to become bitter quickly when they are faced with the sometimes seasonal nature, the job insecurity, and the pedestrian pay rates. It can be a shock to someone who spent a lot of money for training with instructors telling them they will make hundreds of thousands of dollars.

J.J. Sedelmaier, JJ Sedelmaier Productions

Drawing talent - with flexibility of style and technique.
Ability to work with and inspire co-workers.
Humor.
Technical skills and knowledge.

Stephen Fishman, Mac and Cheez
I like smart problem-solvers with good reels. A lot of people tend to fudge the degree of their involvement on a particular piece on their reel. I know that a lot of work these days represents the involvement of huge teams of specialists but I'm always more impressed when somebody has something that they've kind of done soup-to-nuts by themselves. If they can point to something sophisticated and classy that they've done themselves (even if its spec), then I prefer that over the splashy group efforts for larger brands. 

I'd be looking for a self-starter type who can handle many different tasks. Its good to balance the technical and artistic. Although, I'd kind of prefer somebody more technical than myself.

Joddy Eric, Madwerkz 
The most vital skill we look for is the ability to work in a team-orientated environment. Working in the animation and visual effects industry often demands long hours and the ability to communicate and work well with others is key. Secondly, a strong understanding and appreciation of film history, camera framing, story telling disciplines, cinematic aspects of movement, action, comedy, body movement and staging. 

Tawd B. Dorenfeld, Polymorph Productions 
Patience, willingness to learn and share what you learn, and please check the egos at the door…you are not the Director on this so even if your ideas are way better than the Visionary in charge don't approach us with that attitude…make a suggestion and then drop it until someone asks you about it again. 

Other than that, talent goes a long way, but there are a lot of jobs that can be ‘taught’ in animation so when it is not about the creative in charge, I am just looking for good people. 

Brad Graeber, Powerhouse Animation 
At a service-based studio like ours, we look for drawing and animation skills above all else. We need folks with strong drawing fundamentals. At a service studio, you never know which project is going to come through next. It might be a piece in a Looney Tunes style, or it may be a commercial based on anime. If a portfolio looks like it is all drawn in the same “style” we probably won’t be able to use the person. Since no two projects are alike. 

Rich Murray, RichToons  
Obviously I look for someone who is creative and good at animation, (usually in Flash). But I also look for individuals who can think for themselves and make independent creative decisions. Once I give them my creative direction, I don't want to have to keep holding their hand through to the end. I like to trust that they will deliver great animations on time that are true to the project's vision. 

Gary Gibich, RenderJump 
We look for people skilled in the technical aspects of the computing world, and skilled in the programs we currently support, which are 3ds Max, Maya and Cinema 4D and plugins like Vray.

Terrence Walker, Art FX
The most important thing I look for is the artist's ability to draw different styles from what may be their own preference, and to be able to draw a character the same as another artist. Many artists get locked into their own way of drawing and become unable to do anything different. I recently had four interns who were all great at drawing their own thing, but when given the principal character from our animation project, only one could draw the character on model from multiple angles and in multiple poses. In the 3D world, I mostly seek very high-quality and high-detail 3D modellers. 

Laurent Donnay, TouTenKartoon 
We think of the company as a big family, so we like our crew to be involved, to care of the company as much as the company cares for them. We hire mostly young people just out of Animation School. Of course we select the best and guide them through professional training, to give them skills that school just can't teach. 
.I 37
.T
document.37
.W
The best and worst aspects of working in animation
If you've ever talked to a real live animator—just kidding, they don't really walk among us, they are far too busy working their 14-hour+ days—then you've likely heard the ups and downs of working in the animation industry. As a part of our Interview Series we asked animation executives around the country what are the best and worst aspects of working in the animation industry—to help paint a realistic picture for our future animator readers, exactly what its like to be an animation professional.
For those of our readers interested in knowing exactly what an animation career entails here is the good, the bad and the ugly from people with more experience in the industry than most of our readers have on this earth:
Richard O'Connor, Owner of  Ace and Son
The parties, the women and the non stop excitement--which is to say, the opportunity to constantly engage your imagination and create artificial worlds ranks amongst the best.
The worst is, like most crafts in a crass age, aspiring to make high-quality work in a field dominated by garbage.

Arthur Kautz, Aniben
The raising of capital is an entry barrier, particularly for studios that want to produce theatrical content. Software and hardware are expensive. Venture capitalists don't see the benefit of films and would rather invest in the latest internet 'thing' than movies. 

We need to shape their expectations to realize the next Pixar or Dreamworks can be created by one single animated film from a new studio doing well at the box office.

Paul Kakert,  Effective Digital Presentations 
The best aspect is that tools today (software and hardware) are so advanced compared to 10 years ago, that we have reached a point where you are limited only by your imagination (it wasn’t always that way as hardware was once a huge hurdle). 

The worst aspect is that animation and motion graphics has become so commonplace that its value (by clients) is often overlooked, or taken for granted. Clients see so many amazing effects and animation that they undervalue the creative effort that it takes to create something incredible. It’s a conundrum that plagues every aspect of computer design and it is evident as we look back at industries such as desktop publishing, which gave the illusion that anyone with the right software could suddenly produce beautiful graphic designs for print. We cannot loose site of the creative talent it takes to use the amazing tools available today.

Chad Briggs, Creative Director at  Element X Creative
Best aspect is that you can pretty much create anything these days. 

Worst thing is that you pretty much can create anything.

Sean Hutchinson, 3D Technical Director & Kate Ertmann, Producer at Adi 
Best: Creating awesome imagery that appeals to your personal taste and style (and the worst is doing the opposite of that). The best is complete control of production in a desktop environment: No rain dates, missing crew, pick up shots, etc. Another best is Just about anything is possible, if given the time, budget, and allowance for creative control.

Worst: Complete control of production in a desktop environment: We have sole responsibility for delivering compelling visuals from scratch. Sitting in front of a computer, time waiting on computers, explaining technical terms to the layperson, clients who like to noodle things just because it is digital. Another worst is that clients know anything is possible, but don’t always understand the direct correlation of that to time, budget, and creative control and know-how. Also, being a newer, creative, ‘hipper’ profession, people presume work is always fun and therefore don’t always get that this is a job and we need to get paid for it – even if it is a cool animation to produce.

Ian Johnston, Owner of  Too Many Legs 
The best aspect of working in animation is of course the fact you are working in animation! Animation traverses many forms and is useable in every medium, even audio. Sometimes the money dictates how creative you get to be. Balancing budget and creatively is a fine art.

Joe DiDomenico, Applehead 
Probably the best aspect of working in the animation field is being able to bring things to life. The artists at Applehead Factory take pride in knowing that a little piece of themselves can be found in each project we work on.

One of the worst aspects of being an animator these days is that people assume computers do all the work. Although the computers and the software we use aid in the creation of the animation we produce, they are still simply tools in our tool kit. The tools are only as good as the craftsman behind them.”
.I 38
.T
document.38
.W
Tangible advice from the pros for future animators
The point of creating our Interview Series was to provide tangible, actionable advice for aspiring animators—from people with real-world experience. And the series provided just that: advice from experts in the industry—men and women with decades of anecdotal advice.

Many of our experts helped create the industry we know today since way back in the 1970s, before they could fathom the technology we have today.These experts now run the animation studios that form the U.S. animation market—they hold the keys to breaking into the industry and hire for the jobs.

We've taken the best responses from dozens of interviews, and extracted hard-and-fast advice that future animators should use as their Ten Commandments for getting a job:

Kathy Rocchio, Slap Happy Cartoons
Aside from the obvious (learn and hone your skills) is to try and get to know as many supervisors, directors and producers as possible. Friends hire friends with talent and the community is pretty tight knit. Particularly here in Vancouver. Networking is key. Find out where they hang out and buy them beer.

Brad Graeber, Co-Founder of Powerhouse 
It’s about the time you put into the tools, not the tools themselves. When I see entertainment industry pros speak, I often hear younger animators ask them which version of what software they are using or what pencil or pen they like to use. Using the same pencil that Chuck Jones used won’t make you draw like Chuck Jones. You have to sit down and do the work, over and over, and then be able to look at it with a critical eye and make it better the next time.  

Simon Monahan, Serif
To get the best results, invest in a good quality graphics tablet that will help you develop your natural drawing style. Posting your work on sites and forums and becoming part of an online community to receive feedback and critique can also be really useful, as well as helping to keep you up to date with the latest trends and techniques.

Sean Hall, CRASH+SUES
Network, both online and in person. Do your own work and get it out there. Animation has the benefit that you can make your own projects to sell yourself with. 

Don't be afraid to send your reel around. You might not get a response right away, but that doesn't mean they didn't like your stuff. Most places are busy and don't have someone dedicated to hiring, so things can get lost in the shuffle. So try again in a month if you don't hear anything. Persistence and who you know, are the things that are going to get you in the door. Have fun and don't lose sight of your passion. 

John Ryan, Animation Director at DAGNABIT! 
Be passionate. Maintain focus. Develop a back-up plan. Marry for money. 


Mark DiGiacomo, Founder of Digital Elixir Studios
Get a full education because just knowing animation is today's equivalent of being a line worker at a car factory in the 1960's. Learn to write, read and everything else. Don't just be a technocrat because it won't be enough. 

Rob Corley, Funnypages Productions
At Disney we participated in portfolio reviews for many hopeful applicants wanting to become Disney artists, so the three most important words I can give any artist, even CG artists, is to, Draw, Draw, Draw! I know that can sound like a broken record, but nothing separates a great artist from a mediocre one more than a portfolio full of bad drawings. 

Keep a sketchbook and draw from life by going to the park, the mall or the zoo. Learn to adapt and observe as many styles as possible in order to give you an edge over the competition.  An extremely important piece of advice would be to never, ever, think that you can’t learn something new, because the moment you begin to believe you’re there is the moment you stop growing as an artist.

ADi
Limit every animation you do to 5-10 seconds in length when in school or practicing. When deciding to spend a week polishing an animation to perfection or making two more animations in a week, choose to do 2 more animations. Practice your craft, stay on top of technology trends, don't get discouraged, focus your goals.

Also, go into the field because you love it, not because it's considered "cool" or you think you will make a lot of money. Be an artist first.

Paul Griswold, Fusion Digital Productions 
Don't focus on the software. Learn photography, film-making, editing, acting, sculpting, theatrical lighting, and take some fine-art classes. I see so many horrible demo reels where it's clear the student doesn't know anything but how to push the right buttons in XYZ 3D software. Button pushers are cheap and easy to find.

Gabriel Polonsky, Gabriel Polonsky Studio 
Love what you are doing because it ain’t easy. Once you get out of school, you will get a second education by working in the industry, your career may take twists and turns you never expected (for the good and bad). Get your foot in the door, grab an internship, make contacts, do good work, don't piss people off, go where the work is, build a reel and a reputation.

Stephen Fishman, Mac and Cheez 
Like I had mentioned, create your own personal projects. It gives you a great overview of how finished pieces come together. Being a great roto artist or character rigger will be useful for larger companies but somebody who can create killer boards and animate them is indispensable for the boutique outfits. 

Kai Bovaird, AD/M
Get a solid grasp on movement and timing foundational skills. Also learn composition and framing. 


Arthur Kautz, Aniben
Pick the element of animation you like doing best and focus on that. Learning curves for new software are steep, and having a focus helps. Beyond that, try to broaden your artistic talents and understanding of movement. Study the great animated films. Go back and look at the early Disney animation; Snow White, Cinderella, Peter Pan and observe how they did things. See if you can replicate it in your work. 

Matthew Teevan, Arc Productions 
I find one of the problems that we are starting to see in visual storytelling – meaning animation and visual effects primarily – is that a lot of it is becoming derivative of itself. It can start to feel like a Xerox of a Xerox and loses a certain zest. Studying real life, real emotions is key. Reference real people or actors as much as other animation. When you can bring a level of internal ‘thinking’ to an animated character and make it behave the way that it really would physically, then you really have magic. 

Robert Stava, Arup
My own personal strategy has been to always look at the best that's out there, emulate to learn, then try and improve on it. You can learn quite a lot from traditional techniques. 
Work hard, be humble, be persistent. And be original. Your reel has to speak for itself so make sure the opening shots are your best because that's all a prospective employer may see before moving on to the next one. Then show variety - no one wants to see five minutes of the same thing. 

Also, know your target market. There's nothing worse than someone kicking off their reel with a bunch of dancing mushrooms when they're interviewing at an architecture firm: it announces you didn't bother to research the job you're applying for. 

Lastly: be generous with your knowledge - it'll come back to you two-fold. But keep a trick or two up your sleeve. 

Glenn Barnes, Big Sandwich Games 
Get involved in the scene. Whether you're an artist, programmer or designer, the best way to get noticed is to show a game that you've worked on. Hit the forums, hook up with some like-minded individuals, and start working on a game or a mod. That will show potential employers that you've got ambition and discipline, as well as showcasing your talent.   

Trevor Davies, Owner of CORE Animated Effects and Professor at Sheridan College 
Watch films other than animation. Watch international and independent films. Go to Art Galleries and travel when you get the chance. 

Gary Thomas, Crush
Work on your own projects constantly. We will not hire any new grad who comes to us only with student assignments. In this day, with the resources available there is no excuse for a lack of completed projects to show.

Andre Lyman, Clambake Studios
We'd recommend any applicants learn the tools of the trade prior to applying for a job. Those with internship experience at relevant production companies absolutely gain a competitive edge. We look for a clean, neat, prolific portfolio, and recommend you read up on the company you're meeting with prior to your visit. Last but not at all least, bring a hard copy of your resume with you to your interview! 


Paul Kakert, Owner of Effective Digital Presentations
Open yourself to the possibilities and evolve with what the industry needs. Know your strengths and your weaknesses and pursue the job or project that best suits the areas in which you excel. And focus on the design and artistic side of your education just as much as learning the tools of the trade. Animators are visual storytellers and artists just as much as they are technicians that must understand highly technical aspects of the process. 

Mark Cappello, Invisible Entertainment
Work your ass off, constantly challenge yourself and network with your peers. It’s actually easy to spot the rising stars in the industry as they are the ones who are drawing constantly, teaching themselves new skills and production modalities, and they always manage to maintain a wide-eyed wonderment towards all things animation.

Mike Drach, March Entertainment
If you feel you’ve got the vision, talent and business acumen to start up a studio, I encourage people to go for it. One strategy would be to pick an under-served market and become local heroes there. Another is to wedge yourself into an already booming market and hope to eventually get noticed by one of the bigger players.

Also, there’s a huge difference between being a shop, or your own studio developing original properties. I’d say the latter would be much more challenging unless you’ve already got a lot of interest in your idea or portfolio. Not having built a studio from scratch, I’m not necessarily the authority to give advice, though.

Charles Gaushell, Paradigm Productions 
Be aware of the good work that’s out there and set a standard of the quality of work you want to be doing. Get to know others who are working in the industry. Listen to critiques and learn the art of observation. No spaceships, skulls or bad character animations. 

Note that artistic skills are huge, but if you have to have everything handed to you and can’t solve problems then you are pretty much a technical artist. We want design artists – problem solvers that create exquisite illustrations and animations that tell the story needed by our clients. 
.I 39
.T
document.39
.W
What education does it take to succeed in the animation industry?
When you ask people whether it is necessary to get a formal animation education in order to break into the industry, responses can be somewhat muddled. “It takes an education from a top school”, “anyone with artistic talent and software skills has a chance,” to “it takes no formal education necessarily”.
To get to the bottom of things once and for all we asked top animation studio owners, executives, successful freelancers and other animation 'fossils' (as one interview subject put it) what their educational background is. After all, they have reached the top of the game. Here are the responses we got about how top animation industry professionals got to the top of their field, what formal and informal education got them there and additional online learning opportunities:
ADi
I have an MA in Digital Motion Imaging, Art Institute and two [other execs at ADi] were self-taught.

Kai Bovaird, AD/M
From an art school. When seeking a school do your research on who will be instructing the classes.

Arthur Kautz, Aniben
My background is as a hand illustrator, with a degree in Business Administration, and several years of management experience with large corporations before striking out on my own. 

Matthew Teevan, ARC Productions
I was self-taught so it’s hard to comment about education. When I got into the business it was the 1980s, in England. Unemployment was at an all time high – or should that be all time low - and the British Film Industry was all but dormant, virtually no films were being made and what was being done was heavily unionized. I was pretty unaware of any animation or film schools. I had done Art at school and I did a 1-year government-sponsored training program right out of school – I ran the projection room running 35 mm prints of ‘Citizen Kane’ for students, loaded cameras and handled a lot of the A/V equipment, chroma-key and the like. But I was basically self-taught and was making movies on my dining room table in Super8 and 16mm. I read a lot of books on film-making, watched a lot of movies and did a lot of experimental stuff.

I was told repeatedly to look for a different career. But I just pounded the streets, managed to visit the visual effects guys up at Pinewood and naively wrote letters (no e-mail back then) to people in the industry that I really admired and asked them how they got their start and showed samples of my work. Eventually small bits and pieces of all this paid off.

Glenn Barnes, Big Sandwich Games
I studied Fine Art and Digital Art & Design at Thompson Rivers University. The industry is full of people with degrees, as well as people with no post-secondary education at all.   

Tom Stathes, The Bray Animation Project
Self-education. I read books on animation history as a child and as I grew a bit older, I began to make connections with other individuals in the field. Nearly all of what I know and apply to my work was learned through first-person experience and networking. One can learn animation in a school and film preservation in select few universities, but nothing beats going headlong into the field and making connections without academia under one's belt. It is certainly possible to be fully self-taught in this realm of the arts.


Gary Thomas, CRUSH
I am a Sheridan College grad, but my real education came when I took my first job in this business as a Paintbox artist at Centro Digital Pictures, in Hong Kong. My life started the day I landed there. 

Anik Rosenblum, Dancing Line Productions
Art/drawing classes, an unfinished film degree and a two-year program in traditional animation. Also, I believe some general culture and life experiences always help. 

Jon Gallo, VP and Director of Motion Design for DraftFCB
I studied fine arts at the University of Iowa and completed my degree at Columbia College, Chicago, majoring in film.
.I 4
.T
document.4
.W
Movies, games and more – giving the world CGI
RAL
Years before Mario or PacMan or even Pong were conceived, a team at RAL started a revolution in animation. Their work sparked the creation of Computer Generated Imagery technology - changing the face of movie production and making computer gaming a reality. As such a longstanding champion of computer graphics and animation in the UK, we’re proud to continue contributing to a UK industry worth billions.
A 1960’s revolution
Back in the 1960s, employees at RAL began developing computer techniques to help researchers and engineers visualise scientific data as images or animated films.  The researchers realised these ground-breaking computer graphics and animation technologies had wider application and encouraged adoption through knowledge exchange with partners and industry.
CGI through the 70’s
In the late 1960s and 1970s this innovative CGI work caused the Financial Times to pronounce the Laboratory as the home of computer animation in Britain. At that time, RAL featured in a BBC Tomorrow’s World episode about the potential of computer animation.
Oscars and Aliens
STFC continued to lead UK CGI development, most notably by creating the computer imagery for Ridley Scott’s first ‘Alien’ movie. Its (sometimes terrifying) realism helped the film win an Oscar in 1980 for best Special Effects. The success of ‘Aliens’ spawned a whole sector, with many new companies commercialising the CGI concepts and code developed by STFC and introducing them to new markets.
CGI today
At the time, the early pioneers of the 60’s would have had no idea just how big CGI would become. The UK computer animation industry now has revenues of £300 million. It also directly supports other UK industries, including the post-production industry worth £1.4 billion and the gaming sector worth £1 billion. Worldwide the digital animation industry is worth a staggering £120 billion today.
In addition, the graphics industries today are underpinned by international computer graphic standards developed at RAL.
.I 40
.T
document.40
.W
Gabriel Polonsky of Gabriel Polonsky Studio Talks Diversity in Animation
Some animators accidentally stumble into the animation industry, others are highly-trained to do it—Gabriel Polonsky however was drawn to it. Gabriel was born to two artists, giving him a more-artistic pedigree than most animators in the industry. At just 5 years old his father introduced him to cinematic art forms, "my father taught Fine Arts at Boston University and one day he brought home a Regular 8 camera and taught my me and my brother how to do clay animation that was the start of 15 years of film-making."

It is no surprise then that Gabriel's rich portfolio still includes clay animation to this day, as well as traditional animation and live-action production. After a successful career as a freelance animator and illustrator, then a 5-year stint at a Boston production studio, in 1992 he started Gabriel Polonsky Studio and has successfully led his team ever since.

Gabriel has spent the last 20 years building-up his studio, making it one of Boston's leading animation studios producing 2D (cel), stop-motion, mixed media, clay animation and live action, in combination with computer animation and digital effects (for the studio's full portfolio of work click here). And, for the last 18 years he has been teaching the art of animation.

We got a chance to, virtually, sit down with Gabriel to pick his brain about the strategies he used to be a 20-year industry success story. The turn-out was fantastic, with some of the most strategic, poignant advice we have received to date in our Interview Series:

For any of our readers not familiar with you could you explain your studio's vision and what separates you from the (vast) competition?

My studio is an outgrowth of my own personal artistic vision: I like the challenge of constantly evolving artistically and working in many different ways. To me there are no dividing lines between styles, mediums, and genres; fine art and commercial art--it is all art! What excites me about animation is that it incorporates so many art forms. For example we might create a stop-motion kinetic metal sculpture animation for Sci-fi Channel (SyFy) one day, a Warner Brothers style series open for PBS the next day, a retro style character for a Miramax film the next day, and so on. We do many forms of animation including 2D on paper with digital or traditional ink and paint, Flash, After Effects, stop motion, pixillation, live action, and mixed media of all kinds. So I guess what makes us unique is our lack of a directed vision; diversity is our vision!

As a creative professional how have you handled the business-side to running an
animation studio?

I actually enjoy the business-part part (strange for an artist to say that, I know). I do not have a formula, it is an on-going process, and I learn from my mistakes. Repeat business is always important, which means striving to deliver a little more than clients ask for and treating your crew well. When executing a client contract it is crucial to clearly outline exactly what you are doing and how you are doing it. Working for other companies, I've seen projects go awry because those things were not clarified upfront. Clients feel at ease knowing exactly what they are getting, the crew is most-productive knowing exactly what is expected of them, and it is important to set reasonable boundaries about how many client revisions are expected. Delivering good work and service to clients is vital because they will act as 'sales people' for your company by spreading the word about you.

How did you initially get your foot into the door of the animation industry?

After years as an independent animator, filmmaker, and artist, I walked into Olive Jar Animation in  Boston with my portfolio and demo reel one day and worked for them for the next 5 years. It was a unique place with very talented people, and they did some amazing work. I learned a lot there,mostly working on clay animated TV commercials.

What kind of education did it take to get you where you are today?

I am self-taught and from the school of hard knocks. My parents are both well-known fine artists and educators so I grew up around art of all kinds. I began animating, sculpting, drawing, painting, and film-making when I was about 3 and never stopped. As a professional, I have had the great fortune to work with some of the best people in the industry, collaboration is one of the best ways to learn. Otherwise, (as I tell my students) keep your eyes and mind wide open, the answer to every creative question is out there. Formal education is wonderful (I have been teaching college animation and art courses for 18 years) but NEVER discredit or underestimate your own ability to teach yourself and trust and develop your natural talent.

Who does the hiring for your company?

I do .

Has the trend of overseas animation outsourcing affected your firm, if yes, how have you dealt with it or compensated for it?

It is a double-edged sword. It has enabled US studios to produce great series work for lower budgets, but also has driven the budgets down and competition up. I am more focused on short-form projects such as TV commercials, series opens, and network ID's which are not effected.

If you were going to hire a new employee/intern what qualities would you look for in a person and portfolio and where would you look?

I look for great artistic talent, amazing animation skills (with a focus on character acting, emotion, and timing), easy-going personality, and diverse abilities. Almost all of the freelancers I hire have worked with me for many years or decades - I think it is important to stick with good people. I rarely post on Craigslist or freelancer sites, you get too many responses to sift through. I prefer getting referrals from people I know in the industry. I also occasionally hire former students.

Do you hire freelancers? If yes, what would make you throw work their way?

Hmm, freelancers who may know lots of software but obviously do not have natural talent. Someone who does not give a phone number with their inquiry, if I'm going to hire someone, we need to talk live first to get a feel if it is a fit.

What animation software packages does your firm prefer to use? Which one would you recommend to beginners?

I really have no preference, it depends on the project needs. Flash is great for learning simplev2D animation if you use it 'traditionally' (I mean drawing keys and tweens). For really hardcore, squashy-stretchy, Warner Bros. style, 2D character animation, I still prefer doing the animation on paper with digital ink and paint (in Animo or Toonboom). Also After Effects with puppet tools is good too, and Photoshop. Even Digicel Pencil test (and others) can be useful for certain projects. I also like using traditional hand-crafted techniques as much as possible

What advice would you give to aspiring animators looking to break into the industry?

Love what you are doing because it ain’t easy. Once you get out of school, you will get a second education by working in the industry and your career may take twists and turns you never expected (for the good and bad). Get your foot in the door, grab an internship, make contacts, do good work, don't piss people off, go where the work is, build a reel and a reputation.
.I 41
.T
document.41
.W
Animation Industry Jobs Forecast
The animation industry is in a constant state of flux. Job roles change almost as quickly as the technology and the industry as a whole is forced to respond to the increasingly high-quality work coming from overseas studios. At the same time the advent of the internet, smart devices, new media and more are demanding animation on grander scales, compensating for overseas outsourcing.
Due to this unpredictable maelstrom of activity many young would-be animators are debating getting into the industry. You might be one of them. So, as part of our  Interview Series we asked our experts to forecast what the industry will be like in coming years—experts who have lived through the invention of computers, changing technology, outsourcing, boutique-style animation studios and so much more.
We put together their best responses below to give you an expert view of where the industry is likely going, whether there will be an increased or decreased need for animators, and what type of jobs aspiring animators can expect. Be warned though, this is not a rosy-eyed view of the industry, it is the hard truth along with a little advice on how to find a comfy spot for yourself within the industry:

Richard O'Connor, Ace and Son 
The job title "animator" has changed in the past decade or so. For "animators" there's more work -web stuff, motion graphics, compositing. For "animation artists" which was once the bulk of the industry (inkers, background artists, designers, coordinators, checkers, and on and on) there's significantly less demand. The "animator" may do less animation than in years past, but the work an "animator" does has increased. 

ADi
There is certainly an increase in demand, as movies, TV and video games are all filling up with 3D effects. You must learn however, to both specialize and generalize, which is a difficult tightrope to balance on. It does what video can't. You can show something microscopic or show the internal workings of any sort of object – be it organic or inorganic. Animation has become a business tool, not just an entertainment tool.

Kai Bovaird, AD/M 
There will be an increasing demand for animators. Many more smaller studios will open over time and need to fill their ranks with qualified artists.

Arthur Kautz, Aniben
Animation will continue to be strong. As an industry in the United States we have to demonstrate and convince studios and producers we can be cost-effective and to stop shipping work overseas. I believe we will be able to make this case and keep the industry vibrant and viable. 

Matthew Teevan, Arc Productions 
I don’t have any statistics to back this up, but between the TV work, animated
movies and the number of character-driven visual effects shows I think there
is more animation being done now than ever before. Children’s television has
always been dominated by animation. But now, the creative opportunities are
pretty limitless and this is allowing stories that would not have been possible 10
years ago to be made. 
On a practical note, Animation is also one of the more labour intensive parts
of CG. Even with a stylized look, you still need the character to resonate with
the audience. It will be interesting to see how (and when, and if) performance
capture techniques will start to put any of this type of work back into the hands of
actors.

Bill Hughes, BamTUBE
Animation is now part of how we tell stories. I guess cave paintings eventually fell out of fashion, but storytelling is still part of the human condition. Animation should be around for a long time and in larger and larger doses.

Glenn Barnes, Big Sandwich Games 
Demand for developers is definitely increasing, but so is the supply. The market is only getting bigger. Guys like me who used to play Atari 2600 in our basements are still playing games 30 years later; as we age, new younger gamers are recruited and the gaming population grows. Additionally, you've got the casual games revolution, which turned middle-aged housewives into PC gamers, and senior citizens into Wii/DS addicts. Both of those demographics wouldn't touch video games a decade ago. Even so, there are far more developers around now than there were in the 90s, even just in North America. The result is lots of demand for developers...but lots of competition too.  

James Rumpf, Creator of Cartoongems
I think it is increasing because the cost of Flash Animation is becoming more
and more affordable. 

Gary Thomas, Crush
I think there is a demand for animators with real unique vision, but a declining demand for animators who simply fulfil a technical role. Those roles are always the first to be outsourced. Creativity is harder to be sent offshore. 

 

Anik Rosenblum, Dancing Line Productions 
I think it fluctuates, going up and down every few years, depending on new technological trends, the economy, globalization, etc. Really good animators are always in demand, but generally, animation schools produce hundreds of new graduates every year, yet even in good times there is no proportionate growth of studios (or retirement rate to match), so obviously many will struggle to find a job.
.I 42
.T
document.42
.W
Recommended animation software for beginners
With the myriad of animation software programs hitting the mainstream, leaving the choice up to aspiring animators is like letting kids loose in a candy store. By that of course I mean they are only limited by the amount of change jingling in their pocket.
To help our aspiring animator readers choose the right software tool(s) we have taken the best pieces of advice from our Interview Series when it comes to animation-industry software standards and programs, and filed it down to a list of prorgams most-recommended, by pros, for beginners:
Richard O'Connor, Ace & Sons
Software is a secondary concern for beginners. Anyone can learn it. If you don't understand animation and film making all the technical skills in the universe won't make you a good animator.

We mostly use the Adobe suite -Flash and After Effects. These are typically combined with other media.

ADi
We use AutoDesk products – mainly 3D Studio Max, and sometimes Maya. We also use AfterEffects and the whole suite of Adobe products. Also a variety of plug-ins. Try anything and everything you can get your hands on. Be versatile. I would suggest that beginners use free software, or failing that, Cinema 4D.

Kai Bovaird, AD/M 
We use many products from Autodesk, The Foundary and Adobe. Learn what ever your local companies are using. Don't get too caught up on any one particular software. Its ONLY a tool. Learn the foundations! 

Arthur Kautz, Aniben 
We use Maya and 3ds for 3D work, Toonboom Storyboard for board work, and Adobe Illustrator. Maya is an industry standard and a beginner might as well start with that package. The transference of technique is what is important between software packages.

Joe DiDomenico, Applehead Factory Design Studio 
We primarily use LightWave 3D for our 3D animation and Flash and After Effects for our 2D animation. All three of these tools are great for beginners that are interested in getting into animation. 

Robert Stava, ARUP
3ds Max is the primary package we use, augmented by other software like Dynamite, Vue Xtreme, Craft Director tools, After Effects, Composite, etc. Max is fine for all levels of users. 

Glenn Barnes, Big Sandwich Games 
For 3D, we use both Maya and 3DS Max, and both are represented more or less equally within the industry.  Either of those would be a great place to start for beginners. For 2D, Adobe Photoshop is definitely the standard, and even 3D artists use it every day for texture painting and render touchups.   

Brad Trofin, Bradleez Cartoons
I almost exclusively use Adobe Flash. I love that program! It allows artists to be artists and it doesn’t smother artists with too much “techy stuff”. 

Brian Seger, Chromavantage 
I prefer Maya for animation. My newest inspiration is using Modo. I can't wait to open that every day! I would recommend Modo definitely. Having gone through Maya training and remembering what that learning curve was like Modo seems to be very intuitive. 

Trevor Davies, Core Animated Effects and professor at Sheridan College Animation
The standards vary from studio to studio but locally, I think you will be marketable with good skills in Photoshop, ToonBoom or Flash, Maya or 3DMax, Sculpting Tools like Mudbox or Z-Brush, After Effects and Premiere or Final Cut Pro. 

Gary Thomas, CRUSH
We have Maya, and Cinema 4D. Cinema 4D is an excellent package priced for the real world. Plenty of good tutorials available online too.

Andre Lyman, Clambake 
Our studio works with the Adobe Creative Suite, and we animate in Flash. Our designers work in Photoshop, audio editors in Protools, and editors in Final Cut Pro and After Effects. Our storyboarder is working on good old fashioned paper! But, we seek a strong knowledge of Flash and Photoshop in general.
.I 43
.T
document.43
.W
Animation: challenging projects and their solutions from industry execs
The animation business is just that, a business. Despite being 'animators' by trade, animation executives, studio owners and successful freelancers run into the same business-side snags time and time again.

To help our aspiring animator readers preemptively tackle these problems head on we have taken the greatest challenges (and solutions) that our Interview Series interview subjects have come across and put them in a handy list:
Richard O'Connor, Ace & Sons
The most challenging projects are ones in which the client gives you more grief than money. In nearly two decades, I've really only had two of those -one a children's series, the other a theatrical film. Both of these came down to trust. The client needs to trust that the animator will deliver a quality product and the animator needs to trust that the client won't rip them off. Only twice were both of these abrogated and it made for difficult obstacles to overcome.

ADi
Projects where clients don't have a clear understanding of their audience and outcome goals, or doesn't have an investment or hierarchy for arriving at a consensus on feedback. Also, animating subject matter that I'm not interested in.

[It is challenging] When there is some sort of barrier to being able to establish a trust-base with the client – then every review is subject to questions based on there being ulterior motives for the deliverable between client and vendor (us).

Matthew Teevan, ARC Productions 
Every project is challenging. In different ways. Gnomeo & Juliet was artistically challenging – it was a huge step-forward from our prior work. The subject matter was challenging too, in that we had to figure out a way to stay true to the central idea – garden gnomes coming to life, and make them look and behave like those inanimate objects. Yet still imbue them with the necessary level of character to make the story, and the comedy work. That took a long while to find that balance creatively, then to support that endeavor practically. Dolphin Tale was challenging due to the nature of the work. Our visual effects had to be invisible as we were creating the central character and cutting our shots back to back with the real Winter. 

Robert Stava, ARUP
Government projects. They tend to have shifting objectives and a lot of time and money to achieve them. Which can be good and bad depending on your POV. 

Glenn Barnes, Big Sandwich Games
There are always a lot of challenges, but one that stands out in recent memory is the business and financing aspect of HOARD.  We developed the game on bridge financing through RBC, based on the pledge of a completion payment by Sony's Pub Fund, and a loan guarantee by Export Development Canada. While this has apparently been the way to do it in the film industry for quite some time, we're the first Canadian developer to do it for a video game.  As the trail blazers, we had to invent the process as we went, interpreting and reworking a finance model that was developed for a different industry.  After stacks of agreements and much pain in getting the monoliths that are RBC and Sony to play nice with each other, we finally pulled it off. 

Trevor Davies, Core Animated Effects and professor at Sheridan College Animation
They all offer unique challenges I think: TV commercials because of their tight deadlines, documentaries due to limited budgets, the sheer volume of work in television series production and feature films because of the of the longer format and the increased scope that affords. 

Jon Gallo, DraftFCB
The most challenging projects, in retrospect, were the most rewarding.

There have been so many but one that comes to mind is the time we had to figure out how to generate a photo-real particle dust cloud shaking off a falling 3D title made of nacho chips on impact - complete with a spattering of powder on the surface. Round after round with particle generators got close but it still had that "plug-in" look. An editor on our team overheard our struggle and offered up this gem: "Powdered sugar. Just shoot some powdered sugar dropping onto a black card." We could do that... (sound of multiple palm-slaps to the forehead).

Sometimes you get so obsessed with making one technique work that you forget to take a step back to consider other options. Anyway, we had a great time shooting the footage. Everything and everyone on the stage was covered in a thin layer of white powder by the time we wrapped. The end result looked terrific. Thank you, Robert. Lesson learned (again).

Paul Kakert, EDP 
The most challenging projects always boil down to size and scope and managing a team to produce the animation. We have done large architectural walk-throughs of airports and new buildings that involve very complex and detailed CAD drawings. The coordination of the technical engineering side and the artistic animation side is a full-time effort for projects that can last as long as a year or more. 

Ron Allen, GAPC Entertainment 
Back in the 90’s our company was hired by the Department of National Defence to create a series of training videos for CF-18 Hornet fighter pilots, on the operating envelopes of the plane with different fuel/weapons configurations. At the time there were no websites where you could buy a F-18 model so we had to model it from scratch using photos and some rough schematics as our references. The software we were using (Intelligent Light) had a limited graphic user interface so most of the modelling and animation were scripted-–very time consuming. Fortunately we had a good budget and were able to fine-tune things and add the extras that make a project schwing. I look back at it and the videos still hold up today almost 20 years later.  

Tawd B. Dorenfeld, Polymoprh Productions
My most challenging projects are the middle-budget projects. An appropriately budgeted project will get done and generally without heart-attack 24 hour days. The greatly inappropriately barely-budgeted projects (but are too good to walk-away from) also will get done because the immense limitations force us to only do what we can but do that really good. The projects that fall in-between those are the difficult ones. Generally those jobs are not funded well enough for the visions yet the vision needs to be accomplished.

Here we have to blend our dreams with reality and there is a lot of compromise in that…Compromise in a good idea can make something sour fast and because of that, everyone from the bottom up, client, and crew alike are all walking and talking on egg shells. At the same time, most jobs fall into that middle category and we all survive because we all just love what we do. 

Kathy Rocchio, Slap Happy Cartoons 
We have had a show in active development for over 5 years, with three different broadcasters. It is a fantastic show with great positive feedback, but has yet to receive a production order. I guess I would actually describe that as frustrating rather than challenging.... All animation production is challenging! In the mid-nineties I worked on a CD-ROM game. I have put game production on my list of things to never ever do again. 
.I 44
.T
document.44
.W
Most wanted: Top animation schools according to industry execs
For those of our readers considering starting a career in animation by picking one of the many, many, many animation schools popping up around the country—consider this advice from our expert panel (made-up of executives, studio owners, decade-long freelance success stories, etc) about which schools they look to when hiring new interns and employees.

Here are the responses from our Interview Series subjects about their go-to schools when looking for new graduates:

Richard O'Connor, Ace & Son
We've hired from SVA, Parsons, RISD, Pratt and University of the Arts. These are mostly local schools since entry-level positions don't offer the best salaries for artists who need to relocate.  

Joe DiDomenico, Applehead Factory Design Studio 
Most of the artists we have worked with over the years have come from either the University of the Arts in Philadelphia or the Digital Animation and Visual Effects school in Orlando. That said, it's more about the artists portfolio and even more important, their personality. We try and work with artists that will work well with the existing team.

Matthew Teevan, ARC Productions
We are fortunate based on our location (Toronto, Ontario) we have some really
 good animation schools locally – Sheridan and Seneca are world class – and there
are others too. We have hired several people right out of college and they are
thriving. 

Robert Stava, ARUP
We get our referrals mostly (99.9%) from the community itself - in our case, the local 3ds Max and After Effects user groups. It's the best place to network and find new talent, really. 


Glenn Barnes, Big Sandwich Games
I've found that Capilano University in Vancouver has an excellent 3D art program, and usually produces a good crop of talent every year.  If we're actively hiring junior talent, that's usually the first place we look.  

We don't value one school over another when reviewing applicants though; it's all about the portfolio. I once looked over a portfolio from an artist with a Masters' degree in illustration, who seemed to have only mediocre drawing skills. I've also worked with, and hired, some immensely talented and productive artists who were simply self-taught.

Trevor Davies, Core Animated Effects and professor at Sheridan College Animation
Sheridan College, St. Clair College and Centennial College.

Andre Lyman, Clambake
We have developed strong relationships with the career centers of various local art schools, and look to their career advisors when hiring. These schools include RISD, MassArt, AIB/Lesley, and Emerson. We've also got a couple of SCAD alums on our team now.

Mark DiGiacomo, Digital Elixir Studios 
This is a tricky question. Right out of school is often our hardest choice, since sometimes they show a great reel but too often they seem very limited in scope and capability, even if they are good. Often the work is not that great, but in the last couple of years we've noticed the reels looking a lot better in general. I can't recommend a single school, since submissions are so varied from around the globe. I can tell you that some of the work from students coming out of continental Europe is incredible. 

Link Starbureiy, Creator of Egglepple
I'm biased. I did all my research stuff at The Ohio State University, so I'm loyal to the 'Campus in Columbus'. Rightfully so, because they have some really great programs, labs, and institutes, namely ACCAD and HCGL. Anyone with that training gets noticed by me (and many others, I'm sure), right off-the-bat! 


Darcy Vorhees, Flaming Medusa
I am always keeping my eyes out for artists that come from animation programs in Cincinnati, and the Columbus College of Art and Design is a very well respected school that is also nearby.  Really, though, the portfolio is all that is a requirement. I prefer to receive emails from people who are interested in the company with a portfolio website in the body of the email. I also look for connections at conventions, artist-centric events, and during other arts-networking opportunities. 


Jerry Chambless, Illum 
There are several great schools that are turning out talent, both formal & virtual. We have contractors from Ringling College, Cal Arts, Savannah, Sheridan, Columbia.

Mark Cappello, Invisible Entertainment 
We are not snobs when it comes to requiring specific educations. Some of our owners graduated from college (Sheridan and NSCC), and some of them never graduated from an animation course at all. The natural talent combined with an opportunity to lean in the actual industry can be much more of an education than 3 or 4 years in school. I like the Sheridan graduates who are not already convinced they are ready to be art directors, and I really like the graduates from Ottawa’s Algonquin College, they have a strong work ethic, they benefited from great instructors, and unlike some Sheridan grads they have a refreshing lack of arrogance and entitlement. 

J.J. Sedelmaier, JJ Sedelmaier Productions 
Good schools that seem to prepare their student are: Rhode Island School of Design (RISD), School of Visual Arts (SVA), Ringling College of Art and Design, Savannah College of Art and Design (SCAD), Virginia Commonwealth University (VCU), CalArts. 

Joddy Eric, Madwerkz 
We recruit from many schools in the Midwest, some of which are Cuyahoga Community College, Cleveland Institute of Art, Columbus College of Art and Design, Pittsburgh Institute of Art, Kent State University, Virginia Marti College and Cleveland State University

Michael Domgard, Outpost12 
While we don't favor any school in particular, but we have often found a wealth of talent from the Johnny Carson School of Theatre and Film at UNL, and from Full Sail University in Florida. 

Brad Graeberm Powerhouse Animation 
Since we are in Austin, we have folks from the University of Texas and The Vizlab at Texas A&M. We also have several folks from Savannah College of Art and Design, Sheridan, and Austin Community College. We do not specifically recruit from any school or program. We receive many demo reels and portfolios and look at the work.


Kyle Clark, Reel FX 
We recruit from Ringling, Texas A&M, SCAD, University of Texas Dallas, and a number of other schools.

Nadine Zylstra, Sesame Workshop 
We don’t generally recruit new hires from schools, but we use a broad network to commission animations directly from filmmakers. We do not have a preference- if a filmmaker is fresh out of school but has a great idea that is good enough for us. 


Brendan Burch, Six Point Harness 
We have had a lot of success with Sheridan in Canada, Cal Arts and USC.

Kathy Rocchio, Slap Happy Cartoons
Cap College, VFS and of course Sheridan are favourites, however we have hired people without any previous animation experience. Since a big part of our business is development, we are continually looking for new design styles that will work for our 2D projects. We often troll graphic-artist sites for people with unique styles to help create an initial pass of design that will help us sell a show idea. 


Sean Hall, CRASH&SUES
We recruit from schools locally. MCAD for the most part. We have an internship program, and that's usually where we find our talent. We again don't have a large staff, so we like to find people who will come on as freelancers for our bigger projects. Of course though we welcome talent from anywhere.

Brian Deans-Rowe, Stone Fence Studios 
Boston University Center for Digital Imaging Arts is educating a new generation of great talent, and I have the privilege to work with them often as an Instructor there. As a New England company, SFS is fortunate to have access to other great area schools, such as RSDI and Massachusetts College of Art and Design.

Terrence Walker, Art FX 
We all know CalArts is the premiere school from which talent comes these days, but I believe the internet is far more important in these extremely busy times. Although I mostly deal with contractors, it is from their online presence that I find them. When I come across an incredible talent on the net, through an art forum, YouTube video, or their own site, I will bookmark it, make note of it, knowing that I may want to work with them in the future and that I will call them if I think their work can fit a current project. I think it is important for any artist, whether fresh out of school or not, to make a website, join other popular art websites and showcase their work. I know of a few artist who got real industry jobs because of their gallery on the Deviant Art website.

Todd Schowalter, Studio Todd 
Most of my animators are those who have either approached me, or I have found through their websites.

Mary Nittolo, The Studio
I have taken several students from NYU, SVA, and Ringling College, but we interview and hire from anywhere. It's the work that counts.

Bert and Zeea Moss, The Untitled Animation Project 
I'm not really interested in what school someone went to and I don't think it's particularly indicative of how good an animator they are. I've seen some awesome animators come out of SVA and I've seen some that thoroughly suck. If you suck as an artist or animator and go through the art school system, you'll come out the other end as a sucky artist or animator with a diploma. I hire mainly through referrals and networking, but I sometimes advertise on Craigslist, Mandy, Motionographer, AWN and other industry sites if I want some new talent. 
.I 45
.T
document.45
.W
Cloud Case Studies: The Animation Industry	
With the advent of Cloud Computing technology, the ability to dynamically scale up and down has become cost-effective and accessible even to small organizations. All over the world, major companies are migrating their operations to the cloud and finding creative new ways of incorporating the technology into their businesses.

HP, for example, utilized the technology by offering a cloud based music and video streaming services over Touchpad, effectively beating Apple to the punch. Apple has since caught up, and are trying to raise the stakes by also delivering Video on Demand via Internet-capable Smart TVs and Blu Ray players. They are also planning to expand the services to PCs by allowing subscribers to watch the movies they rent or buy through web browsers.

Aside from using cloud technology to offer entertainment and multimedia content over the web, various companies and organizations are also seeing a potential for using the concept of cloud computing for the animation industry. The main reason being that animation these days, whether it’s 2D or 3D CGI, requires massive amounts of computational resources. Normally, animation studios invest a lot of money in buying entire server farms and workstations in order to have enough computing resources to render their animated projects. Added to this is the cost of hiring IT people who will maintain the hardware and the electricity needed to power the hardware.

Cloud service providers are seeing the potential of delivering on-demand and dynamically scalable computing resources as a service, which will allow the animation industry to adopt a more cost effective pay-as-you-go models instead of constantly bleeding money over hardware and manpower that they don’t really use all of the time. Getting rid of all these costly infrastructure will reduce operational costs as well as streamline an organization. Additionally, cloud technology itself gets rid of glass ceilings that the animation industry bumped into in the past, wherein they were limited by the amount of hardware they can muster. With cloud technology, their needs can be met by highly scalable infrastructure.

The Current State and Needs of the Animation Industry
The global multi-billion dollar animation industry these days is dependent on 3D animated film projects that are full of photorealistic textures, colors, expression, and movement. Blockbuster films like Wreck-It Ralph and Brave are constantly pushing the limits of what animation is capable of, when an animator’s skill and talent is mixed with massive computing power.

As an example of how much computing power the modern animation industry requires, it is not unusual for big name studios to spend more than three hours just to render each frame of a CG film on a workstation. For example, it took Pixar two years to completely render all 114,000 frames of the 77 minute film Toy Story using a render farm with inherent parallelism.

The need for massive computing resources is not limited to animated movies, as even live action movies like the Avengers, Thor, and Spider-Man require scenes to be shot in CG, as the situations involved would not be possible using conventional stuntwork and actors. Another added cost that the studios need to shoulder is the license for all the software they work, as there’s no professional-level animation and rendering software. All of these must be bought and licensed for each workstation that will use it.

The massive costs involved in producing an animated movie these days, combined with the rigorous deadlines that they have to meet in order to satisfy quotas and seasonal schedules means that they would benefit from something that can reduce the amount of rendering time, the overall cost of rendering, as well as free up a lot of manpower, which they can then divert into other parts of the business.

Cloud Computing for Animation
The first animated film that took advantage of cloud technology is “The Painter,” which is a 4 minute animated short about a tiny robot whose artistic quest is nudged along by a Genie with the right tools. The short’s rendering was done on a Utility Rendering Service, with the power used being the equivalent of a single Pentium III Proliant server working 24/7 for 278 days. With the URS, the rendering of The Painter only took three months to render. Later on, DreamWorks decided to use URS for their own project, Shrek 2, marking the first time a big name studio used an external infrastructure for their rendering process.

Another aspect of the animation industry that will benefit from Cloud Computing is startup, as there are many startup animation shops that would have otherwise not been able to start due to the high cost of entry. With the cloud’s pay as you go and pay per use models, new animation studios don’t have to invest hundreds of thousands of dollars for render farms and workstations that won’t be able to recoup their investment yet. With cloud rendering farms, animation studios can start small and then scale up once their needs increase and their budgets get bigger.

Case Studies
If you pay attention to the details found in old CG animated films like Shrek and Toy Story, to new ones like Rise of the Guardians and Up, you’ll see that the detail and quality of textures have risen to the point that some scenes already look photorealistic, and could be mistaken for live action if it weren’t for the stylized animated styles. This increase in clarity means that the demands on data storage infrastructure has also increased dramatically, and animation studios now find that they need to store and retrieve extremely large amounts of data at high speeds, and they are in need of a cost effective solution that could still scale well when growth requires it.

To handle this conundrum, DreamWorks Animation has partnered with cloud computing provider Cerelink, which will allow the former to render computer animated films using the latter’s computing resources in a facility at the New Mexico Applications Center. The ability to quickly scale up and down their computing capabilities allowed DreamWorks Animation to better manage their upcoming slate of films, resulting in a series of movies that came out one after another, while other animation studios had to wait almost a year before starting with their next project.

The US is not the only country with an animation studio that already realizes the potential of cloud computing. India is catching up, with its Crest Animation Studio and Lions Gate partnering in order to produce the 3D stereoscopic animated film Alpha and Omega. Lionsgate effectively outsourced the animation and rendering of the movie to India. The movie was rendered using the cloud computing capabilities of a super computer from the Computational Research Laboratories, called EKA.

EKA, which is Sanskrit for number one, is rated as the fourth fastest supercomputer in Asia at the time of its release. The computer cost $40 million to build, and has a peak performance of 120 to 170 Teraflops. The EKA also has a capability to introduce “checkpoints” into the rendering process, which is where it saves the state of the task every fifteen minutes without stopping its main task. The benefit of this is that any problems that result in the rendering being halted doesn’t require the rendering to restart from scratch, as it can go back to the check point, which means it only loses 15 minutes of progress.

Conclusion
Major animation studios these days are making strides in the field of animation, as cloud computing technology allowed the studios regarding of size to churn out high quality animated projects without getting bogged down with hardware upkeep and maintenance costs. The cloud has also opened up the industry even to amateurs and budding startups, providing a level playing field where the only limitations are in the mind.
.I 46
.T
document.46
.W
Computer Animation Industry Barrels Along
Robi Roncarelli

Though the computer animation industry seems to change unceasingly, one constant has been its relentlessly strong growth. The latest year analyzed in The Roncarelli Report on the Computer Animation Industry was no exception, with the total value of global commercial computer animation production at $25.4 billion in 1999, a 25 percent increase over the previous year's total. Though not as large as 1998's increase over 1997 (29 percent) or 1997's over 1996 (35 percent), the growth is still impressive, especially considering that the raw cost of computer animation production has been reduced by improved technology. 

Within this overall growth, changes have occurred among the 14 different use categories we employ to track computer animation: advertising, architecture, broadcast, corporate communications, design engineering, education, film and television content, games, legal and insurance, medical, personal, scientific, location-based entertainment, and the Web. 

Games grew aggressively in 1999, for example, with a 63 percent increase in market dollars. The total amount now being spent on game animation is $2.8 billion, which makes it the second largest computer animation category in terms of sheer dollars, accounting for 11 percent of overall production. Web animation, with a hefty 89 percent increase over last year, still accounted for only 4.3 percent of the total market share. As in former years, the creation of imagery and special effects for television programs and movies leads the pack in terms of dollars, with close to $10 billion spent this year, accounting for 37.5 percent of the total CG animation market.

Indications are that these growth patterns are continuing into 2000 and 2001, and will last for more years than we care to forecast here. Experience indicates that while there may be variations within the statistical makeup of the industry from year to year, overall trends remain the same: lower production costs, continued industry growth, continuing expansion of uses and applications, and growing desire for computer imagery on the part of users and viewers.

By 2004, we predict that the total production volume for the computer animation industry will be $60.5 billion, more than twice the 1999 total of $25.4 billion. Trying to predict what uses that expanded computer animation production will be devoted to is a bit more difficult. Web use and game development represent the user categories of greatest potential.

Last year, we expected these uses to erode percentage shares for advertising, broadcast, and film and television production. Erosion has occurred for the first two categories, but the film and television category has grown appreciably, as viewer and user demand in this area continues to be quite strong.

We believe that in total, the broad-scale uses of computer animation production will not change significantly. The entertainment and communications applications will continue to dominate usage, and remain the major impetus for industry development as producers demand new and more astounding images in their fight to retain and capture users and viewers. 

All in all, we do not expect any major softening in the industry's double digit growth trends for the foreseeable future. And while the total computer animation and effects product will continue to be a familiar entity, how it is created and how it is presented to us will change, and the technology and devices used in that process will be constantly evolving. 
.I 47
.T
document.47
.W
Global Animation Industry: Strategies, Trends and opportunities
The rapid advancement of technology has made computer animation available to the masses and the animation industry is one of the fastest growing industries. The demand for animated entertainment has expanded with the increase in broadcasting hours by cable and satellite TV along with the growing popularity of the Internet. In the past, animation series were aimed at children aged nine and below. In recent years however, TV stations have been producing animation series for teenagers, adults and the whole family. Animation series like The Simpsons and King of the Hill have been successfully aired on primetime TV. The major markets include the United States, Canada, Japan, France, Britain and Germany. Licensing operations for T-shirts, caps and other items have also been a major source of revenue for animation companies. In Japan, several successful computer games have crossed over and have become animated series like Pokemon, Monster Farm, Power Stone and Detective Conan. More broadly speaking, animation is increasingly used in video games, and movies are also increasingly reliant on animation and computer graphic special effects.

Another key trend we are witnessing is the outsourcing of animation content to Asia. This market is increasingly being tapped by North American film and television program producers. The major factor behind this shift of computer animation production to the Asia/Pacific region continues to be the availability of low cost, powerful computer animation platforms and much lower labour rates in the Asian and Pacific Rim countries compared to North America and Europe. The bulk of the outsourcing happens for 2D animation content with some amount of 3D content.
.I 48
.T
document.48
.W
How technology is driving the next wave of film animation
Film animation technology has come a long way since the early days of hand-drawn cartoons. The techniques used by animators to bring characters to life have improved dramatically over the years, and unlike traditional animation, which made its debut in 1906 and created the illusion of movement through frame-by-frame manipulation of drawings and illustrations, most animators today use computers to generate three-dimensional images.
Pixar, together with Disney, was the first company to create a feature-length computer-generated animation, with Toy Story in 1995. DreamWorks followed in 2001 with Shrek, which earned $484.4 million at the worldwide box office, and solidified computer animation as one of the most sophisticated and emotive forms of animation.
While computers have assisted animators in their efforts for decades, the advent of computer animation was a turning point in terms of the type of technology animation studios needed to use. Until then, all of their animation could be carried out on workstations (powerful desktop computers), but computer-generated (CG) images create such large amounts of data that animation companies now have to build their own data centres in order to handle it all.
These data centres contain hundreds of powerful servers, which provide vast amounts of processing power, enabling CG animation studios – big and small – to work with large, complex datasets and intricate 3D models. HP is one of the main providers of data centre infrastructure, alongside Dell and Cisco, and brought together some of its animation studio customers at the Cannes Film Festival to discuss the importance of technology to their businesses.
French-based Dwarf Labs, a fast-growing animation and visual effects studio, relies on a combination of workstations and data centre infrastructure from HP to do its rendering. Belisaire Earl, head of production engineering at Dwarf Labs, said that the company's latest short film, Lune et le Loup, consists of 4 minutes of animation, which equates to 7,500 frames. But each frame is 150-200 MB, so the four minutes represents about 1.5 TB of data.
These demands are big, but the data demands of major animation studios such as Pixar and DreamWorks are even bigger. Today, almost all films are shot at 24 frames per second, which equates to 130,000 frames over a 90-minute film. In computer animation, each frame has hundreds of assets, and every character has thousands of control points, so an entire film can consist of up to 500 million digital files.
As a result, some animation studios have had to start outsourcing some of their data processing to even larger online data centres. While animation companies may not do all of their rendering in this 'cloud', there are inevitably times of year when the demand for processing power exceeds the capacity in their own data centres – especially if they are working on several animated films at one time – so they will 'burst out' into the cloud for short periods.
“Yes we're storytellers, yes we love great characters, but under the hood, DreamWorks Animation is a digital manufacturer,” said Kate Swanborg, head of technology communications and strategic alliances at DreamWorks. “We are crafting 100 per cent digital goods for the consumer.”
A single DreamWorks film, like the soon-to-be-released How to Train Your Dragon 2, requires as many as 10,000 simultaneous computing cores, and 75 million computing hours, to render all the images. It also requires 250 TB of active disk space to store the film and deliver it to the servers and the artists. One movie is half a billion files, resulting in 250 billion pixels on screen.
n order to support this, DreamWorks has 20,000 computing cores in HP servers across three data centres around the world. Swanborg said that HP’s latest ‘Gen 8’ servers are 40 per cent faster than the previous generation, which means “40 per cent more pixels, 40 per cent sooner”. The company also has capacity in a fourth ‘cloud’ data centre, which is owned and controlled by HP.
“We are no longer living in a time in which you have to have all the compute resources you need under your own roof,” said Swanborg.
“We’re a creative enterprise and creativity is not linear – you have moments when things are working at the same time, and then you have moments when you’re rethinking and re-planning. If we had to build to the peak, we would have to nearly double our compute infrastructure to accommodate those moments, but we don’t have to do that, because we have HP Cloud, so when we have those moments of inspiration, we are not constrained by technology.”
HP said that technology not only has an important role in storing and processing data, but in analysing it. David Chalmers, chief technology officer at HP’s European Enterprise Group, said that film studios can benefit from using tools like HP Autonomy to conduct sentiment analysis, to gain insight into how viewers are responding to their films.
“It used to be you’d go to a screening and then fill in a little card. The film studios would take those little cards and try and work out whether they thought it was going to be a hit or not,” said Chalmers.
“Now we can use the Autonomy technology to build an analysis tool to look at social media output. What we’ve shown already is that in very early generations of that style of analytics, we are at least as good at predicting as the way they used to do it in the past.”
In the future, the amount of data generated during the creation, distribution and reception of animated films is only going to grow. Films will move from HD to Ultra-HD (4K) resolution, resulting in a multiplication of the amount of performance needed for rendering, and the amount of capacity needed for storage.
The spread of new animation techniques – like motion capture, which involves tracking the movement of objects and people to create more life-like characters – will also inevitably contribute to the data avalanche. Meanwhile, Lucasfilm has announced that the next generation of Star Wars films will use 48 frames a second rather than 24, signalling a new era for the film industry.
As these numbers increase, studios will depend more and more heavily on faster processors and cloud computing. The onus is therefore on companies like HP to continue supplying the industry with cutting-edge technology that will enable and drive the next wave of film animation.
.I 49
.T
document.49
.W
The Unofficial truth about the animation industry
It is almost that time of year, again,... when animation hopefuls will soon graduate from their various animation schools, and people are looking to apply for animation jobs, etc., etc.  Schooled in technique and process.  ... Yet! ...
... for these individuals, and others, there are still MANY questions about the "animation industry" that have gone...
... unanswered!!!


The Unofficial Truth about The Industry 
written by Joe Harkins  
(Originally posted 06/21/06, updated 09/13/10)
  Some of this will seem like information you’ve heard before, like common sense, like something someone should have sat down and told you. Maybe that’s the case, and maybe this is just affirmation of what you already know, but either way, I think you should read this.

   I realize that you might not be a full-time student, and you might be working in the industry. In fact, some of you I know from work, and you’re just here to brush up or learn a new skill. Your continued education is evidence of the dedication you have, and that’s such a great thing to have! I admire those who want more when they already have what they need.

   I believe that no matter what and where you choose to learn, be it at a public institute, a private school, or even in front of your computer at home, you should feel comfortable with your decision. You should feel like you're learning and that you've been given the tools you need to succeed in this extremely tough industry.

Do you need to go to college to get a job in this industry?
  --- No, but it doesn't hurt your chances to have a degree, and it won't be frowned upon if you don't.

Do employers require a degree to get a job?
--- Yes, some of the larger studios do require a degree for some of their more advanced TD, software engineering, and infrastructure related jobs.

What about non technical jobs, do those require a degree?
--- No. While some schools hold a certain amount of clout with many large studios and their degrees are in fact well respected, like Ringling or Cal Arts for example, artistic jobs do not require a degree.
(Blogger's note: "And of course Animation Mentor")

Do I need to be artistic?
--- Yes. Hands down it all comes down to your natural, raw, artistic talent, your eye for detail, your ability to take criticism for your own work, and your ability to critique others. 

What if I’m technical though, do I still need to be artistic?
--- At the end of the day, the answer is yes. While it’s acceptable to not have any artistic talent and be completely scientific in many of the job functions, if you truly want to excel in Computer Graphics, you need at least basic artistic abilities to get by. It will only make you a stronger technical candidate.

So should I go to college or not?
--- Are you talented enough to get a job without it? Are you completely sure about your artistic ability and what you want to do? Do you need more time to work on your portfolio? Do you have the discipline and determination to get a job with your current abilities? Keep asking yourself questions, and eventually you’ll figure it out.

What if I get a degree in something else?
--- That’s fine if you want to have something to “fall back” on, so to speak. Conservative people recommend this option to avoid pigeonholing yourself. I personally think that you should get a degree in whatever it is you want to do as a career. You can minor in something else, like business, while still majoring in art or computer science, for example. Either way, it’s not a bad thing, but it does raise a question as to how determined are you to make it in this industry if you’re already making a backup plan?

How do I know if I am getting what I need out of school or not?
--- “I feel lost…” I’ve heard that one a lot. I honestly want to tell you to consider doing something else with your life if you feel lost and are already taking classes for your major. If you’re just wondering whether or not you’re getting what you need from school, then you should probably ask yourself what it is you expect. You’re only going to get out of it what you put in.

Should I focus on art or science?
--- That’s for you to decide. Unless you’re absolutely sure you want a technical job that requires a degree, the B.A. vs B.S. is not worth arguing over. You need to pick something that fits your goals, but remember that it’s probably irrelevant later on anyways.

My school seems more interested in my money, is this normal?
--- Many schools are cashing in on students desire to learn. They are almost all the same as far as what you end up with on paper. As far as actual teaching quality, instructor experience, and overall reputation, that all depends on your school.

If you feel like your school is just seeking a profit, then your hunch is right, it is. The difference will be in the graduating students. Look at where grads are working, not so called “job placement” numbers that the school puts out. Just remember, it’s your responsibility to teach yourself and get a job, not anyone else, no matter how much money you spend on school or how much they promise to help after graduation.

What software should I learn?
--- First and foremost, forget about the software for a minute. If you are interested in the technical side of things, then you are going to need a strong background in math and science. You'll also need programming experience. 

If you're mainly an artist then you need to focus on traditional skills such as drawing, painting, and sculpting, among other things. Work on your 2D skills before trying your hand at 3D.

The software is only a tool.

To answer the question though, the software most commonly used for 3D in the industry is Maya and 3DSMax. PhotoShop is a standard application to know. For compositing you're best bet is to learn Nuke. For rendering, Renderman and Mental Ray have the strongest markets. Houdini and 3DSMax are popular with FX artists. Also, many larger studios have proprietary packages that are very unique to their pipeline. 

It can matter what software you learn, because they are complicated packages that require training and time to understand. The less experience you have with the most commonly used software, the less valuable you will be.

I am about to graduate, what should I do?
--- There are a few steps to preparing for graduation and entering this industry.



Look at job openings and preparing your resume
Put together an online portfolio and/or demo reel
Make contacts who can review your work
What should I have when I graduate?
--- The most important thing you need is a demo reel and online portfolio with your work on it. You need a resume, obviously. Almost everyone gets reviewed solely on their demo reel, so, you’re going to need that demo reel. If you don’t have that when you graduate then you essentially have nothing to get a job with!

I graduated, now what?
--- Now is when you flood the market. You are new, you are unknown, and you need a job. Flood is the key word here. Send out as many hard copy reels and e-mails as you can. Take time and make cover letters for each one, and make them specific to each company. Don’t write generic cover letters. Don’t overdo it either, simple and to the point. Cover letter, resume, and demo reel, 3 things, that’s it.

As far as demo reels go, here are my rules:
3 minutes or less, anything more is too long
Your best work goes first, never repeat anything
Don't focus on your soundtrack, it’s on mute, sorry.
Name, phone and email all over the place, don’t forget contact info.
What to put on it?
--- Only your best work. If you don’t think it’s great, no-one else will. 
You should really get as much feedback from people as you can before you cut your demo reel. You need to find out what your best work really is. It could be that one piece that is really great that gets you a job, but if you throw in five others that are terrible, forget it.

Tailor your reel to the job that you would like.
  --- If you’re a modeler, show models. If you want to animate, show animations. Don’t try to show more than one or two skills, even if you want to do everything. You cannot possibly be good at everything, and your weakest areas are going to shine through, not your strongest. Be aware that all of your work shown is being judged, not just what you say you want to do. Not fair? Then don’t put it on your reel!

How much is your demo reel worth?
--- Technically, it’s priceless. A foot in the door in this industry is tough to get, and you are up against many willing and talented people who want that opportunity as bad if not worse than you do. So, it’s priceless. If you spend one week hacking together a reel, it’s obvious. All the talent in the world won’t make up for rushed work, laziness, or procrastination. Be proactive, and don’t doubt for a second – there is competition.

So, how much money can you make?
  --- It depends on the market that you’re in. Let’s take LA for example. An entry level artist at a 3D job might work for anywhere between $18 and $22 an hour, depending on the company, the work required, and your negotiating skills. That could be a 3D tracker, modeler, character TD, animator, lighter, or even a compositor. At this point, it’s almost all the same; you’re looking at equal pay across the board for most entry level jobs.

What if I don’t get a job right away?
--- That’s normal! You’re going to have to keep trying, and be persistent. Keep applying, keep making phone calls, writing e-mails, and keep refining your reel. Cut a new version of your reel every week if you have to, just keep making it better and better until you get that first job. The first job is so important and so hard to get, you have to really want it.

How long does it take to hear back once you’ve applied?
--- Unless they’re interested, you won’t hear anything. If they are, usually a couple of weeks at most unless there’s an enormous amount of candidates or someone else fell through. Calling HR a week after is acceptable, but don’t call everyday.

It’s been a really long time, should I send in another reel? --- Call them first, ask them what the status is of the position. Ask if you can reapply. If they say yes, then go for it! If not, then don’t waste the postage.

I got an interview…so what do I say?
Just be yourself, take extra reels and resumes and be on time and prepared. Most importantly, be honest; don’t lie about what you can do. Don’t dress up, but at least look presentable. Be confident, they’re interested in you; try to sound interested in them.
.I 5
.T
document.5
.W
Science-fiction or science-fact? David Attenborough warns of confusing CGI in television documentaries

Computer-generated imagery in science and nature programmes is confusing viewers, David Attenborough has warned.
The veteran TV presenter admitted it has become a ‘big problem’ and suggested that broadcasters put captions to point out scenes that had been artificially reconstructed.
Sir David told the House of Lords Communications Committee his ‘misgivings’ over the use of the technology when watching controversial BBC1 biology programme Inside The Human Body.

He said: ‘If you wanted to confuse the audience, you have got more convincing ways of confusing them than ever in history.’
He added that there are ‘well known examples’ of programme-makers ‘overstepping the mark’ and giving viewers false impressions created by computer.

Computer generated tactics are used routinely in science and nature shows - but the viewer is given little guidance about the nature of the image.
One member of the committee suggested a warning dot on shows every time the practice was being used.

Sir David said problems came when people and start recreating things which they ‘think’ happened rather than know.
The natural history presenter suggested a solution, saying: ‘One of the ways to do it is, by putting on, either at the beginning or the end, a caption which says "some of the scenes and sequences that follow are computer generated", or something of that sort.’
Sir David, referring to Inside The Human Body, which showed a man’s moment of  death, but also computer generated images of disease, said: ‘I thought I don’t know, I don’t know where we are on that.‘
But he claimed it was ‘not an easy problem to solve’ as the technology could be very helpful to illustrate information.
He added: ‘The problem comes when you overstep the mark and you think you know  and you have actually put on something that is false and there are actually well-known examples of that happening. 
'The problem is much greater than it has ever been before.’ 
He pointed to an example where the body of a rare fish was photographed but  then by aid of computers you could ‘waggle’ its fins. He said the image was both ‘false’ and ‘true’ in some ways.
But he added that red dots flashing up every time the practice was used would be confusing.
.I 50
.T
document.50
.W
Visual Effects
In filmmaking, visual effects (abbreviated VFX) are the processes by which imagery is created and/or manipulated outside the context of a live action shot.

Visual effects involve the integration of live-action footage and generated imagery to create environments which look realistic, but would be dangerous, expensive, impractical, or simply impossible to capture on film. Visual effects using computer generated imagery have recently become accessible to the independent filmmaker with the introduction of affordable and easy-to-use animation and compositing software.

Timing
Visual effects are often integral to a movie's story and appeal. Although most visual effects work is completed during post-production, it usually must be carefully planned and choreographed in pre-production and production. Visual effects primarily executed in Post-Production with the use of multiple tools and technologies such as graphic design, modeling, animation and similar software, while special effects such as explosions and car chases are made on set. A visual effects supervisor is usually involved with the production from an early stage to work closely with production and the film's director design, guide and lead the teams required to achieve the desired effects.

Categories
Visual effects may be divided into at least four categories:

Matte paintings and stills: digital or traditional paintings or photographs which serve as background plates for keyed or rotoscoped elements.
Live-action effects: keying actors or models through bluescreening and greenscreening.
Digital animation: modeling, computer graphics lighting, texturing, rigging, animating, and rendering computer-generated 3D characters, particle effects, digital sets, backgrounds.
Digital effects (commonly shortened to digital FX or FX) are the various processes by which imagery is created and/or manipulated with or from photographic assets. Digital effects often involve the integration of still photography and computer-generated imagery (CGI) in order to create environments which look realistic, but would be dangerous, costly, or simply impossible to capture in camera. FX is usually associated with the still photography world in contrast to visual effects which is associated with motion film production.

Types
VFX can be categorized into:

Simulation FX
Matte painting
Compositing
.I 51
.T
document.51
.W
Working as a visual effects artist
• The job: Visual-effects artist

The nature of the work: Visual-effects artists and supervisors create special effects, animation and do visual clean-up for feature films and commercials. One day, you may be supervising a shot of film extras so they can be digitally duplicated into a scene. Other days are spent in front of a computer, creating an entire alternate universe—like that used in "Avatar."
• The pay: Earnings vary, depending on whether you are employed by a company, a studio or as a free-lancer. Typically, short-term commercial jobs pay more, but television-show and film jobs provide more job security. Junior visual-effects supervisors earn an average of $2,500 a week, according to Jeffrey A. Okun, chairman of the Visual Effects Society; top-of-the-line supervisors can command tens of thousands of dollars a week.

• The hours: Workdays are usually at least 10 hours long. Deadlines are high-pressure and rarely flexible. Many artists say they work through the night to deliver a project on time. Visual-effects artists bemoan that there is no union representation to regulate hours and working conditions.

• The benefits: Artists and supervisors employed by post-production companies are usually on the payroll and receive health care and retirement benefits. Free-lancers can receive insurance via the Visual Effects Society, an industry association.

• Other incentives: Because of the late-night work required, meals are often billed to clients. Travel is also a regular part of the job. And in some cases, artists can see movies before they are released to the public.

• Best part of the job: Working alongside on-set industry luminaries, as well as the occasional actor, is exciting, says Eric Alba, a free-lance visual-effect artist who has worked on science fiction TV shows, including "Star Trek: The Next Generation." "On the best days, I get to blow up cars on set," Mr. Alba says. For those interested in office aesthetics, post-production houses also often have snazzy offices complete with videogame consoles, and desks laden with action figures, Mr. Alba says.

Worst part of the job: Dealing with clients can be arduous, particularly for advertising customers who only have a conceptual idea of what they want, says Chris Wells, a visual-effects supervisor with Hydraulx, a firm in Santa Monica, Calif. "You have to dig into a client and ask a lot of abstract questions to really get the palette and the mood they want," Mr. Wells says. "There can be a lot of trial and error." Willingness to relocate is crucial, as the lion's share of jobs are available in just a handful of cities such as Los Angeles, New York, Chicago, Vancouver, British Columbia, and San Francisco. The long hours also can wreak havoc on personal relationships, Mr. Alba says. "I've called this job the widow-maker."
• Education/Qualifications: Animation and visual-effects programs are offered at a number of universities, but a degree or certificate isn't required. More important is an eye for artistic detail, such as light, shadow and texture, says Mark Tobin, managing director of The Moving Picture Co.'s Los Angeles office. "You can teach the technical knowledge, but you can't teach a great eye," Mr. Tobin says. "The key is getting your foot in the door."

Newcomers usually enter the industry through internships and apprenticeships—sometimes unpaid. Expertise in software such as Autodesk Maya and Adobe Photoshop helps. A strong reel (a short video showing clips) is critical. Since it's a tight-knit industry, networking is also key.

• Hiring: Employment in the industry is cyclical and tied to film studio budgets and appetites for films with extensive special effects. According to the Bureau of Labor Statistics, employment for artists and related workers is expected to increase 12% through 2018—on pace with other occupations.
.I 52
.T
document.52
.W
How to Become a Visual Effects Artist: Career Path Guide
A great way to become a Visual Effects Artist is to get a head start by landing an internship with a visual effects studio while you are still a student. Speak with your instructors and your school’s career services office in order to get assistance with identifying and applying for such opportunities.
 
School’s that offer programs related to a career as a visual effects artist have a vested interest in maintaining high rates of graduate employment, so they will likely prepare you for employment by ensuring you have created a portfolio and possibly a website in order to showcase your work.
 
You may or may not be left to your own devices to find employment, but if you have a good portfolio it shouldn’t be too difficult to edge out the competition. Contact visual effects studios and inquire about any employment opportunities they may have available. Make note of who you spoke with and when, as you will want to follow up with everyone you spoke to within a few weeks.
 
One way to increase your chances of landing a job as a visual effects artist, whether permanent or freelance, is to network with like-minded individuals and industry professionals. You may also want to consider joining relevant organizations, such as the Visual Effects Society, as they often have employment listings.
 Education and Training Requirements to Become a Visual Effects Artist
The education and training requirements to become a visual effects artist can vary, depending on the employer or client, and there is certainly no set path to take. Generally, the more education and training an aspiring visual effects artist has, the greater their potential to obtain employment or a client base will be.
 
Education and Training Requirements may include:
 
• A Bachelor’s degree in Computer Science, Animation or Art (including Fine Arts and Visual Arts)
• Additional technical area of study or interest (such as Physics, Mathematics or Engineering)
• Relevant job experience
• Expertise in software such as Autodesk Maya and Adobe Photoshop
• A strong reel (a short video showing clips) or portfolio
Current knowledge of 2D and 3D computer graphics techniques, as they are used in the feature film and media production industries
Visual Effects Artist Job Description
Visual effects artists are multimedia artists that are responsible for much of the post-production work in the television and film industry. The visual effects artist ensures that all visual effects are woven together seamlessly. Visual effects artists are continuing to become more specialized as the film and television industries embrace the newest in technology.
 
 
Visual Effects Artist Job Duties
• Must ensure that visual effects added in post production are added careful, as to not let viewers know that this was done
• Adjust lighting, colour and placement of visual effects to ensure they are identical to the scene in which they are placed
• May be responsible for creating graphics that incorporate motion to accentuate brand names, advertising or other significant messages
• May design the motion aspect of the motion graphics
• Use editing, illustration and animation software
 
 
Where do Visual Effects Artists Work?
Visual effects artists typically work in one of three settings; a company that specializes in visual effects, a post-production studio, or they work as a freelancer. Each form of employment has its advantages as well as its disadvantages.
 
Working for a VFX company - Pros and cons
 
• Job security is typically the highest in these settings, as well as health and retirement benefits
• Little control over the projects that are worked on
 
Working for a post-production studio – Pros and cons
 
• Rate of pay and job security are typically lower than working directly for a visual effects company
 
Working as a freelancer - Pros and cons
 
• Freedom to select projects and set rate of pay
• Job security is typically the lowest in this form of employment
• Marketing skills are necessary to find work, although many freelance artists rely on referrals to obtain business once they are established in their industry
 
Please Note: Jobs for visual effects artists in North America are primarily found in but a handful of cities: New York, Chicago, Los Angeles, Vancouver, Toronto and San Francisco.

Visual Effects Artist Career - Work Environment
Working Hours: Typically around 10 hours long in order to meet rigid deadlines. Many visual effects artists will work through the night more than a handful of times during their careers in order to meet deadlines.
 
Work Setting: Due to the extremely specialized nature of the hardware being utilized by visual effects artists, it is by nature an office-based job. It may not be your typical office however, as many post-production houses have offices with videogame consoles and desks covered in action figures.  Senior level visual effects artists operate largely outside of the office, as they must be on set with the director while working on films in order to coordinate how the film is shot for scenes which require visual effects.
Is Becoming a Visual Effects Artist Right for You?
Long days and sometimes nights, staring at computer screens, winning Oscars…this career may not be for everyone. Below is a list of positive and negative attributes pertaining to a career as a visual effects artist that everyone who’s serious about getting into this field should consider:
 
• Depending on the project you’re working on, if you do an outstanding job you can be nominated for a little thing called an Oscar…no big deal.
 
• Working long hours and weekends are quite common when nearing a deadline. This can have a detrimental effect on personal relationships.
 
• Being creative isn’t just a great skill to bring to the table; it’s a requirement.
 
• Using problem solving skills and creativity to solve artistic problems can be highly satisfying.
 
• Visual effects artists may have the chance to see movies before they are released to the general public.
 
• Dealing with clients can be stressful when they only have a conceptual idea of what they want created.
 
• Patience is required when beginning a project, as there will be a lot of trial and error.
 
• Work for visual effects artists is mainly found in Los Angeles, San Francisco, Vancouver, Toronto, Chicago and New York, so an aspiring artist must be willing to relocate.
 
• Visual effects artists need a solid aesthetic sense as well as a finely tuned creative eye that can recognize, direct and execute well-integrates visual effects.
.I 53
.T
document.53
.W
My job explained: visual effects artist
Dave Lieberman reveals the solid skills you need to conjure up illusions on the silver screen.

Can you tell us a bit about your job?
I work as a 2D visual effects artist at Prime Focus Film London. Specifically my role is that of a compositor but in this job I primarily work as a stereo conversion artist. This involves converting films which were shot with one camera (2D) into stereoscopic films (with 3D glasses) in post production. 

Can you describe a typical working day?
A typical working day can start around 9.30-10am and end any time between 6.30pm and as late as 4am sometimes.  Film work is organized but can be unpredictable due to faults, issues, clients changing their minds.

Why did you choose to go into visual effects?
I always had a love for the moving image and used to mess around on Photoshop with digital photos as early as 14. It’s only later on that I realized there is a role (compositing) which comprises of both technical and artistic elements which suits my style and abilities.

The visual effects industry is also extremely laid back. You are not judged by how you are dressed and what you’re into - you are simply judged on your ability to finish a shot in time and well. Bosses speak to you on a level and although you sometimes have to work very long hours you work hard and play hard.

What qualifications do you have?
I did a two year HND in Multimedia. This gave me the option to complete a BA in the third year but by then I knew I want to get into a more specific animation role so I joined a Digital Animation BA and was allowed to jump straight onto the second year due to the fact I had my HND. I didn’t find the degree teaching to be industry standard and was left doing a completely unrelated job for a year after I graduated. After a year of being slightly disillusioned I joined Escape Studios to do a three month intensive programme in Digital Compositing. There is no qualification but qualifications aren’t particularly important in our industry - if you’re 18 and can do the job better than a 30 year old with a BA and Masters you will most likely get the job instead of him. Escape Studios was expensive but gave me the latest industry standard teachings from highly experienced artists who have worked in all the biggest visual effects houses. They also sent me straight to work literally a day after completing the course as they are affiliated with all the large post houses in the UK and abroad.

What other skills do you need?
Language, communication and managerial skills help if you want to move up the ladder quickly and eventually supervise.

What’s the best bit of your job?
The laid back atmosphere at work.

What’s the most challenging bit of your job?
Keeping up with new technology and the competition. Young people are joining the industry in an alarming rate and its becoming easier and easier to learn the material at home rather than study or move up the ranks at work. There are now online schools, free tutorials, and software is easily attainable.

Was it hard to get your first job?
My first long term contract was very hard to get and I was lucky. Most people in visual effects freelance from project to project so I am extremely lucky to be in a permanent position with a staff contract at Prime Focus.

What advice would you have for people who want to follow in your footsteps?
The best advice for someone who is already familiar with the VFX world or even just have basic skills with Photoshop would be to join a professional school or studio to learn the material. I don’t believe many universities have the adequate technology and staff to be teaching you industry standard visual effects. This industry moves, changes and develops extremely quickly and universities just can’t keep up. Gnomon in America is great and Escape Studios in London is excellent but there are many other private studios, just do your research and always check with people who have experience on forums such as VFXTALK.

Your other option is to join any large studio in Soho such as Prime Focus, The Mill, MPC, Dneg, or Framestore as a runner. Many of the top artists in Soho today started off as runners and being a runner allows you to understand the workings of the company from the bottom up. If you are a good communicator and a fun person you will make friends in no time, and certain artists and supervisors will let you do some free work after your shift. Do that for a few months and you’ll see that first low pay offer come in. From that point onwards you will just get more work, more pay, and more experience. 
.I 54
.T
document.54
.W
My Job explained: Animator
Watching cartoons as a child opened Rob Cureton’s eyes to his dream job. Read on to find out more.

Can you tell us a bit about your job?
I primarily work as a freelance animator in the corporate sector. This involves animating video for internal communications, presentations, conference openers, stuff like that. Sometimes we will be spending weeks on a full character animation piece whereas other times we will be creating simple motion graphics around video footage.

Can you describe a typical working day?
The work day does vary from job to job. Generally though, the team will get together and go over our jobs for the day, go through any feedback from clients and share the workload out. The majority of the day is then spent in After Effects, Final Cut or Photoshop working through. I'll usually show my work to my boss throughout the day to make sure it's going in the right direction. Nothing worse than spending three hours on something and then finding out it's all wrong! At the end of the day, we'll render, edit, export and compress our day's work to send back to the clients for feedback.

Why did you choose to go into animation?
I've always loved animation as a medium. I've been drawing my whole life and I remember as a child watching cartoons and trying to work out how the layers were set up in Tom and Jerry. I fell in love with Wallace and Gromit in my early teens and so when it came to applying for university and I realised animation was a thing you could actually learn, I signed up to be the next Nick Park. Unfortunately, I was rubbish at stop-motion but instead found a fondness for traditional and cut-out animation.

What qualifications do you have?
I studied a BA in Animation at university. While a degree helps, it means nothing if you don't have a strong portfolio to back it up. Someone with no degree but lots of examples of animation and design is far more likely to get work than someone with a degree and nothing to back it up with.

What other skills do you need?
Patience! Animation is a very slow, tedious process and it's often weeks or months until you start to see your hard work paying off. You also need to be able to accept criticism. It often turns out that how you imagined a piece of animation working is not the same as how your client imagines it. You can get frustrated by this but once you learn not to be precious about your work, it becomes a lot easier.

What’s the best bit of your job?
Seeing a character I've spent weeks designing, rigging and animating come to life on screen. The problem with animation is that you never know that something is going to work until you've actually done it. There's no better feeling than playing something back after three hours of animating blind and seeing you have nailed it! It might take three or four attempts to get to this stage but it still feels amazing.

What’s the most challenging bit of your job?
Planning! Before you even START designing a character you need to be absolutely sure of everything they need to do. It's not uncommon for me to have dozens of sheets of paper on my desk with various lists of hand shapes, mouth shapes, props, backgrounds, rigging notes and diagrams that I need to work through before we can begin animating. Animation is a series of problems that need solving and figuring out what those problems might be before you find them is half of my job.

Was it hard to get your first job?
I got incredibly lucky with my first job. I had finished uni and, like many people in that position, was back at home with my parents not entirely sure what comes next. I took on a couple of tiny little jobs through friends but nothing worth talking about. After six months of this, I got a message out of the blue from a studio in London saying that a friend who had been working for them was heading off travelling and that he'd passed on my details as someone who could fill in for him while he was gone. I did a couple of jobs with them over a few months, staying with family before they offered me a long-term contract and I moved down to London permanently.

What advice would you have for people who want to follow in your footsteps?
Persevere. It's tough going but you will get there. If you're struggling to get work, start a self-initiated project and keep your skills up. No point in finally landing a job and realising you've forgotten how to do it. Go to networking events. Go to festivals. Talk to all the right people. Buy them a drink. If they offer you a drink, accept it and sit and chat with them for a while. It's amazing how often I've done this and it actually is remembered. Most importantly, enjoy it.
.I 55
.T
document.55
.W
The Scope of animation in different professional fields
Animation refers to the use of graphics in different types of professional fields. These computer graphics are mainly used in different sectors whether it is aviation, information technology, medical, hospitality, banking or insurance. These graphics are mainly employed for the presentation of ideas or concepts. Marketers deploy these moving pictures for the purpose of advertising their products or services. This is also used for the purpose of brand promotion of the product or service of the organization.

There are many uses of the animation in today's modern world. It is used for e-commerce in advertising the products and services of the organization. A marketer can incorporate the multimedia content in the web pages of a company site. This embellishes the website of an organization. There are a number of web visitors who get attracted towards the site. A web visitor gets attracted towards the site of the company. These images help a marketer in highlighting the benefits of using the product of the organization. You can elucidate the unique features of the product or service of the enterprise. As a result of which you can encourage the customer to purchase the product. Aviation sector can encourage e-ticketing among its customers. For alluring the customers, a marketer, belonging to the aviation sector, can use animated images for integrating the web pages. The graphics are used for journalism or audio-film production while preparing video clips or films. The advertisement or public relations agencies and content writing often require the animated pictures for the purpose of embellishing projects, presentations or articles. A person in public relations may require these images to present graphs, charts or columns in the annual or financial reports. It is widely used in the film and entertainment industry. In the film industry, the animated films are created where cartoon character are created instead of film actors. Film producers can achieve desirable expressions from these cartoon characters with ease.

As animation has entered into different types of professional fields, many new institutes have also emerged where young aspirants are trained to explore prospects for themselves in this field. The use of graphics has enhanced the presentation style of various professional fields.



Article Source: http://EzineArticles.com/3972658
.I 56
.T
document.56
.W
About 3D Animation
Computer animation, where there is 3 dimensional anime, it is possibly the most used form of animation technique brought into usage especially by the media fraternity. Ever since the introduction of it in the market, it has been able to change the face of movies, television, video games, internet and other methods of entertainment. Its capability to create amazing 3D animation was at a certain point in time restricted to costly and high-powered work stations however with advancement seen in the field of technology the cost of using the technique downsized by a good level. This made it easily accessible for various people to utilize this in their work.

Although high end systems tend to remain as the ones that are brought into usage so as to create the most professional looking images but with quality animation creation technology this is possible to create work even on home computers. Given that you have no knowledge and experience relating this form of animation then you could think of assuming it as a hybrid of a classic technique and live action movie. The basic principles applicable when creating something cannot be overlooked and are still applied. The best of the animators start working as cel or stop-motion animators in the industry.

The traditional methods to infuse expressions and liveliness into characters allow professionals to work in a far superior way so as to come up with something that is eye popping and striking. Knowledge of film production is as well one key factor that helps in the creation of high quality 3 dimensional work. Like you have seen how a director gets the setup of camera, lights and actor placed, so similarly you as an animator would need to get your stuff.

Just because there is the help of computer available, thinking that the technique is easy and fast to create 3D computer animation is not right. Although there is no denying that the machine does most of the work, draws frames needed for a final creation but the overall procedure is multifaceted and it does take time for an individual to get used to utilizing it. Just like any other artistic and articulate work, in this too there is a need to keep a lot of patience. There are software products that you can get easily by spending a tiny amount as they would help you create realistic and stunning imagery, encapsulating your own world of dreams that everyone else would be able to see.
.I 57
.T
document.57
.W
Animation is all about being creative
To define the term 'Animation', it could be said that it is an illusion of motion that is developed by displaying a chronological display of various images in real speed. Pictures could either be displayed via 2D technique or even three dimensional. The optical illusion which is one vital aspect relating animation creation is a result of a phenomenon that is better recognized as 'persistence of vision'. This remains as one most general form of creating characters with animated effect. There are various techniques that are used to come up with those creations. Some like to stick with the old traditional forms whilst a few do not mind going the modern way.

Traditional- During the 20th century, this technique was extensively used in film making. The initial step that is taken up here is of drawing of various sequences of characters. Then they are Xeroxed on acetate sheets. Sides of the sheets opposite to the line drawings need to be filled with the specific hues to be used. Post this; photographs of them are taken on motion pictures via the help of rostrum camera.

Computerized- There are two categories under this classification which are 2D and 3D and vector graphics are used with various techniques like tweening, interpolated, morphing, rotoscoping and onion skinning. Rigging is a method that is used in three dimensional category and it is the digital models that are made for this type of process. Animator can easily manipulate the looks of the characters via various features.

Stop motion- The technique makes use of the similar phenomenon of optical illusion to develop its creations. But the real world objects are physically manipulated and photographed with a frame at a time.

Skilled pupils like creating something new at all times. If you visit any of the websites of a multimedia school, you'd be able to see in the animation gallery the creations made by the students. In 2D, they use CorelDraw, Photoshop, Flash, Adobe Illustrator software, etc. For 3D, programs such as Maya or Max are brought into usage.
.I 58
.T
document.58
.W
Animated or cartoon characters could help you make a successful career
Superman, Batman, and many other super heroes, Tom & Jerry and the famous Popeye! Do you wonder where all they come from or how they were created? Ever imagined what purpose they are meant to serve? Probably they all are a part of intelligent and creative thinking of people and have been able to amuse all from the time they were introduced to the world. A cartoonist in the year 1971 created Chacha Chaudhary which was later adapted into a television version and it became a favorite of almost all. Most of the cartoon characters have comics' editions too but definitely people love to watch the animated version or moving clips of such characters in action. The appeal of animation or cartoons is not limited to kids but adults too like watching them. Ask any person who would not have any idea about Tom & Jerry series. If only comics were produced on the same, probably the attraction to read or know about them would have been meager. It is animation or the moving concept, added with audio content is what has been able to lend a shine and edge to such cartoon clips of Tom & Jerry series.

There is art involved in every way when it is about creating a full-fledged character. If you desire pursuing a career in the animation industry it becomes vital to undergo a well-designed training program for which also a reputed training center is important. With time the technique has gained popularity and subsequently more number of students desire making a career in the sector. There are many animation institutes which offer the best of the trainings that one can get. They have highly planned programs for students and classrooms equipped with the needed facilities to be given to the pupils. It is very important when you opt to get admission in any of these institutes if they as well would offer placements with reputed names and firms in the industry or not. A lot of institutes as well offer in-house or practical trainings so that students get a needed level of exposure.
.I 59
.T
document.59
.W
Courses for a career in animation industry
Entertainment industry is the one that has been using the art of animation and professional animators are much in demand. Animation is one of the creative ways of communication. This method is well utilized not only by film makers but also businesspeople. They use it for marketing any product. The technology has been developing at a rapid pace, and now, two as well as three-dimensional graphics are used to give an image a strikingly visual appearance. There are numerous animation programs and tools that help animator professionals to create animated characters.

When any alumni begins with a computer animation course, the sessions start with Macromedia Flash, basically used to create cartoons and Web pages. 3D Studio Max is used to create videos and for the advanced level model creations, students are taught about using a program 'Maya' as this helps in creating amazing moving images. There are courses available in many reputed animation training institutes which vary depending upon the duration, cost, and other factors.

B.Sc. in Multimedia and Animation: You can opt to complete a Bachelor's degree in multimedia and animation, which is for a term of three years. A standard curriculum for the same comprises the initial year with sessions where you'd be introduced to the basic 2D animation and flash.

Specialist Program in Animation: This is one of a kind curriculum meant for those who are career oriented. Some of the academies might offer a course such as this one. With five semesters, this course might stretch up to 31 months. There is no specific educational requirement to pursue it. With +2 qualification or students with any educational background are eligible for the course. This comprises sessions on sketching, graphics, illustration, 2D animation, portfolio, video content, and 3D animation. All these are divided into phases and as you do advance with the courses, so does the content.

Course in Graphics and Web Designing: You could be a graphics and web designing professional after completing a year's animation program. Under this sessions on Adobe PhotoShop or CorelDraw are included. Also, classes on the usage of Flash, Javascript, DreamWeaver, etc are conducted. Other short term courses also help you make a career in this sector.
.I 6
.T
document.6
.W
The Role of Computer Generated Imagery in the Film Industry 

Computer Generated Imagery is the special effects used in motion pictures to create a visual depiction of an illusion that can not be easily created in real life. Directors of major motion pictures have been using these technologies since the early days of the personal computer. Early on, when and special effects were in their beginning stages, it was difficult to make efficient and effective effects that are well accepted by the movie critics and the general public. An evolution of special effects and the introduction of computerized animation brought the standards for movie effects to a higher level. The development of new methods of Computer Generated Imagery for less money and more effective than in the past has allowed even fairly low budget movies to incorporate such technology. Today, movies use CGI to create special effects to replace thousands of extras, stunt people, and puppet like characters, as witnessed in the Lord of the Rings Trilogy. The evolution of special effects and Computer Generated Imagery technologies has taken the film industry to a whole new level. 

Computer Generated Imagery began with awkward and dull effects in the early 1980’s. The 1982 film “Tron” was a desperate attempt from Disney to jump on the CGI bandwagon and start a revolution in film making technologies (imdb.com). Although this film showed an attempt at something that had never been done before in the history of cinematics, it was weird and confusing. This broke the door down for other companies to start up and aid films in creating better and better effects that appealed to a larger market. Although the effects were not good in the early days, the general film going public was astonished by computer generated effects and flocked to the theaters to see these cheesy attempts to use basic technology that did not transfer well to the silver screen. It was not until later films like “Jurassic Park,” “Toy Story,” and “The Lord of the Rings” until CGI became a film making powerhouse and the killer application for high budget movies. 

The evolution of the 1980’s saw the pioneers of the early ages of CGI, but it was not until major revolutions in computer aided film making when the industry took a notice. Steven Spielberg’s 1993 film “Jurassic Park,” one of the first major motion pictures to use CGI on a large scale, is one of the largest grossing movies of all time (imdb.com). It brought CGI in film making to a whole new level. After this movie, CGI became common in high budget, high grossing movies. It clearly showed that people will flock to well done CGI films, in astonishing numbers. This film clearly opened the doors for films like Disney / Pixar’s 1995 film “Toy Story,” the very first feature length CGI motion picture (imdb.com). What would “The History of Computer Generated Imagery” be without “Toy Story?” This movie was the challenge of Disney that a full length CGI could be done, and well. The success of “Toy Story” again paved the path for more common use of CGI. Now that film makers have seen proof that there is no such thing as too much CGI, they are free to carry out their most wild and adventurous imaginations. 

Peter Jackson’s The “Lord of the Rings” trilogy takes cinematography to a whole new level with CGI technology. This series of film has perhaps peaked as CGI’s greatest accomplishment to this day. Nearly every frame of every film is dubbed, masked, or altered in some way to improve the effects of a real life Middle Earth. Nearly every CGI technique in the book was used to pull off this wonderful masterpiece of film. From the digitally background to the Massive produced Orcs, this movie spent attention to detail to provide a superb quality of CGI never before witnessed. Each frame of background was digitally enhanced to bring up the lighting, color, and general effect. This was the first film to use wide spread digital background enhancements. It was very effective in enhancing the cinematography of New Zealand’s countryside. Massive is a computer program that can simultaneously control thousands of CGI characters. In LOTR, Massive was used to control the Orcs in the major fight scene. It too was an effective way of creating the deception of reality. Someday, CGI will replace stunt doubles, extras, and puppet like characters completely. Through the success of such films as LOTR, this day will come soon (Watrall, T101, 2/16). 

CGI has greatly improved from the early days of computerized film making. The evolution of CGI and new technologies has shown a great return on investment in most cases and a general increase in the visual quality of film. The ultimate goal of CGI films is to have the deception of real life. Hopefully for film directors, they will be making a lot of money along the way. 
.I 60
.T
document.60
.W
The different types of animation
When it comes to jobs that require a combination of skill, boundless creativity, and passion, few can compare to animation.

Animators are the ones who bring ideas to life so that others may enjoy stories and characters not possible in real life.

Animation has been around for a while now and many new types of techniques have been introduced, which means animation studios and companies all over the world are looking for talented individuals who have what it takes to master them.

Below you’ll find information on the two main types of animation techniques as well as a few less relevant methods.

Whether you end up making digital 2D animations for movies and TV shows or environments for games, we hope this helps guide you down the animation path that’s perfect for you.

2D Animation Styles
What is 2D Animation?
2D animation is when scenes and characters are animated in a 2D space instead of a 3D environment.

Today, artists use computer software to create everything in a 2D animation, including environments, characters, visual effects, and more.

For most of the 20th century, animation was done by taking photographs of drawings on paper and then placing them on transparent acetate sheets called cels.

This process was abandoned with the introducing of computers, which allows artists to create digital animations and then use techniques to manipulate the image. Compared to drawing multiple images, using computers is far less time-consuming and effective.

Although drawing skills are still required to be a 2D animator today, most of the work is done with the use of computer software.

These programs often have a huge toolbox of features that help the artists manipulate the animation in a number of ways, including making it look smoother by fine-tuning important elements such as timing.

Other advantages of 2D animation over the traditional way include being able to save and load work. Being able to do so proves very handy if something didn’t work and you need to revert back to an earlier version of the animation.

Being skilled in a particular 2D animation program also allows you to make good use of a vast library of visual effects.

Of course, every 2D animation software comes with its own learning curves, which only get steeper the better the program is.

Knowing what each tool does and how to use it effectively is essential if you want to be a good 2D animator that isn’t limited to a few techniques.

Notable 2D Animation Programs

Toon Boom Studio
Autodesk’s SketchBook Pro
Anime Studio Debut
DrawPlus
FlipBook Lite
Adobe Photoshop
The TAB Pro
CrazyTalk Animator
MotionArtist
Flip Boom Cartoon
Where is 2D animation used?
2D animation is widely used in a number of creative industries and is still widely used despite the rise of 3D animation.

Everything from cartoon series and Japanese anime to video games and full feature films are done in 2D. The fact that 2D animation is flexible enough to be done on a wide range of platforms it what makes it such a popular form for anything from entertainment and multimedia to broadcast video.

Television is where 2D animation is still used the most.

The number of shows that have been made with 2D animation is near-endless, with some of the more well-known ones being The Simpsons, SpongeBob Squarepants, South Park, and Avatar: The Last Airbender.

Anime, a style of Japanese animation inspired by their manga comics, also makes use of 2D animation.

Some of the biggest anime hits are:

Dragonball Z
Naruto
One Piece
Attack On Titan
Plenty of influential and critically-acclaimed films have also used 2D animation, including The Lion King, Snow White and the Seven Dwarves, and The Iron Giant. Disney has always been at the top when it comes to companies that produce well-received animated feature films.

Another notable company is Studio Ghibli, a Japanese film studio who has produced classics like:

Spirited Away
Kiki’s Delivery Service
Castle in the Sky
2D animation was also once the dominant art form for most of video game’s history. Beloved titles like Super Mario Bros, Mega Man, Super Metroid, and The Legend of Zelda all employ 2D visuals.

Despite 3D being the most popular style for games, indie developers are making 2D games popular again with hit titles like Shovel Knight, Braid, Limbo, and more.

Typical 2D Animation Career Path
While some companies are more than willing to hire you if they see that you have a talent for 2D animation, most are only looking for artists with college degrees.

This is because someone who went through a two or four-year program in animation, computer graphics, or other related field usually has knowledge of the programs they’ll be expected to use.

Animation college graduates also normally have a portfolio to showcase their technical and artistic skills to the places they apply to.

So if you’re an aspiring 2D animator, it is possible to break into any industry by learning software programs yourself and refining your skills.

However, your path will likely involve some kind of college or university program if you want the best chance of getting hired at a company that does 2D animation.

These can include game developers, animated film studios, television companies, and most other multimedia fields.

3D Animation Styles
3D animation is the manipulation of three dimensional objects and virtual environments with the use of a computer program.

Animators first create a 3D polygon mesh with various connected vertices to give it form.
The mesh is then rigged by giving it an armature, a skeletal structure that can be manipulated to make the object appear in specific poses.
After making other objects and environments, the artist then uses the software to create scenes that are much more lifelike than 2D animation.
This form, which is also called computer-generated imagery (CGI), is a fairly recent technique that only came into use during the 1990s.

Before that, the closest thing to 3D animation was stop-motion and Claymation, which involved using real-life objects and taking pictures to give the illusion of motion. Now it is arguably the most popular form of animation and is used in anything from TV shows, video games, and feature films.

A computer and 3D software program is required to create 3D animations, which usually comes with a ton of features that let you do anything from modeling and simulation to rendering.

Tools for adding lighting, visual effects, physics, and other elements are also normally included.

The reason 3D animation has become popular is because it can be used to create realistic objects and scenes.

Live-action films like Transformers, Avatar, and The Avengers would not be as impressive if you removed all the 3D elements, which often include entire characters and settings. 3D has also become the standard visual style for video games because it lets players do much more than a 2D game.

But like other forms of animation, 3D has its own learning curve that involves gaining a firm understanding of 3D software programs.

These programs also tend to be pretty expensive, which means they can be hard to learn as a student who doesn’t have a few hundred bucks to spend on one.

Notable 3D Animation Programs

Autodesk Maya
Autodesk 3ds Max
Unity
CINEMA 4D
Houdini
Autodesk Softimage
LightWave
Modo
TurboCAD Deluxe
SketchUp Pro
Where is 3D animation used?
Today, 3D animation is used in more industries than ever before.

Common examples include:

games
movies
television shows
interior designing
business
architecture
medicine
many other multimedia fields
Without 3D animation, beloved movies like Toy Story, Frozen, How To Train Your Dragon, and Big Hero 6 would not have been possible.

When it comes to games, 3D animation is everywhere.

Some of today’s most successful titles are in 3D, including Super Mario 3D World, Bloodborne, Halo, Call of Duty, and many more.

Television has also finally started seeing a number of well-received 3D shows such as Star Wars Rebels, Kung Fu Panda: Legends of Awesomeness, and the latest Teenage Mutant Ninja Turtles series.

Typical 3D Animation Career Path
Just like with 2D animation, most places will want to see a bachelor’s degree in a related field. This is because 3D animation is a very technical specialty that requires a solid understanding of different programs and how to use them effectively.

Since studios that make 3D games and movies are demanding, fast-paced environments, they want to hire people who have already mastered the 3D software programs they use for their projects.

That is why a self-taught 3D animator isn’t as likely to get hired as someone who went through an animation program at a college or university.

We’re not saying it’s impossible to get a job by teaching yourself how to animate in 3D, but the average company has more confidence hiring someone who can prove they’ve spent a number of years learning how to be a 3D animator and receiving instruction from trained professionals.

.I 61
.T
document.61
.W
Does computer animation apply to other fields of study
When people think of computer animation, the first applications that spring to mind are the most obvious, video gaming and animated movies. But there are many more opportunities for a talented animator.
Here are a few areas that employ animation specialists:
Movie production: Sure, you're thinking Toy Story, but that's not the only thing out there. It's hard to imagine a real life action movie today without animated elements. Groundbreaking animation produced that cool bullet effect in The Matrix and the monster in Cloverfield. As animations get more sophisticated, the line between fantasy and reality blurs, leaving theviewer with a satisfying sense of entering another reality, a different world. Jurassic Park employed a technique known as animatronics, a combination of animation and live-action models.
Television: Watch any news or sports program and see animations throughout the show. Logos, backgrounds, and features, all are animated and colorful to capture and hold your interest. Pay attention and you'll see screen transitions, weather reports, score cards, and myriad other moving, changing widgets aimed at keeping you glued to your seat.
Advertising: Let's be honest, do we really watch commercials if they aren't interesting and funny? That's why big names like Budweiser and Coca-Cola spend so much on those halftime commercials during the Superbowl. And what do the best ones have to offer? You guessed it, animation. Even billboards and advertising trucks have jumped on the animation wagon.
Web: animation is all over the web. Flash designs are popular on many websites and advertising banners are nearly always animated. Viral video production has become a popular marketing tool to build mailing lists and a solid customer base.
Engineering: Some elements of animation cross over into design fields such as engineering, automotive design and architecture. Similar Computer-Aided Design (CAD) programs are used by game designers to create monsters, by architects to create buildings and by auto designers to build cars.
Medical/forensics: Scientists and doctors use 3D modeling and animation to create simulations of crime and accident scenes, to construct models of faces based on skulls, and to calculate bullet trajectory.
Cartography: Maps are no longer flat pieces of paper, they are interactive, animated, and loaded with information about everything from nearby restaurants to traffic patterns.
Animation is everywhere, enmeshed in the fabric of today's society, and this trend will only continue to grow as programs become more complex and offer more options. An education background that includes computer animation could translate well into any number of careers, including advertising, software or web design, fashion design, engineering, architecture, automotive design, medical or forensics fields. Today's animation is not just about gaming. It is a solid career path that can lead in many lucrative directions.
.I 62
.T
document.62
.W
CGI Skin Just got a whole lot more realistic
We might be one step closer to eradicating the uncanny valley.

Researchers from the Imperial College London and the University of Southern California have created a new way to depict human skin, making facial expressions more lifelike.

Motion capture of a human actor remains the best basis for a realistic CGI animation, but no motion capture system is capable of recording the minute details and deformations of skin that appear with different facial expression. To combat this, the researchers built a special device that manipulates the skin on an actor’s face, capturing detail at a resolution of 10 microns.

They noted how skin becomes rougher as it contracts, and smoother and shinier when it is stretched, and how different areas of the face are contracted and stretched with different facial expressions. Once this data has been recorded, CGI artists will know which areas of the face of blur and which to sharpen, based on the compression and stretching that corresponds to each expression. This data can then be mapped to the CGI character’s face, providing a new level of verisimilitude.

Unveiled at this years SIGGRAPH (Special Interest Group on Graphics and Interactive Techniques) conference, it’s unsure how long it will take before this technology filters down to the media we consume. But be on the lookout for eerily lifelike CGI characters.
.I 63
.T
document.63
.W
Avengers and the age of CGI Overkill in hollywood
In the bad old days of “Whiz! Bam! Pow!” TV-and-movie superheroes — which yielded cut-rate, campy artifacts like those “Captain America” TV movies or Roger Corman’s unreleased version of “Fantastic Four” — a massive spectacle like “Avengers: Age of Ultron” seemed unimaginable. Yet the technology that has made such blockbusters feasible has, creatively, become a curse as well as a blessing.

This story first appeared in the May 05, 2015 issue of Variety. Subscribe today.
Computer-generated imagery, or CGI, makes all things possible. While the 1978 “Superman” used the memorable slogan, “You will believe a man can fly,” that claim has never been truer than it is now.

The ability to mount enormous battles featuring multiple super-powered characters, however, has become its own trap. And while the results can be visually ­astounding, the movies regularly feel as lifeless and mechanized as the technology responsible for bringing those visions to fruition.

The why of it remains something of a mystery, but the outcome is frequently a hugely expensive — if often enough quite lucrative ­— tentpole release that certainly puts the money onscreen, yet nevertheless proves more numbing than exciting, even during what should be the show-stopping sequences.

The original “Avengers” was mostly a happy exception, even with its prolonged alien-invasion climax. “Age of Ultron,” while ambitious in exploring relationships among characters, becomes drearily repetitive as the heroes mow down another CGI horde, this time consisting of artificially intelligent robots.

Granted, these movies are popular targets, and it’s easy for midnight-screening types to dismiss such criticism — as evidenced by the tone of the reviews in the Los Angeles Times and New York Times — as the lament of a stodgy curmudgeon who worships at the footage of “Citizen Kane.” However, as one who collected comicbooks and endured one disappointment after another seeing beloved heroes brought to the screen, this critic rejoiced as Tim Burton’s “Batman” and Bryan Singer’s “X-Men” helped usher in the current golden age — quite literally, based on the subsequent trail of record-breaking opening weekends.

Notably, a TV series like “The Flash,” operating on a smaller budget, can’t match theatrical action setpieces and must exhibit greater ingenuity. On the flip side of the coin, watching two Kryptonians go toe to toe in “Man of Steel,” destroying much of Metropolis in the process, became a bruising ordeal for viewers, too, despite how good the scene looked compared with the confrontation three decades earlier with Zod and his sidekicks in “Superman 2.”

The pattern has become predictable. “Iron Man,” a terrific movie overall — particularly in capturing the origin story — degenerated into a mundane brawl between two armor-clad characters. Ditto the “Hulk” reboot with Edward Norton, which culminated with the title character’s ho-hum showdown with another green behemoth, the Abomination.

One can argue, in fact, that the much-maligned second “Star Wars” trilogy sacrificed an element of its humanity in George Lucas’ embrace of a wholly digital filmmaking approach. At a certain point, watching droid armies being whacked to pieces begins to yield diminishing returns.

Put more simply, just because CGI wizardry allows you to do something, whether hoisting an entire city into the air or leveling skyscrapers willy-nilly, doesn’t always mean you should. Because while the box office figures might suggest otherwise, there is an audience out there that’s weary of these movies precisely because of the hollow quality to the inevitable final 30 minutes of unrelenting mayhem.

For fans, the first emotion in seeing comicbooks taken seriously has no doubt been something approaching gratitude. After all the cinematic indignities the genre experienced, it’s been thrilling for Hollywood to recognize that these stories needn’t be presented as camp, as if no one over 12 could take them seriously.

The good news is comics have become big business, making the entire movie industry covetous of, and reliant upon, the emerald riches at the end of the rainbow. Yet watching the Avengers lay waste to another army of tin men, what these films are lacking isn’t a brain, or even heart. It’s something closer to an actual pulse.
.I 64
.T
document.64
.W
Why is VFX being vilified
Avengers: Age of Ultron opened this month as the box office steamroller it was destined to be. Much of the critical response to the film has been lukewarm, however, citing the bloated visual effects action sequences as a source of lethargy. This is hardly a new sentiment. As early as 2006, a discussion began in the media that continues sporadically: when will audiences finally grow weary of the visual effects reign of terror?

The box office indicates that the answer may be never. When looking at a list of the worldwide top grossing films of all time, there is not a single film that is not reliant on effects work. (Even Mama Mia, which clocked in at 97, employed a visual effects crew—yes, many of those idyllic Greek island vistas were the product of green screens and compositors.) Meanwhile, the popularity of superhero films affirms there is a global audience with an essentially unending appetite for them. And yet there is the sense right now in the critical establishment that the spectacle of movies has reached an untenable pitch of over-the-top effects-driven destruction, and that the people who make these effects are in fact responsible for the downward slide of the art of cinema.

A recent article in Variety, "Avengers and the Age of CGI Overkill in Hollywood," outlines the general principle: somehow the technology is to blame here. It’s too profitable and too easy. Those who wield the power can’t help but keep pushing the VFX button, and it has ruined the movies. But decrying the use of visual effects in movies fails to look at the multi-national global complex that now comprises film financing. Not only does the Variety article fail to assign any responsibility to the director of the latest Avengers film, it does not even begin to allude to the economic forces that are driving these decisions. Incidentally, these same economic forces keep VFX houses perpetually in the red, and far away from making the financial and artistic decisions that comprise the content they are contracted to generate.

Pitting artistry against technology implies that filmmaking is one thing and "CGI wizardry" is something else. It also reflects an ignorance about just how pervasive image manipulation is in everything we watch—Birdman being the latest film to be touted as an intelligent critique of the glut of franchise films, even as it too was a product of the same sophisticated VFX those films employ. There is no argument here over the fact that action sequences have become overly long, brainless, and punishing to watch. But rather than holding filmmakers responsible for the way in which they use the VFX tools available to them, critics imply it is the medium itself that is culpable, as if it can only be used in one way: a shock and awe campaign beating audiences into submission.

Blaming computers for the dumbing down of movies has become a journalistic trope
This discussion is partially attributable to the age old tension between high and low art forms; the argument over what appeals to the masses versus what has intellectual value. It also speaks to our growing ambivalence about living in an increasingly technological world. We are attracted to technology, even though we may not always understand it. At times we feel beholden to it. But, with entertainment media being inextricably invested in the financial success of the Hollywood establishment if not, at times, its mouthpiece, there may be something even more sinister happening beneath the surface of the debate.

The international subsidies-driven business model under which VFX companies operate has been well documented. In pursuit of tax rebates offered by various governments to produce films in their jurisdiction, studios insist that VFX companies open branches in these locations or reduce their bids by the amount of the subsidy in question. Even as studios, directors, and audiences demand the latest in cutting edge technology, VFX houses must underbid one another to get the work and many have been shuttered due to operational losses in the wake of explosive blockbuster budgets. The cost of research and development, shrinking schedules, and the unlimited changes that are the building blocks of every tentpole film, are shouldered entirely by VFX houses. Devaluing their product in the public discourse has become part of a larger strategy towards keeping costs down and profits squarely in the pockets of studios.

In 2010, James Cameron’s Avatar became the highest grossing film of all time just 41 days after its release, raking in an incredible $2.7 billion by the end of its run. Weta Digital, the VFX studio that created the majority of the visual effects, along with Lightstorm Entertainment, invested years in developing the tools and talent necessary to create Cameron’s almost entirely computer generated vision, with the cost of making the film rumored to be upwards of $500 million. Cameron had promised to show the world what visual effects could do and he succeeded. The results were universally lauded as visually stunning and unparalleled.

Yet, rather famously, the film and Cameron were snubbed that year at the Academy Awards, both for Best Picture and Best Director. The blame was laid at the feet of the critical success of The Hurt Locker. However, awarding Avatar the Academy’s highest honor would have been acknowledging visual effects as not only lucrative, but high art as well, worthy of its astronomical price tag. And that was a bargaining chip Hollywood was unwilling to concede to an industry it continues to hold hostage with threats of outsourcing to unskilled laborers around the globe.

As the debate surrounding what visual effects are worth rages on, it is clear that the studios themselves have an interest in perpetuating the myth that VFX are the product of clinical assembly lines and the results are equally lifeless and mechanical. Blaming computers for the dumbing down of movies has become a journalistic trope that is bandied about to squeeze the one part of the Hollywood machine that has no union or organizational skill to push back. The right hand asserts they are something not worth paying top dollar for, while the left lines up an interminable roster of VFX-based box office juggernauts for the foreseeable future. Even as big budget franchises continue to dominate the box office, the studios will do whatever it takes to keep costs down until audiences truly do tire of their superhero agenda.
.I 65
.T
document.65
.W
Is CGI software poised to kill photography? Its close
Despite public craving for ridiculous Photoshop failures and public shaming of horrific photographers, the perpetual myth that a fancy-ass camera and technical wizardry is the way to get rich off photos still remains. Outside of the hyper-competitive world of fashion shooters and international photojournalists — and the decidedly un-glamorous world of city news, which finds photogs shooting sidewalk blood stains on an uncomfortably regular basis — the path to working success for a young photographer tends to involve grinding out a thick portfolio of stock images and product shots.

Stock photos may not be super exciting, but they certainly help pay the bills. They’re also becoming increasingly easy to replace. Don’t believe me? Take a look at the next two images and tell me which one’s fake.

Sorry, you’re wrong. They’re both fake. Photographer Mark Meyer whipped them up with a cheap bit of CGI software, and according to him, it’s easy as pie. In an excellent post on his blog, Meyer notes that while photography was long the cheapest way to capture realism, that’s changing. Thus, as software becomes increasingly powerful and cheap, photography increasingly looks like a dated technology. He writes:

Computer generated imagery and photography are on intersecting trajectories. While photographers employ tools like Portrait Professional that sanitize their portraits, making them look more like renderings, 3D artists are adding blemishes and developing tools like subsurface scattering to make their renderings look more like snapshots. Photographers are fighting to remove noise, CGI artists are adding it; photographers are using digital techniques like focus stacking to extend depth of field, while CGI artists begin with unlimited depth of field and artificially reduce it. At the moment photography is still the most affordable means to quickly create realism in most applications with notable exceptions in large scale cinema productions and car advertising. But the two worlds are about to merge and a large part of the photography industry will be replaced by software.

Now, before we go any farther and people start freaking out, let me remind you that we’re talking about photos as products, not as art. When it comes to an ad for a watch or a gadget, firms don’t care if a photog shot on a Hasselblad or a Mamiya, they just want smart, clean images. If a computer can do the same, with more flexibility (changing perspective after the fact, for one, is a huge potential selling point), why not?

It’s not like this is the first time photographers have worried about being replaced, either. Wander into any photo forum online and you’ll find a wealth of people complaining about how cheap, easy-to-use DSLRs and a wealth of online photo-publishing platforms have flooded the world with a ridiculous wealth of images, ranging from great to heinous.

Now, I’d tend to view those guys as a bunch of crotchety complainers, like many forum people tend to be, especially when you have guys praising examples of poorly-designed complexity in modern cameras because it makes it harder for non-pros to use them. But when I’ve found myself wandering through a favela in São Paulo only to come across a family stumbling about, waving $10,000 worth of gear around for aimless snapshots, I guess I understand a little bit.

Then there are more egregious examples, like that of David Shankbone, who’s allegedly been called “arguably the most influential new media photojournalist in the world.” Why’s that? Well, he’s taken the photos that have been used in over 5,000 Wikipedia articles, thanks to the fact that he licenses all of his images under a free Creative Commons license.

Paparazzi make a ton of money, and as such are a rather competitive bunch, and they surely don’t take kindly to Shankbone giving away all his work for free. But Shankbone’s hardly the problem; for every one of him, there are thousands of other people putting their shots out their to be seen, rated, and distributed for free.

From a publishing standpoint, that’s great. Motherboard would be a hell of a lot more costly to run if we had to pay licensing fees for every image we use. And from the standpoint of an amateur or someone who shoots a lot on their own time, the ease of spreading a portfolio online means getting exposure (and finding good photos) is more egalitarian than its ever been before. But, once again, if photos pay the rent, the huge online photo community doesn’t help.

But what if CGI and the mountain of images on the web were combined? Well, that’s already happening. In a paper published on the Association for Computing Machinery’s Queue Blog, David Crandall and Noah Snavely discuss how to apply the methods of computational photography to the vast wealth of images online to not only get a better spectrum of images of a single place — see geotagging on Flickr — but to also create whole new images. Let me borrow a slide from their post to illustrate what I’m talking about:

Thousands and thousands of photos of the Colosseum are easily available online, but the best are most likely going to cost money or involve some sort of licensing. Look at the image Crandall and Snavely produced: It’s well-composed, relatively distortion-free shot that would normally need the right equipment, skill, and potentially the stitching of a number of separate images by a pro. Crandall and Snavely skipped all that:

The reconstructed cameras are shown as black wireframe pyramids indicating where each photo was taken, and the Colosseum is reconstructed as a dense 3D point cloud, similar to what a laser scanner would capture—but in this case, reconstructed completely automatically from photos found on the Internet.

Just think about that for a second. Here’s a photo with a custom perspective and lighting, developed totally from images ripped off the Internet. Sounds like a dream doesn’t it? I mean, why would anyone pay for a photographer when they could take the best parts of a bunch of random Internet pictures to make their own perfect shot? No wonder people are saying that photography is screwed. The only problem is they’re wrong. As Meyer writes:

For the first time in history, photography is about to lose control of its monopoly on affordable, convincing realism and it’s time for us to understand that realism has never been the most important feature of the photograph. Although we rarely think about it, we understand this intuitively: a computer rendering of your daughter’s wedding will never be the same as a photograph even if both are equally realistic. The photograph is defined by its causal, mechanical connection to the real world.

Look at it this way: Photojournalism will always persist. Look at award-winning photographs of powerful moments, and then try to tell me that they could have been replicated by computer processing of other shots (impossible) or by some dude wandering by with a cell phone (nearly impossible). Good photojournalists will always have jobs because it’s impossible to replicate what they do. (Shrinking photo budgets are of obvious concern, but aren’t directly the fault of technology.)

And, although photojournalism is a particularly stable example, that thread carries through to anyone who takes pictures for a living. So are photographers poised to go out of business? Well, people grinding out product shots for cheap employers are probably going to feel the pinch, but as for anyone else, people simply don’t want a substitute.

People demand the real deal, and aside from the aesthetic advantage of a good shooter versus a computer rendering, there’s the simple fact that people will always have a better connection with an image that was captured by someone who was actually a part of that moment. It’s as simple as that: You feel disappointed as soon as you real an image isn’t real, because capturing reality — not realism — is the whole point of taking pictures.
.I 66
.T
document.66
.W
Why are CGI Humans Creepy and What are scientists doing about it
A century ago, psychologists identified "the uncanny" as an experience that seems familiar yet foreign at the same time, causing some sort of brain confusion and, ultimately, a feeling of fear or repulsion. Originally no more than a scientific curiosity, this psychological effect has gradually emerged as a profound problem in the fields of robotics and computer animation.

The most familiar things in the world to us — the voices, appearances and behavior of humans — are being replicated with increasing veracity by animators and robotics engineers. Today's ultra-lifelike androids and computer-rendered humans would seem to bridge the valley between the land of the living and the distant cartoon world occupied by Disney princesses and animé characters. But these characters aren't so much bridging the valley as falling into it. When we look at them, they seem at once familiar and eerily alien, triggering an uneasy feeling.

The spooky region occupied by these characters, so close to us and yet so far, is known as "the uncanny valley." The term comes from a graph created by Japanese roboticist Masahiro Mori that plots human empathy against the anthropomorphism of robots. On the graph, as robots become more realistic and we feel more and more empathy for them, the line trends upward. But as the robots' humanism approaches that of actual humans, our empathy for them — and the line on the graph — suddenly plummets.  The resemblance between human and robot goes from remarkable to repulsive, and this precipitous drop became known as the "uncanny valley."

Karl MacDorman, a professor in the Computer-Human Interaction Program at Indiana University, leads a research team that is investigating why, psychologically, the uncanny valley exists. He hopes his research will help animators and other roboticists bridge the valley by creating human replicas that come across as lifelike and natural rather than creepy. Doing so won't just improve animated movies and video games; androids are becoming more widely used in everything from the service industry to iPhone apps to scientific research. They're here to stay, so scientists are doing what they can to make their presence more pleasant.

Mapping out the valley

Since 1970, when Mori first described the uncanny valley effect in the context of robot/human interactions, scientists have been trying to determine what it is about humanlike non-humans that creeps us out, exactly.

According to MacDorman, occupants of the uncanny valley have one defining quality: "an eerie feeling elicited by a human character that is highly realistic in some aspects but not others," he told Life's Little Mysteries, a sister site to LiveScience. For example, as MacDorman discovered in a recent study, "this feeling can be elicited by a mechanical-looking robot that sounds human or a human looking robot that sounds mechanical — or moves in a mechanical way." [How the Cleverbot Avatar Talks Like a Human]

In other experiments, MacDorman's team showed that people feel particularly disconcerted when characters have extremely realistic-looking skin mixed with other traits that are not realistic, such as cartoon eyes. Furthermore, in a 2009 study in which participants were asked to choose the eeriest-looking human face from among a selection, the researchers found that computer-rendered human faces with normal proportions but little detail were rated eeriest. When the faces were extremely detailed, study participants were repulsed by those that were highly disproportionate, with displaced eyes and ears. In short, viewers seemed to want cartoonish facial proportions to match cartoon-level detail, and realistic proportions to match realistic detail. Mismatches are what seemed eerie.

Based on his research, MacDorman thinks the uncanny valley effect happens when certain realistic traits lead us to expect all other traits to be realistic as well; we feel disturbed and repulsed when our expectations are then violated. Strangely, though, only human characters can trigger the effect. In the highly successful computer-animated film "Avatar," for example, "the uncanny valley was avoided by reserving computer rendering primarily for the Na'vi characters and not the human characters," MacDorman said. The alien Na'vi in the 2010 film were humanoid and extremely lifelike, but they were blue-skinned with other clearly non-human features, so they didn't trigger the uncanny valley effect. [Inside Movie Animation: Simulating 128 Billion Elements]

Creepy feeling

So why do we feel unnerved or repulsed by quasi-humans, but not quasi-dogs or computer-rendered Na'vi? What's the evolutionary root of this psychological phenomenon? There are several hypotheses, but as yet, no scientific consensus. One is that the actions of androids and computer-rendered humans might deviate subtly from how we expect humans to socialize and interact, and as acutely social beings, we find the violations of our social norms disturbing.

Alternatively, psychologist Christopher Ramey of the University of Kansas suggests we struggle with the conceptual strangeness presented by androids. "Humanlike robots may force one to confront one's own being by creating intermediate conceptualizations that are neither human nor robot," Ramey wrote in a 2005 article.

A third hypothesis is that "uncanny valley" characters differ subtly from what we perceive as healthy and beautiful, and that we reject them just as we reject mating with those we perceive to be reproductively unfit. Along similar lines, other theorists have argued that we feel disgusted by uncanny valley characters for the same, evolutionary reason that we feel disgusted by certain diseases. We sense that they are somehow diseased, and steer clear in order to avoid contagion.

No one knows which of these guesses is correct. "I am working on testing the various theories," MacDorman said.

Billion-dollar issue

Whatever the psychological root of the problem, there's a lot to be gained from figuring out how to get around it. Many computer animation studios, including industry leader Pixar, shy away from characters that might get lost in the uncanny valley, preferring cartoon stylization instead. They've watched braver studios fail. For example, ImageMovers Digital, a computer animation firm headed by producer Robert Zemeckis, produced a series of critical and commercial flops because of negative audience reactions to their eerie characters.

MacDorman says it's easy to see why many of Zemeckis' CGI (computer-generated imagery) films flopped — starting with "The Polar Express" in 2004 and including "Beowulf," "A Christmas Carol" and "Mars Needs Moms." "A common feature of Zemeckis' films is a mismatch between the characters' physical appearance and movement owing to the misuse of motion capture technology," MacDorman said. (With motion capture, human actors are filmed and their motions are used to animate digital characters.) "For example, in 'A Christmas Carol,' we see an old man thrust into the heavens, and yet his movements are that of a young acrobat. This mismatch between appearance and behavior breaks the illusion of being transported into another world. Audiences lose their identification with and empathy for the characters."

Ward Jenkins, an animator and blogger, has pointed out that characters' eyes are often overly bright compared to the shadowy lighting of scenes in Zemeckis' films, and that their eye/skin mismatch lands them in the uncanny valley.

As Zemeckis has no doubt become acutely aware, you can't make much money on a film whose uncanny protagonist doesn't garner empathy from the audience. ImageMovers Digital closed in March after the failure of "Mars Need Moms," though it announced in August that it would reopen and continue trying to perfect the use of motion capture.

MacDorman says success will require matching the level of realism of all aspects of the characters.

After all, according to MacDorman, there is much to be gained from bridging the gap between the cartoon and the real world. "Clearly, many topics demand a high degree of realism, of authenticity," he said. "However, sometimes they also demand the impossible of actors, such as extreme age progression and regression in 'The Curious Case of Benjamin Button' or aerial acrobatics in 'The Matrix.'" [See video]

Those two films used computer animation in a way that did not produce disturbing results, MacDorman said. This was partly because CGI was used only when necessary, to animate actions that human actors could not perform, and within this limited scope, great care was taken to give all aspects of the characters the same level of realism. "Many viewers did not realize that in 'The Matrix,' digital doubles of Keanu Reeves and Hugo Weaving were used in some of the scenes," he said. "'The Curious Case of Benjamin Button' was particularly adept at modeling and animating an elderly digital double of Brad Pitt and compositing into actual film footage. This is a case where we can say that the uncanny valley was bridged."
.I 67
.T
document.67
.W
Why computer animation looks so darn real
Walt Disney once said, “Animation can explain whatever the mind of man can conceive.” For Disney, this was animation’s magic — its power to bring imagination to life.

Disney died in 1966, 11 years before computer animation’s heralded debut in Star Wars, and he likely never imagined how life-like animation would become, or how pervasively it would be used in Hollywood. As viewers, we now hardly blink when we see a fully rendered alien planet or a teddy bear working the grocery store check-out counter.

Animation has largely stripped its reputation as a medium for children; it’s been used far too successfully in major films to remain confined to kids. After all, who hasn’t had the experience of going to an animated film and finding the theatre packed with adults? Who doesn’t secretly remember the moment they were a little turned on during Avatar?

Considering animation’s rapid evolution, it sometimes feels like we’re just weeks away from Drake and Chris Brown settling their beef via a battle of photorealistic holograms.

So how did we get here? How did computer animation come to look so darn real?

From the MoMA to Casper

Computer animation debuted in 1967 in Belgium, and soon after at the MoMA, with Hummingbird, a ten minute film by Charles Csuri and James Shaffer. The film depicted a line drawing of a bird programmed with realistic movements and was shown to a high art crowd, who probably weren’t fantasizing the medium’s potential to create a sassy talking donkey.

In 1972, Ed Catmull, future co-founder of Pixar, created the first 3D computer-animated human hand and face, which was incorporated into the 1976 sci-fi thriller Futureworld. Computer animation didn’t capture the mainstream’s attention, though, until the classic trench run sequence in Star Wars, which used 3D wireframe graphics for the first time. It was the product of a lot of guesswork and brilliance, particularly by animator Larry Cuba. If you have 10 minutes to kill, this old-school video of Cuba explaining how they pulled it off is fascinating:
The late seventies were a time, though, when innovation didn’t happen at the breakneck pace we’re accustomed to today. The next big moment for computer animation didn’t come until 1984, when a young member of George Lucas’ Lucasfilms team, John Lasseter, spearheaded a one-minute CGI film called The Adventures of Andre and Wally B, which pioneered the use of super-curved shapes to create the fluid character movement, a staple of future films by DreamWorks and Pixar, where Lasseter would serve as CCO.

1986’s Labryrinth introduced the first 3D animal — an owl in the opening sequence — and 1991’s Terminator 2: Judgment Day introduced the first realistic human movements by a CGI character, not to mention Arnold Schwarzenegger’s obsession with voter demographics.

In 1993, computer animation’s reputation soared with the release of Jurassic Park and its incredibly realistic dinosaurs. The creatures sent adolescent boys into fits of delight, even though the film only used computer animated dinosaurs for four of the fourteen minutes they were on screen.

Then came 1995 and the release of Casper, which introduced the first CGI protagonist to interact realistically with live actors, though that interaction was predominantly Christina Ricci trying to seduce a ghost.

But Casper was just a warm-up for Toy Story.

The Toy Story and Shrek Era



Six months after Casper, the first feature-length CGI film was released: Toy Story. It was an incredible four-year undertaking by Pixar’s John Lasseter and his team; the film was 81 times longer than Lasseter’s first computer animated film a decade before. They faced two fatal challenges: a relatively tiny $30 million budget, and a small, inexperienced team. Of the 27 animators, half were rumored to have been borderline computer illiterate when production began.

"If we’d known how small our budget and our crew was," remembered writer Peter Docter, "we probably would have been scared out of our gourds. But we didn’t, so it just felt like we were having a good time."

They thrived. The animators began by creating clay or computer-drawn models of the characters; once they had the models, they coded articulation and motion controls so that the characters could do things like run, jump and laugh. This was all done with the help of Menv, a modeling environment tool Pixar had been building for nine years. Menv’s models proved incredibly complex — the protagonist, Woody, required 723 motion controls. It was a strain on man and machine alike; it took 800,000 machine hours to complete the film, and it took each animator a week to successfully sync an 8-second shot.

There are more PhDs working on this film than any other in movie history,” Pixar co-founder Steve Jobs told Wired at the time. “And yet you don't need to know a thing about technology to love it."

Jobs was right. Audiences loved the film not just because of the impressive animation and three-dimensional realism, but also because of a superb script and voice work by Tom Hanks, Tim Allen and Don Rickles. It sparked computer animated films’ reputation for pairing stunning visuals with compelling stories. That reputation was key, as computer animation’s evolution hinged on the willingness of studios to invest in it.

In 1998, DreamWorks’ Antz and Pixar’s A Bug’s Life maintained computer animation’s stellar reputation, while briefly terrorizing countless entomophobic parents. The flood scene in Antz received widespread praise, particularly from those who couldn’t wait for the bugs to die.
Computer animation’s next breakthrough came in 2001 with Shrek. Shrek delved into true world building; it included 36 separate in-film locations, more than any CGI feature before it. DreamWorks also made a huge advancement by taking the facial muscle rendering software it used in Antz and applying it to the whole body of Shrek’s characters.

“if you pay attention to Shrek when he talks, you see that when he opens his jaw, he forms a double chin,” supervising animator Raman Hui explained, “because we have the fat and the muscles underneath. That kind of detail took us a long time to get right."

Shrek brought a new age of realism. Hair, skin and clothes flowed naturally in the elements; the challenge of making Donkey’s fur flow smoothly helped animators render the realistic motion of grass, moss and beards (and other things hipsters like). Shrek grossed nearly a half billion dollars, won the first-ever Academy Award For Best Animated Feature, and established DreamWorks as an animation powerhouse, alongside Disney-Pixar.

Advancements in Photorealism and Live Action
.I 68
.T
document.68
.W
. Introduction
One of the problems conventional computer animation has to deal with is the generation of motions that appear natural and realistic. On the other hand, it is important for the biomechanist creating, verifying or utilizing models, to visualize and present adequately the results of simulations based on these models. Computer animation is a powerful tool for presenting complex interdependencies clearly. User selectable frame rates and points of observation offer numerous possibilities in the form of presentation. If the animations are based on physical models, realistic motions are obtained. Thus, not only is computer animation a valuable tool for studying and comprehending the results of biomechanical simulations, but the use of (bio)mechanical models has also improved realism of computer animations.

An instructive form of presentation, which is particularly useful for comparing actual and simulated motions, results from overlaying video sequences with computer animations. This method is also applicable for presenting the results of model-based human motion analyses, such as calculated joint torques, compressive or shear forces, simultaneously with the motion of the subject.

Applications of three-dimensional and video overlaid animations have been developed and will be presented in the sequel. Before this is done, a short survey of the animation techniques used is given.

2. Three-dimensional computer animation
Three methods can be distinguished for generating three-dimensional computer animations[1]. The principle of the first method, image-based keyframe animation, is to create inbetween frames by interpolating keyframe images supplied by the animator. The second method, parametric keyframe animation, is based on describing the keyframes by a set of parameter values, which are interpolated. If the motion is algorithmically described by a list of transformations defined by parameters, which may change during the animation according to certain physical laws, the third method, algorithmic animation, can be applied. Such parameters may be time-dependent data sequences provided as a result of a biomechanical simulation. Examples of such parameters are rotation angles, e.g. the rotation angles describing the position of the right forearm in relation to the right upper arm in the case of human motion simulation.

If the animated motion needs to be viewed from different positions, three-dimensional graphical models have to be developed. In computer modeled animation[2], three main activities are involved. First, the three-dimensional objects, which are animated, have to be modeled. These models must be parameterized so that differences in the geometry can be taken into account. In the next step, the motion must be specified. In the last step, realistic images must be produced by removing hidden surfaces and adding effects like shading. This process is called “image rendering”. Three methods have been established for this purpose. The polygon shading method is often hardware implemented and can be performed in real time. The surfaces of the objects are constructed of primitive polygons such as triangles and quadrangles which may be shaded. The ray tracing and radiosity method allow the generation of realistic images but are expensive in computation time.

Animations can either be generated in real time or produced frame by frame. Real-time computer animation is limited by the capabilities of the computer, because at least 15 frames per second must be displayed to generate the illusion of a continuous movement. Frame by frame animation systems use the computer to produce each frame individually. Afterwards, the frames are presented in real time. This can be achieved by the real-time playback method, where computed frames are saved in mass storage and then displayed by a real-time program. Another possibility is to store the frames on a videorecorder and to display the whole sequence afterwards. Using the frame buffer animation method means dividing the pixel memory into different regions, where each region contains a frame, and displaying the images by using zoom, pan and scroll operations.

3. Video overlaid animation
The principle of this presentation technique is to splice together animation with digital video files. The video images are first captured from videotape or videocamera using frame-grabber boards, or provided by special digital recording systems, such as the KODAK EKTAPRO 1000 system used in the application to be described. The video images are then overlaid with the corresponding frames of the animation and either displayed by applying the real-time playback method or stored on a videorecorder frame by frame.

4. Animation of the ball–racket impact phase
Models of the tennis racket and the ball have been developed by Hatze[3], which permit the simulation of the ball–racket impact. The result of the simulation yields not only information on the time-dependent three-dimensional positions and orientations of racket and ball (three linear coordinates of the center of mass and three Cardan angles each) but, in addition, on the transverse and torsional vibrations of the racket as well as on the deflections of the string plane and the compression of the ball. Graphical models of the racket and the ball have been constructed. That of the racket is parameterized, so that the shape of the racket's head can be varied. The polygon shading method is used for image rendering, a frame by frame technique for creating the animation. The animation system has been implemented on a parallel computing system based on T800 transputers. Fig. 1 shows one frame of an animation sequence. Arrows represent the simulated impact force and reaction forces on the racket, which is held by an artificial arm in the model simulation.

Animation of ball–racket impact phase. Instant of maximum string deflection.
Fig. 1. 
Animation of ball–racket impact phase. Instant of maximum string deflection.
Figure options
5. Animated presentation of drop jump analysis results
Drop jumps are exercises for improving reactive capabilities (e.g.[4]). Athletes performing that kind of motion jump down from a raised platform and, upon landing, execute a maximal vertical jump. Different methods are applied to analyze drop jumps biomechanically. In particular, the vertical jumping height, i.e. the height, at which the mass center is raised from leaving the ground to the vertex of the flight phase, and the durations of the phases of downward and upward movements during foot contact with the ground are used for quantifying the jumping capability. These parameter values are determined from measured data. A rather inaccurate method estimates the jumping height from the flight time, i.e., from the time between the instant of leaving the ground and the instant of landing. This method works if and only if the height of the mass center at the instant of leaving the ground is exactly that at the instant of landing. In another method (e.g.[5]), markers are placed on the skin of the subject in order to define the positions of the bodysegments and the motion is recorded with a high-speed motion analysis system. In combination with a model of the human body, the trajectory of the mass center of the whole body is calculated. The jumping height is then computed as difference between the highest position reached by the mass center and the height of this mass center at the instant of leaving the ground. There are, however, sources which may introduce errors into these calculations: the position of the mass center is calculated from markers applied to the skin of the subjects. Due to skin motion, these markers shift relative to the skeleton. Moreover, the center of mass is calculated utilizing models, which do not comprise all relevant degrees of freedom of the real human body. For example, in most of these models, the whole torso is modeled as a rigid segment. Consequently, the trajectory of the mass center will be calculated erroneously and all parameter values derived from it as well. The correct jumping height and durations of the phases of downward and upward movements can, for example, be calculated, if the vertical ground reaction forces during take off from the raised platform and during the vertical jump are measured. The jumping height is then derived from the integral of the net vertical force (vertical ground reaction force minus body weight) taken from the instant of beginning the take-off motion to the instant of leaving the ground.

Two force plates have been integrated into our experimental setup to measure these ground reaction forces. The drop jumps are recorded with a frequency of 250 frames per second with a KODAK EKTAPRO 1000 high-speed video system, which allows recording frequencies of up to 1000 frames per second. The resolution of the recorded images is, however, only 239×192 pixels. The 17-segment model of Hatze[6], which is very detailed when compared to other anthropomorphic models, is used to calculate the trajectory of the mass center.

Video overlaid animations can now be generated to illustrate the differences resulting from applying the different methods. The video images of the motion are overlaid with graphical elements illustrating the following quantities: ground reaction forces (neglecting the component perpendicular to the sagittal plane); the vertical position of the center of mass relative to the position at the instant that the toes loose contact with the ground, and the vertical instantaneous velocity. The latter quantities are calculated applying the exact method using two force platforms (illustrated by bars labeled A in Fig. 2), the method based on the determination of the trajectory of the center of mass (B in Fig. 2) and the flight time method (C in Fig. 2). The base-line is set to the (approximate) vertical position of the center of mass at the instant that the toes loose contact with the ground. The overlaid images are stored frame by frame on a videorecorder. A miroVIDEO DC1 board is used for that purpose. The real-time playback method is also applicable. Fig. 2 shows one frame of an animation sequence.

Comparison of methods for analyzing drop jumps.
Fig. 2. 
Comparison of methods for analyzing drop jumps.
Figure options
6. Summary
The suitability of computer animation techniques for visualizing biomechanical research results has been demonstrated. Increased computer performance and improved graphic facilities have offered this economical and efficient method for communicating and presenting information.

The main aspects of three-dimensional and video overlaid animation have been summarized. Both techniques have been illustrated by practical applications.

As an example of computer modeled animation, which is probably the most important form of three-dimensional animation for presenting the results of biomechanical analyses or simulations of human or animal motions, the simulated ball–racket impact phase has been visualized. Three-dimensional parameterized geometric models of the tennis racket and the ball have been developed for this purpose. The motion of racket and ball (translation, rotation, transverse and torsional vibrations of the racket, deflection of the string plane and compression of the ball) is given as result of a biomechanical simulation. A polygon shading method is used for image rendering and for removing hidden surfaces respectively.

As an example of video overlaid animation, high-speed video sequences of recorded drop jumps, i.e. motions, where athletes jump down from a raised platform and, upon landing, execute a maximum vertical jump, have been overlaid with graphical elements to compare three methods for determining the jumping height and related parameters. The vertical position of the center of mass relative to the position that the toes loose contact with the ground and the vertical instantaneous velocity are represented by bars of variable length. Both quantities have been calculated applying the three different methods, so that differences can vividly be demonstrated.

.I 69
.T
document.69
.W
Animation, the ultimate tool
2. The uses of animation

2.1 Cartoons

The most common use of animation, and perhaps the origin of it, is cartoons. Cartoons appear all the time on television and the cinema and can be used for entertainment, advertising, presentations and many more applications that are only limited by the imagination of the designer. The most important factor about making cartoons on a computer is reusability and flexibility. The system that will actually do the animation needs to be such that all the actions that are going to be performed can be repeated easily, without much fuss from the side of the animator. Speed here is not of real importance, as once the sequence is complete, it can be recorded on film or video, frame by frame and played back at an acceptable speed.

2.2 Simulations

Many times it is much cheaper to train people to use certain machines on a virtual environment (i.e. on a computer simulation), than to actually train them on the machines themselves. Simulations of all types that use animation are supposed to respond to real-time stimuli, and hence the events that will take place are non-deterministic. The response to real-time stimuli requires a fast response and the non-determinism, requires a fast system to deal with it. This means that speed is the most important factor in simulation systems.

2.3 Scientific Visualisation

Graphical visualisation is very common in all areas of science. The usual form that is takes is x-y plots and when things get more complicated three dimensional graphs are used. However there are many cases that something is more complex to be visualised in a three dimensional plot, even if that has been enhanced with some other effect (e.g. colour). Here is where animation comes in. Data is represented in multiple images (frames) which differ a little from each other, and displayed one after the other to give the illusion of motion. This adds a fourth dimension and increases the information conveyed. Speed here is again the most important factor, as huge sets of data might have to be displayed in real-time. Someone might argue, that results maybe filmed and played back, but that depends on how often the sequence has to be recalculated. For example it might take a few days or weeks to generate an animation of a fractal, which zooms in slowly, and it might be distressing to realise that it has zoomed in at the wrong place.

The uses of scientific visualisation can be classified into two main categories: analysis and teaching. Both of these are described below

2.3.1 Analysis and Understanding

Very frequently, scientists have large sets of data (often in the form of lists of numbers) that need to be understood and often a theory needs to be formulated that explains their relationship. It would be very difficult to go through these lists manually or otherwise and make any sense out of them, unless some graphical technique is used for the initial approach. If the data set is massive, a short (or long) animation of the data can give the scientists a first idea of how to approach the situation.

Examples of the different uses of animation:

Astronomers use computers to do animations if high speed jets penetrating different gases, to determine why a few galaxies flare dramatically. (This research has given out valuable information about why some galaxies flare into broad plumes and why others remain extremely straight and narrow).
British Telecom uses sophisticated programs that plot on a map of the UK, the density of telephone fault reports using different colours. When a storm was plotted on top of this map and the whole system was animated it could be seen that the density of faults increased significantly at areas from which the storm had just passed.
Animation can be used in software engineering, where an algorithm can be animated, in order to understand how it works or to debug it. Spotting errors using animation, becomes much easier.
2.3.2 Teaching and Communicating

One of the most difficult aspects of teaching is communicating ideas effectively. When this becomes too difficult using the classical teaching tools (speech, blackboard etc.) animation can be used to convey information. From its nature, an animation sequence contains much more information than a single image or page of text. This, and the fact that an animation can be very "pleasing to the eye", makes animation the perfect tool for learning.

Two examples of the use of animation for learning are:

Programs that show the planetary system in action in three dimensions make it very easy for kids to understand rather than using tables of sizes, periods and diameters.
Astrophysicists at the National Center for Supercomputing Applications, work with artists, in order to explain some phenomena which cannot be seen such as the visualisation of the gravitational field of a Schwarzchild black hole. The latter is not visible as it absorbs all light that falls onto it. The only way of experimenting with it is to animate it on a computer.
3. History of Animation Techniques

3.1 Brief History of Animation

Picture animation was invented in 1831 by Joseph Antoine Plateau. He used a machine called phenakistoscope to create the illusion of movement. The device consisted of a spinning disc that held a series of drawings and windows that framed the user's perception of the drawings. Many other animating machines were invented since then, but it was not until 1906 when the first complete animated film was produced by J.Steward Blackton. It was called "Humorous Phases of a Funny Face". In 1915, Earl Hurd introduced the technique of cell animation which took its name from the transparent sheets of celluloid that was used. The father of animation, Walt Disney produced a huge cartoon world in less than ten years at 1928. The first commercial animated cartoon, "Snow White and the Seven Dwarfs", was then produced. Many people followed, which contributed to this evolution. The results were good, but to a certain point. When very complex animation was required, everything turned out to be extremely difficult. Something was definitely missing and technology would give the answer in the following years.

3.2 Traditional Animation Techniques

Hand-drawn animation, with each frame individually crafted by an artist, requires a lot of skill, a lot of patience and very little equipment. The drawing is usually done on a cell which allows multiple frames to be drawn by the same cells. Each frame can be recorded on film or video, and the amount of work going into an animation is staggering. A feature film containing the production of 250,000 drawings would take fifty years of labour if all were to be drawn by a single artist. So usually it is coordinated by one person but the work is divided among a number of artists. Senior artists will draw the key frames and junior artists will draw in-between ones.

As we said before all the detail can be painted on to every frame; it is more likely that the frame will be compiled from several cells at the point of filming. The background may be on one cell, static characters on the other and the moving character on the top. In this way the bottom two cells can be used in a number of frames. It might also be that the cells are moved relative to one another, in successive frames, without being redrawn. Conventional animation is oriented mainly towards the production of two-dimensional cartoons. Every frame is a flat picture. In order to achieve the multiple frame design by using the same cells the multiplane technique is used. Several glass layers are placed beneath the camera at varying distances. On the layers the cells are placed and the frame is filmed. A lot of camera effects can be added into the animation but they are usually difficult to produce and sometimes are very expensive. A few of them are: zooming, fade-in, fade-out, etc.

3.3 Computer Assisted Animation

It is very clear that automation of the whole animation or even part of it would be very productive. Computers were used for animation for the first time in early sixties but it was mainly for scientific reasons. Ten years later animators started to consider computers to be a very powerful and useful part of their animation systems.

Today, computers can be used in animation in two main ways: as tools to improve the application of traditional methods; and as a means of generating animation which is not possible using traditional methods. Computers can considerably improve the speed, accuracy and at the same time reduce the cost of traditional animation methods. Projects which were impossible to realise in the past could actually be attempted.

Computer animation systems are classified into several different levels. These levels define the depth of the assistance that is provided by the computer. At the lowest level the animator can use software only to design the drawings. On the other hand at the highest level the whole work drawing, modeling and motion control is produced by the system.

The second more important advantage of modern animation systems apart of the fact that make everything easier is the interactivity. Animation can not only be a visual effect that one simply sees and waits until it is finished. The user becomes a participant of the whole story and can decide upon the development of the sequence. This has a large amount of applications which give to animation systems a very important existence in life.

There are several animation software packages currently available in the market. They all have a different approach to animation but tend to work on the same principle. There is an interactive graphics interface where the drawing, paint and modeling takes place. An animation language takes care of the motion control and of any advanced animation that is required. Every language currently available requires different programming skills. However the more advanced a language is, the more enhanced the produced motion will be. The problem that arises here is that computer animators usually don't have strong programming experience since they mostly come from areas of traditional animation. There is not a single answer to this problem but the most satisfying one is that software should approach differently each user depending on the result that is required to produce.

.I 7
.T
document.7
.W
Become a CGI Artist: Job Description, Duties and Requirements
Research the requirements to become a CGI artist. Learn about the job description and duties, and read the step-by-step process to start a career in animation.

Should I Become a CGI Artist?
Computer-generated imagery (CGI) is the creation of still and moving images and visual effects using computer hardware and software. CGI artists create characters, environments, objects, special effects and locations, both real and imagined. Although CGI encompasses many specialties in computer graphics, 2-D and 3-D animation and special effects, the term is most often used to refer to 3-D animations created for television, video games and film.

Many multimedia artists and animators, including CGI artists, are self-employed and therefore must spend time finding work. Although they might work long hours to meet deadlines, they often work from home or other convenient locations.

Career Requirements
Degree Level	A bachelor's degree is common, but an artist with experience and technical proficiency can also enter the field
Degree Field(s)	Computer graphics, digital media, Web development, graphic design, fine arts
Experience	Up to 1 year for an entry-level position, at least 2 years for mid-level positions
Key Skills	Artistic ability, creativity, technical proficiency; graphics and video editing software such as Maya, Studio Max, Photoshop, Premier, Illustrator, Flash, After Effects and Final Cut Pro - Web design software and languages like HTML, CSS and Java; digital paper, digital pen, digital camera
Salary (May 2014)	$69,410 per year (Mean annual salary for all multimedia artists and animators)
Sources: U.S. Bureau of Labor Statistics, Monster.com job postings (July 2012), O*NET Online.

Step 1: Obtain a Degree
Degree programs are available for a wide variety of specialties, including game development, animation, and entertainment design, providing students with the opportunity to select programs closely aligned with their career goals. Students also have the opportunity to focus on the aesthetics of animation by enrolling in a fine arts degree program or on the more technical aspects by selecting a computer-related degree program. Many programs feature basic courses in graphic design, art and technology before branching off to offer specialized coursework. There are also limited degree options in CGI art, as a self-defined major.

Success Tips:

Choose a program carefully. Since there are so many sub-specialties in this field, students should carefully research degree programs to insure they select one providing coursework that aligns with their future goals.
Complete an internship. Many degree programs offer internships, which can provide on-the-job experience and networking opportunities.
Step 2: Build a Portfolio
Artists are expected to have a portfolio to show prospective employers. This is a collection of the artist's best works, showcasing his or her artistry and technical proficiency. Most degree programs require students to create a portfolio as part of their graduation requirements, but artists without a degree also need to have portfolio. Many employers require artists to submit portfolios on a CD or DVD or to provide website link.

Success Tips

Select portfolio pieces based on a potential employer's needs. Artists can tailor their portfolios to the positions for which they're applying to demonstrate their style and proficiency using the technology required by the job.
Limit the number and scope of pieces in your portfolio. The contents of a portfolio should be chosen with care and restraint to avoid overwhelming a potential employer with too much imagery or too many technical gimmicks.
Step 3: Gain Experience
Many positions require professional experience. New artists or graduates may have to accept assistant-level positions to obtain the necessary on-the-job experience to advance. This field also has many freelance opportunities available, allowing artists to commission CGI art for experience and a contract fee.

Success Tip

Volunteer locally. Volunteering to perform CGI work for schools or other nonprofit organizations can provide valuable experience. Additionally, cable access stations may seek volunteers to provide programming and production services, which can be included in an artist's portfolio.
Step 4: Complete Continuing Education Courses
Advancements in the technology used to create computer-generated imagery are incredibly dynamic. Having invested substantially in the technology, employers generally expect artists to have the technical skills and up-to-date product knowledge to maximize all the features present in software programs and hardware equipment. To stay competitive, artists can take continuing education courses offered by colleges or product vendors, including Apple, Autodesk and Adobe.

Education and experience can lead to advancement opportunities for a CGI artist. He or she may get promoted to a senior artist position, a review or editorial position, or may even lead projects. A degree and business acumen may lead to a supervisor or management position with a large enough company. Alternatively, with more experience and education, a CGI artist's skills will become more valuable on a freelance basis.
.I 70
.T
document.70
.W
7 types of computer animation software worth knowing
The animation industry has countless styles and demands in both the 2D and 3D industry each year. If you have a deep understanding of animation principles, then each piece of software can be viewed as merely a different tool for accomplishing what you need, but there’s no denying that each program has its own perks that are unique from the rest. Most animators will be challenged to learn whatever software their studio chooses, but if you have the option of picking your own, then this is a great place to start before making a choice.
FlipBook (DigiCel)

For creating 2D animation of any kind, Flash and FlipBook should be the very first two programs you consider. DigiCel’s FlipBook animation software does it all, from scanning to digital painting to mattes to lighting and any other novice or veteran trick you might need. While most companies boast their software is perfection one year, and then curiously have a long list of new features in their yearly update, FlipBook instead has remained mostly unchanged in 15 years because it already has everything it needs. If you’re a 2D animator who wants minimal computer involvement, then FlipBook is a must.

Flash (Adobe) 

If you want to make Web animations but don’t want to do it on paper and scan it all in, or if you’re an amateur who just wants to make something quick without having to tween frames yourself, or even if you’re a professional animation studio who wants to reach a large audience on the Web, then Flash is a great low budget easy solution with a lot of options. It’s rarely used to create films or long animations, but for something like a short commercial or public service announcement, it’s perfect. Google and other huge companies still use it from time to time when showcasing their new product releases. 

Blender (The Blender Foundation) 

Did you love Flash, but now need an “easy to learn and use” equivalent for 3D animation software? If so, then you should start here. Not only is it small and not processor demanding, but it’s also free and comes with a Web community that offers hundreds of free classes and tutorials on its site. It’s also been used to make award winning short films and has plenty of advanced features that are worth checking out. 

Poser (Smith Micro Software)

If your job is to just 3D model, skin, rig, scene light, texture, or any other 3D specialty, then you’re the unsung hero on AnimationCareerReview, and you have our staff’s respect! However, if you just exclusively want to work on animation, and showcase purely your animation skills, then why bother with the rest? If that describes you, then Poser should be high on your consideration list since it comes with a free library of base human and animal 3D meshes that will save you large amounts of time. Yes, it can do other things as well, but not as well as the others on this list.

3ds Max (Autodesk)

Arguably the iPhone equivalent of the 3D animation industry, it has been – and still is – impressively ubiquitous in all 3D markets, and is arguably still the king of the competition. There’s almost nothing it can’t do that any other software on the market can accomplish, and if you can afford its high price tag then you’ll definitely get your money’s worth.

Maya (Autodesk)

Even though Autodesk acquired Maya in 2005, they’re still in competition with one another, and slightly catered toward different needs. It depends on what person or studio you talk to, but often the answer you’ll get is that Maya is friendlier to animators’ specific needs than 3ds Max is, but they’re both still exceptional programs that everyone should consider. Chances are good that over the span of your career you’ll eventually need to learn both, so you may as well get a head start!

Cinema 4D (Maxon)

There are plenty of other animation software packages out there that compete with one another, but the one that stands out to me as gaining the most momentum in the past five years is Maxon’s Cinema 4D. It may not be as rampant in the 3D gaming industry, but it’s seen an abundance of use in the film industry for dozens of high budget box office hits, and because its popularity is newer by comparison, knowing it might give your career an edge as its demand rises.

.I 71
.T
document.71
.W
New CGI Method to Produce Ultra-Realistic Faces For Animated Games And Movies
IMPERIAL COLLEGE LONDON, LONDON, UK. A new technique to make Computer generated imagery (CGI) faces look even more realistic has been developed by a group of experts in the field. With the current CGI method being used to create faces, one can easily tell that it is nothing more than just animation. In fact, it gives you that creepy wax-looking feel just looking at CGI faces because their skin is just too perfect. Not to mention their lifeless facial expressions which are far from the real thing.

With the new method developed for CGI faces, you won’t be able to easily see tell if it’s real or not. It is because of the realistic illumination on the face which gives an ultra-realistic skin simulation. Of course, to make it look even more realistic, the developers made sure that they go down to the smallest facial details such as blemishes, pores, wrinkles, shadows and even bumps.

To make it happen, the group uses a special camera and lighting system. Every simulated light source is then split into four rays. Three rays penetrate the skin to different depths before being scattered while one ray is made to bounce off the epidermis. They also used a special scanner to take high-resolution images of human skin from volunteers’ cheeks, chins, and foreheads to use for various projects. The detailed scanned images of skin from the volunteers were then combined with simulated lighting technique which produced really impressive results.

The team is led by Abhijeet Ghosh of Imperial College London and Paul Debevec of the University of Southern California. They are expecting gaming and entertainment companies to show interest in their technology approach. In the future, the new method could also be useful for even more practical applications that would make a huge difference in the consumer market.
.I 72
.T
document.72
.W
Becoming a better animator: Q & A with Jason Ryan, iAnimate
You’d be forgiven if you thought that animating, supervising and directing at Walt Disney Feature Animation, DreamWorks and Cinesite would satisfy the cravings of any animator. But for industry veteran Jason Ryan, these accolades have only piqued his interest in the craft more and urged him to continue the learning process. Lucky for aspiring animators, Ryan channeled his impulse into the successful online animation school, iAnimate.
iAnimate’s certification courses allow students to select tracks in Feature Animation, Creature Animation and Game Animation. They can also choose from courses in rigging, mocap, lighting/compositing, modeling, and pre-visualization. Uniquely, every applicant submits a sampling of their work so that Ryan and crew can place the student in the workshop level that fits their current abilities or weaknesses. In addition to super small class sizes and access to a character library that would make your drool, iAnimate students also have access to the weekly demo instruction from Jason Ryan himself.

For our latest spotlight Q&A, we speak with Jason Ryan about his never-ending quest to become a better animator and how iAnimate offers his students a solid footing for a career in animation. We hope you enjoy!

ACR:  Jason Ryan, before we get into iAnimate, I’d like to start with you. Growing up in Ireland, when did you set your sights on a career in animation?

Jason Ryan: Art and animation really wasn’t on the scope for me growing up. I was training to become an accountant! In secondary school, I took art classes and my teacher encouraged me to pursue graphic design or illustration. I didn’t even know there was a future in that, to be honest. But I fell in love with drawing and at the end of secondary school, I planned on going into advertising. I applied to Dun Laoghaire Art College where Dave Brain (Disney Studios) looked at my portfolio and thought that because my drawings were very clean, I’d make a good animator. The rest is history.

ACR:  Were there elements missing from your animation education that you’ve tried to rectify in your career?

JR: I wish I had studied more live action reference. When I was studying animation, there were no websites or Youtube. Framing wasn’t done perfectly as it is now; it was done on VHS video or Betamax and you were pausing it and hopefully you didn’t have the lines going across the screen. I would pause through a video and see the squash and smear frame. I’d be taking notes to see how it was done, and then I’d try for myself. But I never motion captured or rotoscoped anything and I wish I had opened my mind toward that.

ACR:  Referencing in general is such a crucial tool of the animator which aspiring animators don’t always recognize at first.

JR:  Absolutely. Every week on iAnimate, i do a demo for two hours for students and recently I animated a four-legged character pacing back and forth to dialog. I had to really study how a real four-legged animal turns- what actually goes into that physical process. They lean this way, and glance that way, and this foot does a stretch which releases the other foot... it’s only through that process when I can see how it all works and and animate it.

ACR:  Those weekly two-hour tutorials are such a unique feature of iAnimate, where students get to see that even at veteran such as yourself never stops learning...

JR:  You hit it right on the head. I’m not trying to show off, but I’m trying to show that we’re just human and we push ourselves and are constantly learning. In the demos, I’m talking as I’m animating and explain what I’m doing as I go; sometimes it sounds like gibberish but my students get it because they’re watching and interacting in real time.

ACR:  Before you began iAnimate, you were offering frequent tutorials on your website. What was the impetus to jump beyond those popular offerings and found a full-fledged online school?

JR:  It’s all student driven. My Jason Ryan Animation Tutorials, which I started in 2007, were based on how I would have liked to have learned: by watching a veteran animator animate shots in front of me and watching frame by frame as they’re creating the animation. Then, the students wanted to ask questions so I started doing live webinars where I would animate live and they would type in questions and I would address them. Then, it evolved again because students wanted feedback on their work which I wasn’t sure how to do without actually talking to them. Email just wasn’t getting my explanations across. And that’s how iAnimate came to be.

ACR: Your students get very individualized attention from yourself and the veteran animators who teach your courses. And it’s all through a software system that makes it seamless and entirely virtual...

JR:  Right. Our instructors only have eight or nine students maximum, so that’s incredible. With the Zoom (web conferencing) software system we use, we’ve never had this type of real-time collaboration and instruction before. Being able to go through frame-by-frame without any sort of drag is awesome, and the students use their own speakers so the sound isn’t distorted. This gives us the ability to bring animation to places so remote that they wouldn’t have any chance of getting an animation education.

ACR:  Another great aspect of iAnimate is that it allows students to focus on certain areas that they feel they need to. Do most take all of the courses or just a few as they need them?

JR:  I think the ones that come in at the very beginning tend to go through to the end; the ones that come in later might just take a few courses. That’s the beautiful thing with iAnimate- I don’t want people coming in with a lot of experience and starting at the beginning. That makes no sense. They should move forward from where they are. In the basic courses, there are real beginner animators so if someone with experience comes in to those, they would get bored while the beginner animator might feel stupid and not ask the questions they should. I want people at roughly the same level so they grow together and ask questions and learn.

ACR:  So when someone applies to one of your courses, they submit a demo reel and you assess what level they’re at?

JR:  Exactly. Earlier on, their mechanics might need some work. Or maybe they need to work on locomotion. If their mechanics are killer but they have no acting experience, then Workshop 4 is for them. If they’re ready to put everything together in some juicy shots, Workshop 5. And Workshop 6 is when someone animates through cuts on a sequence for a feature film and it’s really showreel polish… they have their training but now they need to work on shots to get hired. You’re always judged on your weakest shot in your showreel.  Everything has to be at the very top level.

ACR:  Being critiqued is another important element that iAnimate offers thanks to its virtual classrooms. How do you help new animators leverage critique to their benefit?

JR:  The first thing I tell them is that they have to be their own worst enemy critiquing their own work. We are all blind to our own work but easily spot mistakes in other people’s work. It’s difficult to get over the ego and accept the help. No one is out to thrash your work, they’re just trying to make it better. That’s really important because at iAnimate, we try to make them the best animators they can be. If I take away their idea in favor of my own idea during a critique, they’ll stop coming up with their own ideas. Instead, I try to encourage them to come up with their best idea. Then, I can look at two versions they came up with and give them feedback.

ACR:  Animation as an industry is constantly evolving. How do you prepare students for the inevitable changes they’ll face in their careers?

JR:  A lot of people ask me about what to do on their showreel in order to be marketable. I tell them to do as many different styles as possible. DreamWorks is naturalistic, whereas Sony is more cartoony. Disney is somewhere in the middle with a stylized way of moving. So they need to cover all these styles and be open to them to adapt. Some students aren’t necessarily into the cartoony stuff, but they need to learn it to get their brain working in new ways and find little sparks. You have to be open to new things and own up to your weaknesses.

I’ve done a lot of complicated body mechanic type shots throughout my career, but I haven’t done a lot of really, really subtle acting shots so I try to get those assignments and work on my weakness. I want to do more assignments myself to be a better animator. Hopefully, I’m inspiring students to do the same thing- I want them to love what they do and not be fearful of it. The more time you put into this craft, the more you’ll get out of it.

ACR:  Last but not least Jason, what’s on the horizon for iAnimate that we can look forward to?

JR:  I’d love to get in some of the 2D resources like layout and storyboarding and even honing our artistic side. A lot of people don’t like to draw so doing drawing classes would be great. My ultimate dream for iAnimate is to do commercial work with students; so if someone has a product, we would do the modeling and rigging and layout and previews and send it through all the way into lighting and compositing. Right now, I am hiring my own students to work on feature films for Cinesite Studios and about half my crew are from iAnimate. I know they’re going to hit the ground running because I’ve trained them!
.I 73
.T
document.73
.W
The use of animation in digital digital marketing

It’s pretty clear from the buzz around them that this is the year of the web video. You’ve probably seen statistics claiming as much. According to YouTube’s vice president of global content, video will soon account for 90% of Internet traffic. Videos in emails can increase the open rates by 6%, and Forrester found that video increased email click-through rates 2-3 times. Videos in universal search results have a 41% higher click-through rate than plain text results.

And that’s just the tip of the statistical iceberg! comScore, Econsultancy, TechCrunch, and Mashable all keep tabs on these amazing web video statistics – it’s well worth seeking out some of these statistics and reports to see just how staggering the results really are.

Given all of these phenomenal web video statistics continuously released, it seems odd that animation is yet to receive much attention, especially when some of the biggest companies across the world are using animation in their digital marketing.

In this blog post, I am going to highlight a few of the big companies using animation in their digital marketing and how animation can be a highly effective method of getting key messages across to target audiences.

Animation and apps go hand in hand

GE recently released a series of animations promoting a health related Facebook application. In this blog post, I am going to highlight a few of the big companies using animation in their digital marketing and how animation can be a highly effective method of getting key messages across to target audiences.
It’s important to think of interesting ways to visualize online activities, to direct traffic to your social networks or to get people to download an app. Instead of using screenshots and footage of someone using a computer, GE made these short promotional animations. A lot of animations that pop up online are used to promote apps or products and services that can’t really be explained by using live footage. Let’s use Spotify as an example. Their quirky house style can be seen across all of their animated promotional videos – of which they have many. In the Spotify player there are animated banners featuring the same characters from these ads. Take a look at their 2011 video showing how Facebook integrates with the Spotify player.
Because they already have a great aesthetic going with their branding – the quirky hand drawn effect – the illustrators simply applied this style to the screen shots of Facebook. These animations appear on their YouTube channel in various languages as the company expands across the globe.

Cloud Computing and Animation

Salesforce use animation in their digital marketing to great effect. They have a whole host of amazing web videos that explain their various products and it all started with an introductory video that explained the basics of cloud computing.
In fact, cloud computing is one of the most animated subjects in the web video world. Amazon and Google both have animated web videos that explain their individual “clouds”.

Google have a great portfolio of web videos in general, but the most recent addition to their web video artillery is a great animation explaining their fiber optic broadband network.

Animation adds an exciting and engaging element to demonstrations of how these products are going to work and how they can benefit the viewer. Animation provides a far more interesting way to showcase information about these often complex ideas.

Amazing antipodean animation

Let’s take a quick detour for a moment. We’ll head down under and discuss what an antipodean airline is doing with social, animation and web videos.

If you’ve never flown with Air New Zealand before, you’re missing out. The Kiwi airline is well known for their lighthearted safety videos. Over the past couple of years, their safety videos have included eighties aerobics instructors, rugby players, puppets, body painted flight attendants and this year, animated celebrities.
The sketch animation blurs the line between educating passengers about the safety procedures and just being downright entertaining – and handily doubles as online PR. They give insight into the overall brand that Air New Zealand strives towards: a jokey, upbeat vibe that embodies the Kiwi spirit itself.

Within a month, the video has already had over a million views on YouTube. Combined, Air NZ’s online and offline presence has resulted in its place amongst the top 10 of the most successful airlines in social media. That’s pretty impressive for a country pushing a population of 4.5 million. They are the sixth largest airline for social media presence in the world.

A small airline creating safety videos that will double as marketing fodder, go viral and enhance their social media presence – clever, isn’t it?

What does it all mean?

Web-based companies are cleverly using animation to explain their services and showcase their individual personalities. They’re also really effective fodder for digital marketing – Salesforce’s cloud computing animation is the first result in a YouTube search about “cloud computing”, which just goes to show the strength of the animation.

This medium is a way to animate things that are otherwise inanimate. Sure it’s been done before – just look at any Disney movie. But animation to promote products and services in an engaging manner, that’s where things start to get really interesting.

The Air NZ safety video just goes to show that animation can be the perfect way to give a new spin to something that can be a struggle to get people to connect to. The forward thinking company not only has a great animated video but they also knew they could use the video across their digital marketing.

The advantage of using animation is that it’s not only easier to explain concepts with, but animation can show off the flair of a company. Animation is creative, it’s entertaining and it’s fun.

Summary

So in summary, the potential benefits of animation in digital marketing include:

They can help get across complex (and often uninteresting messages) in a fun, engaging manner, especially when compared to relying solely on text to communicate the same message.
They can significantly boast the conversion rates of websites and e-marketing campaigns.
They can help directly generate traffic by getting indexed in search engines such as Google and YouTube.
They can help create a memorable brand identity.
In addition, animated web videos can potentially help enhance organic rankings by improving analytics, reducing its bounce rate, and increasing the average visitor time spent on it. Improving such measures causes Google to view the associated website as being more relevant for the related search phrases which can have a positive impact on its search rankings.
.I 74
.T
document.74
.W
Animation and Multimedia
The ability to combine moving images, graphics, text, and sound in meaningful ways is one of most powerful aspects of computer technology. A dynamic and technically accurate presentation is helpful in making the message not only understood but effective. At Exponent, we combine our engineering and scientific expertise with cutting-edge artistic talent to create visually compelling and technically accurate presentations for industrial and legal applications. We work closely in teams to produce technically precise, 2D and 3D animations and other multimedia. We consult with clients throughout production, and our work has been shown throughout the world and has been the subject of numerous feature broadcasts on network and cable television.

Animation

Animation is the creation of artificial moving images to replicate an event. Dramatic events sometimes happen in the blink of an eye. But a single picture or graphic doesn’t always convey that moment adequately. We use computer animation to help viewers understand a single moment, as well as to see how things change over time. Two- and three-dimensional models allow the scene to be recreated from various viewpoints, including those of eyewitnesses and participants, and also from overhead perspectives. Using state-of-the-art animation software, we can reproduce real-world phenomena such as fire, smoke, and fluids. Our professionals are specialists in modeling, lighting, materials creation, and animation. Working from sketches, photos, or engineering drawings, we create accurate, realistic models of objects and subjects, from a simple part to complex machines and environments. We have developed animations to illustrate fine points of mechanical or electrical design, reenact a fire at a large manufacturing facility, and illustrate the movement of chemicals through the air and ground, and even through the respiratory system. Our experience includes projects for the Internet, interactive CD-ROMs, marketing and business presentations, and for use in courts of law around the country. Our animations have stood the scrutiny of the legal system and have been presented to mass audiences through cable television programs around the world. 

Multimedia 

Many clients choose multimedia to explain technical issues. Multimedia uses a navigational approach to accessing data, allowing one to display video, animation, graphics, drawings, documents, and still images as needed during a presentation or testimony. This technology helps our clients organize and retrieve documents, share information, and graphically present information in a more understandable and persuasive manner. Our Visual Communication group works to reduce client costs by creating effective presentations using state-of-the-art tools such as Flash-based interfaces and software such as Adobe Director® and Microsoft PowerPoint®. We also use technologies such as extranets to allow clients to review and discuss our work, so that our staff can provide the most cost-effective and timely presentation of materials under development.
3D Visuals 

Exponent provides its clients with accurate, cutting edge, and compelling 3D visuals. The latest software tools are used by Exponent’s experienced Visual Communications staff, working side by side with our engineers and scientists, to produce 3D visuals with solid engineering foundations as well as the visual clarity needed to illustrate situations in clear, concise ways. Our staff has many years of experience in all aspects of 3D production, including modeling, texturing, lighting, and animation. 

Ability to import/export a wide range of file types, including .dwg, .dxf, .3ds, .obj, .stl, and .iges 
Ability to assist engineers in analyzing and conceptualizing objects in 3D space 
Ability to create 3D models, using photogrammetry tools and blueprints 
Simulation of real-world elements (e.g., fire, liquid, smoke, particles) 
Specialists in realistic texturing, lighting, and rendering
Illustrations
The Visual Communication staff can produce a wide range of visuals, from elaborate 3D animations to charts and graphs. Sometimes budgets or projects do not warrant the use of 3D imagery. For many situations, 2D line-art illustrations are very effective. They are clear and easy to understand, yet can illustrate complicated issues and interactions. Line-art visuals are a versatile solution that can be used within PowerPoint® presentations, and can be blown up for use as court boards. 

2D Animation and Flash

Yet another use for 2D visuals is 2D animation. Flash interactive modules and animations use 2D art to demonstrate a sequence of events or a process in a very clear manner. This is a very effective way to show complex interactions or events. 2D animations are usually less expensive than 3D projects, yet in some cases, provide a better visual description. Flash interactivity provides an interface that allows control over the animation’s timing and display. This has proven to be an effective tool for educating an audience.

Match Moving

Another aspect of Exponent’s video capabilities is 3D Match Moving. This is the process of a camera matching actual video footage to a 3D environment of the scene. By creating a 3D scene based on actual survey data, and camera-matching that scene to video footage taken at the scene, we can insert computer generated elements onto the video to accurately re-create what the scene or event looked like. Signage is gone now? We can replace it as it was. Need to show an accident or event in the exact surroundings and circumstances? Match moving allows us to do just that. Remember the scene in Jurassic Park when the T-Rex chased the Jeep? That is an example of using Match Moving to insert a computer-generated character (T-Rex) into dynamic actual footage. We provide the same service but with an engineering foundation to ensure accuracy. 
.I 75
.T
document.75
.W
History of animation
Looking at the past and the present, animation has evolved over time. It started with pieces of
paper and rope in 1828 and is today 3D animation videos. In this section, we will list the
chronological order of the development of animation and animation devices which have evolved
and improved over the past two centuries. We have also included the most famous animation
characters in the history of animation.
Thaumatrope
A thaumatrope (invented by Paul Roget in 1828) is a simple mechanical toy which creates
the illusion of movement. Thaumatrope means “wonder turner” derived from the Greek words:
θαῦμα “wonder” and τρόπος “turn”. Roget was the first person in history to create such a device
which produces the illusion of movement. In order to enjoy this animation, one would only need
one small round piece of paper with pictures on it and thin ropes fixed at both ends of the shape
(Figure 1). Below shows what a thaumatrope (Figure 1) is and how the illusion of movement is
produced (Figure 2).
Phenakistoscope
After the invention of the thaumatrope, the phenakistoscope followed made possible by
J.A. Ferdinand Plateau in 1832. This device uses the persistence of vision principle to create an
illusion of movement. Phenakistoscope originated from the Greek φενακίζειν (phenakizein),
meaning "to trick or cheat"; as it tricks the eye by making the figures in the pictures appear to
move. It is composed of six similar images in different positions taken in order to relay the
movement. A very simple example is a running reindeer and jumping frogs (Figure 3).
Zoetrope 
In 1843, William Horner, a British mathematician invented the zoetrope. A zoetrope
produces an illusion of movement from a rapid succession of static pictures. Derived from the
Greek words ζωήzoe, "life" and τρόπος tropos, "turn" this forms a “wheel of life”.
Praxinoscope
Almost the same as a zoetrope, the only difference was the integration of a mirror to the
device which makes the viewer more comfortable as they watch the movement of the objects. It
was designed by Emile Reynaud in 1877 and was known as the “action viewer”.
Kinestoscope
An early motion picture exhibition device was invented in 1888 by Thomas Edison
together with his colleague Eadweard Muybridge. The kinestoscope was designed for films to be
viewed through the window of a cabinet (Figure 6). Kinestoscope means the “view of
movement” from the Greek words κίνησις “movement” and σκοπός “movement”.
Multiplane Camera and Storyboard 
Walt Disney and his colleagues had a problem with creating realistic animation and how
to conserve time while creating it. Then they came up with a great solution which can be
considered another innovation in the field of animation - the multiplane camera (Figure 12).
The multiplane camera is a piece of equipment designed to make cartoons more realistic and
enjoyable. It uses stacked panes of glass each with different elements of the animation
(Figure 13). With this, it allowed for the reuse of backgrounds, foregrounds, or any elements
not in motion. The multiplane camera was developed by a Walt Disney Productions team
headed by William Garity in the early 1930s. It was also known as the “super cartoon
camera”.
The storyboard was yet another successful creation in animation technology. It is used to
recheck the story and utilizes pencil sketches to review motion.
Next we will discuss the first ever animated films together with some of the most famous
and successful animation characters. Outstanding works in stop motion and clay motion are
also elucidated, followed by a discussion of computer graphics and computer animation, i.e.,
3D animation.
Humorous Phases of Funny Faces
After the invention of the above-mentioned devices, J. Stuart Blackton made the first
animated film in 1906. The film was entitled Humorous Phases of Funny Faces, and with
this he became known as the father of animation. He was using a blackboard as his
workplace together with chalk and an eraser as his main tools. He was able to record the
animation using the “draw-stop-film-erase” method. 
The Birth of Cartoon Characters
The creation of the first ever animated film also inspired many animators to create their
own animations. For instance, Winsor McCay drew Gertie, the trained dinosaur (Figure 8).
It was an animated film astonishingly consisting of 10,000 drawings. The animation was
shown as a film in theatres as well as at a multimedia event on stage with McCay interacting
with the animated Gertie. Next in line was Felix the Cat (Figure 9). During the early 1920s,
he became the most famous animated character. Then who could forget Mickey Mouse?
(Figure 10). Mickey Mouse was created on November 18, 1928 and with his creation came
the first successful sound animated film. Mickey Mouse was originally known as Steamboat
Willie (Figure 11). He became an international star and made way for the launch of Disney
Studios. Lastly, Looney Tunes was introduced in 1930 by Hugh Harman and Rudolp Ising
run by the Warner Bros. Company. Bugs Bunny, Daffy Duck, Tweety Bird and Silvester are
just a few of the main characters in this cartoon.
Stop Motion and Claymation
Stop motion animation is used to animate things that are smaller than life size. Willis
Harold O’Brian pioneered motion picture special effects, which were perfected in stop
motion. He became famous after his successful work on King Kong (Figure 14), claiming the
title Dean of Stop-action Animation. Ray Harryhausen followed in the footsteps of O’Brian
and became one of the most outstanding stop motion film makers through his films Mighty
Joe Young and The Lost World (Figure 15).
On the other hand, claymation also became a trend. Technically, it is the art of moulding
clay figures and making them move, dance, talk, sing and whatever you can think of. Frames 
are run together to produce the animation. Chicken Run and Wallace & Grommit are the two
most successful claymations created by Aarmand Studios of the United Kingdom
Computer Animation 
When it comes to new forms of animation, firstly let us define traditional animation - a
system of animating in which the illusion of movement is presented by photographing a
sequence of individual drawings on consecutive frames of film. On the other hand, computer
animation is a form of pictorial presentation which refers to simulated motion pictures
showing movement of drawn objects.
Computer Graphics and 3D Animation
This is where graphics are created using computers and the illustration of image data by a
computer particularly with the help of respective graphic hardware and software such as
Superpaint. It is used to replace physical models then create realistic intermixed elements
with the live action. 3D animation is today’s animation. By using some sophisticated
software and looking at the Principles of Traditional Animation Applied to 3D Animation
concept, animators are able to produce outstanding and aesthetic animations such as, Toy
Story, Madagascar, Megamind, etc.
.I 76
.T
document.76
.W
Have computer generated images changed the meaning of cinematography
In the past four years, the Academy Award for best achievement in cinematography has gone to a film with heavy amounts of computer-generated-imagery three times. In 2009, Avatar took the top prize in cinematography, followed by Hugo and Life of Pi in 2011 and 2012 respectively. These films, while visually stunning in every sense of the phrase, don't necessarily conform to the traditional definition of cinematography because much of the time the lighting, composition, and camera movement are created digitally by a group of compositors. This begs the question, should there be a distinction between traditionally-shot films and digitally crafted ones? Or has the definition of cinematography changed as digital technology has become more prevalent?

There are certainly a couple of different sides to this question. In one sense, it's an entirely technical matter. Films like Gravity and Ain't Them Bodies Saints were created in two vastly different ways, and therefore it would be silly to judge their images by the same standards. On the other hand, however, it can be argued that the method and technology don't particularly matter as long as the images have the same effect on an audience. Let's take a more in-depth look at these two sides of the cinematographic debate of the decade.

It's Purely Technical
In modern filmmaking, there are two basic methodologies which  pervade the cinematographic landscape. The first, and more common (especially in independent film), is one in which the images are created in a physical environment such as a set or on location. This method is one that we talk about frequently here at No Film School, as it's all about composition, physical camera movement, and lighting with physical fixtures. Being able to competently create meaningful images in this way is not only the traditional definition and method of cinematography, but it's a unique technical (and artistic) skill that requires of the DP an in-depth knowledge of many different technological facets and processes.

As an example of this first type of cinematography, here's the trailer for Ain't Them Bodies Saints, which was shot practically (and quite beautifully) by Bradford Young on celluloid:
The other methodology of modern cinematography is one in which the images are created digitally through compositing various elements and pieces of footage together in order to create the final image. This method often uses green and blue screen keying (which is a tremendous technical skill of its own) as the basis of the image. While the characters are lit and framed by the cinematographer on the set, these decisions are often unrecognizable after the digital effects team has finished with the footage. In these cases, much of the lighting and composition actually happens in a computer.

As a prime example of this type of filmmaking, here's the trailer for Gravity (just in case we haven't shown it enough times already).
Both Gravity and Ain't Them Bodies Saints are stunningly gorgeous films, but their respective methods of image capture and manipulation are so vastly different that it seems borderline ludicrous to judge them by the same standards. In these cases, the vast differences in the cinematographic method absolutely demand that the Academy (as well as other motion picture institutions) create two separate distinctions in the craft. For the sake of this article we'll call those distinctions "Traditional Cinematography" and "Virtual Cinematography."

Of course, in modern filmmaking, most cinematography exists somewhere in the middle of these two sides. Even films that are shot practically are rife with extremely subtle digital effects. Conversely, films that are heavily reliant on compositing often have scenes that are shot practically with a minimum of digital effects. In order for traditional and virtual cinematography to exist independently of each other, there needs to be a line drawn between the two. Where that line exists, however, is a question for another day.
Does Method Matter?
Around the time that Gravity was released, we talked extensively about the role that famed cinematographer Emmanuel Lubezki played in creating the stunning images in that film. Not surprisingly, he was present in every stage of the process, and was largely responsible for all of the digital lighting and composition. Even though he had captured the characters and created stunning camera moves on the set, he remained present in the entirely effects/compositing-driven post production process in order to ensure that the images maintained his unique cinematic touch.

This begs another question. Does the method of cinematography actually matter if the end results are used to affect audiences in the same way that traditional cinematography would? Whether or not the image is created on location, on a set, or with a computer, cinematography is used for the same purpose, to drive the story and to convey/strengthen the emotionality of the characters in the film. Even in a computer, the core concepts remain the same. You have camera and light, and it's the manipulation of these elements which creates the cinematography, not the method of manipulation.

Here are two examples of westerns that were shot with these different methodologies. The first, The Assassination of Jesse James by the Coward Robert Ford, was shot practically by none other than Roger Deakins. The second is The Lone Ranger, and it was shot by Bojan Bazelli.
This is a bit like comparing apples to french fries, as these two films couldn't possibly be more different. One is a subtle character drama and the other is a big-budget action flick. However, in terms of cinematography, it can be argued that the aesthetics of these films, though created in two vastly different ways, accomplish the explicit purpose of the craft in that they drive the story and tell us about the characters.

Personally, I think method does matter and that we need to create a distinction between traditional and virtual cinematography. However, a strong case can be made that technology is simply changing the definition of cinematography and that the core principles remain intact. For a little bit of extra reading on this debate, as well as a solid read about digital distribution, head on over to Indiewire and check out this fantastic article by Jamie Stuart.

What do you guys think? Should we separate traditionally created images from digitally created ones? Or is that a pedantic distinction given that the end result is the same? Let us know down in the comments!
.I 77
.T
document.77
.W
Computer generated images influence trial results
Recent cases involving the use of computer generated images as evidence in courtrooms have shown the powerful impact they can have on jury decision making. But studies show that jurors can be unduly influenced by these images and videos.

The case over the murder of British student Meredith Kercher is a particularly high-profile example that highlights the way in which computer-generated exhibits can be used to “fit” the evidence. The successful appeal of Amanda Knox and her co-defendant Raffaele Sollecito called the validity of the graphic animated sequence used in the trial into question since it was based on flawed forensic evidence in the first place. The case showed the importance of having reliable forensic evidence to support the content of an animation before deciding to use it in a trial.

What are the rules here?

One of the surprising issues to arise in debates on the admissibility of computer generated exhibits is that there are very few formal guidelines on appearance, content and style. In the US, where they are more frequently used, standards set a range of guidelines for the acceptance of expert, technical and scientific evidence. However, even in the US, the judge generally decides what is and isn’t admissible. This means that there is substantial variability in the acceptance of computer-generated material at trial.

This raises a number of concerns. I have demonstrated that by manipulating often minute and discrete variables in these images and videos that they can exert wildly different results. This suggests that the variation in presentation styles and technology used will undoubtedly create problems for jurors and other legal decision makers.

Easily swayed

Alongside the ambiguity over the legal standards of animated evidence, there has been relatively little empirical examination of the potential impact using evidence of this kind might have on trial results when compared to other ways of offering evidence to a jury.

One early experimental study, presented participants with a number of hypothetical scenarios based around an equivocal suicide. The overall premise under investigation was whether the deceased had fallen or jumped from a roof of a building. This was established by looking at the distance of the body from the edge of the building. If the body was found at between five and ten feet, it is more likely the person might have slipped and fallen. A longer distance of around 20-25 feet would suggest they had jumped.

Participants were shown computer-generated images that either supported or contradicted the premise that the deceased had fallen. They either showed the body as landing near or far away from the building. Of most concern in this case was the fact that a significant number of participants believed that a falling object – in this case a human who had fallen – could land 20-25 feet from a building when the computer-generated evidence suggested that this is what had happened. Ultimately, this led to the suggestion that people are poor intuitive physicists and easily influenced by computer generated images.

The study did also show, however, that when the physical evidence was congruent with the animated sequence, the video evidence served to improve juror decision accuracy. This implies that, when used correctly, animated evidence can be useful.

Depends which way you look at it

There is also evidence that juries might react differently to animated evidence depending on the perspective from which it is presented.

In my own research, manipulating the “angle of view” in an animated vehicle accident demonstrated stark differences in culpability judgements. When participants were presented with an animation of a car crash that depicted the situation from overhead, they were more likely to conclude that the driver of one car was at fault. If the animation was presented with an in-car perspective, they appeared more likely to conclude the other driver was at fault.
With more sophisticated VR evidence – where jurors can take on an interactive “first-person” role – understanding the potential psychological impact of this technology is vitally important to ensure fairness and proportionality.

Lessons to learn

At a basic level, jurors and other legal decision makers must be made aware that these exhibits are merely a representation of one potential sequence of events. Clearly, the vivid and easily compressible nature of these demonstrations can be linked to hypothesised models of jury decision making and could – in some circumstances – encroach upon the ultimate issue and extend beyond their intended probative value.

Psychological theories and research methodologies have a great deal to offer the courts and legal profession in relation to CGE. Just as it seems incredible that we would have once put a child witness in a courtroom or introduced relatively unqualified “experts” to offer advice, so it may also be that we allowed sophisticated techniques of persuasion to form part of legal trials without any real safeguards or guidelines in place.
.I 78
.T
document.78
.W
FdSc 3D Computer Generated Imagery
In brief... 
Computer Generated Imagery (CGI) provides significant cultural and economic contribution to the UK through games, films, TV, advertising and visualisation, and these companies are always looking for new talent. Graduates from these courses can have exciting opportunities to work on the highest grossing films and games, the funniest and cleverest adverts and some of the most creative commercial artwork around at the moment.

In 2015, Bournemouth was recognised as the fastest growing digital economy in the UK, making Bournemouth & Poole College a great place to study CGI. Our 3D CGI programme has been training students and preparing them for industry for more than a decade.

We offer two main pathways: Modelling & Animation and Architectural Visualisation. Whichever pathway you enrol on the first year is generic to provide a solid base of 3D skills and you don’t need any previous experience of 3D.
Who is it for? 
Modelling & Animation is geared primarily towards character-based industries such as games, films and advertising. It includes character and prop modelling, texturing, lighting, animation, rendering and post-production and as such provides a good set of generalist skills to allow you to have the best chance of working in your dream industry. 
What courses can I do after this? 
With a Foundation Degree in Modelling & Animation and a good portfolio, graduates will typically find junior positions in VFX companies, games companies and CGI boutiques in the UK and abroad. However, your progression opportunities are increased by continuing with our BSc top-up programme which is one year with an optional placement year in industry. Many students who take placements are invited back on a permanent basis after graduating from the BSc top-up.

What jobs can I get? 
Our graduates work in over 100 different companies including many of the big games, animation and VFX studios such as Blue Zoo, Climax Studios, Codemasters, Double Negative, Exient, Framestore, Jellyfish, Lionhead Studios, MPC, Prime Focus, Rocksteady, Sony Computer Entertainment Europe and The Mill.
.I 79
.T
document.79
.W
Fabricating fabric
FILMS like “Captain America”, “Tron Legacy” and “The Curious Case of Benjamin Button” have shown that it is possible to use computer-generated imagery (CGI) to make actors look younger, older or wimpier than they actually are, in a surprisingly realistic manner. At least, it is possible if those altered actors are kept at a suitable distance from the viewer. The difficulty of recreating the textures of both skin and fabric means the effect is less convincing when seen close up.

The reason is that, whereas it is possible to simulate realistically the forces which make virtual skin and fabric hang, bend, flap and stretch, recreating the subtle ways they reflect light has so far proved extremely tricky. The shimmer and sheen of both fabric and skin depend on the geometry of their internal structures—the exact arrangement of threads or protein fibres. This is hard to model accurately. Steve Marschner and his colleagues at Cornell University have, though, come up with a way to get round that problem. Instead of modelling, they are copying. They are using computerised tomography (CT) to analyse the structures of fabrics at high resolution and then plugging the results into CGI. That, allied to the laws of optics and some heavy-duty computer power, seems to do the trick.
Computerised tomography is most familiar as a medical technique for examining people's insides. Like classical radiology it uses X-rays. But because the image is constructed inside a computer using shots taken from many different directions, rather than being a single exposure recorded on photographic film, CT can capture fine detail and record soft tissues that are invisible to classical radiology.

Dr Marschner and his colleagues used a benchtop version of CT, developed for looking at the structure of materials rather than at human bodies, for their experiment. Employing doses of X-rays many times stronger than those used to study people, they obtained high-resolution information about small pieces of fabric. Computerised tomography allows the three-dimensional structure of the fibres in such scraps to be recorded, with all their kinks and imperfections. A number of small pieces can then be patched together into an entire garment inside a computer, in the same way that a handful of actors are turned into a CGI crowd. But because the internal structure of each bit of the garment matches that of a real piece of cloth, the way light will play on it can be calculated far more realistically than if it were just a computer model of what the interior of cloth is thought to look like.

Demonstrating the results of their technique at the SIGGRAPH computer-graphics conference in Vancouver this week, Dr Marschner and his colleagues showed realistic renderings of felt, gaberdine, silk and velvet. Moreover, their renderings remain realistic even when viewed close up. Sadly, skin is still beyond them. The high intensity of the X-rays involved would be too damaging for use on a living human being, and a corpse would probably not produce the right results. But once the rendering technique has been speeded up (at the moment it is still a bit slow and clunky), the swish of a virtual cloak or the doffing of a computerised hat should look far more realistic than it does now.

In the meantime, according to Dr Marschner's colleague Kavita Bala, the technology might have an application in online retailing. At the moment, people buying clothes over the internet have only standard photographs to help them choose their purchases. Using CT-based computer graphics might, paradoxically, give a better idea of what the material an item of clothing is made from is really like than can be garnered from a boring, old photograph of the original.
.I 8
.T
document.8
.W
Get Movin’ With a Career in 3D Animation

	
What is 3D Animation?

Sometimes referred to as 3D CGI, 3D animation is a type of animation that uses computer generated images to create animated scenes. Compared to 2D animation, or traditional animation, 3D has much more depth, and it looks much more realistic.

An animated scene starts with one picture, which is referred to a frame. The next frame is a picture that is slightly advanced a few milliseconds in time. After hundreds or thousands of these frames are flashed on a screen in rapid succession, they give the illusion of a moving picture.

The majority of the animated feature movies and short animated skits today are created with 3D animation, and this is a rapidly growing industry.

What Does a 3D Animator Do?

A career in 3D animation involves creating 3D moving images using computer software. These images are made with the use of digital models. After the models have been created, details are added, like hair, clothing, skin, grass, trees, and any other item that completes a scene.

The types of animations that 3D animators create can vary. Some 3D animators create long feature movies, for instance. Others may create shorter animations, like short skits, which can be used for advertisements or website animations. Some 3D animators specialize in creating animations for video games, and others create special effects for live action motion pictures.

Depending on an animator’s area of expertise, he might also specialize in creating different aspects of an animation. For instance, one animator may create animated people, while others will help complete the background animation, like landscapes and buildings.

3D animators also work with several different people when creating an animated scene. For instance, they will often work with writers and directors. They must also coordinate the animated action with voice actors and music directors.

What is the Annual Salary for a 3D Animator?

3D animation is one of the fastest growing careers. Since most animated scenes are now created with this type of technology, the demand for this type of technical knowledge is increasing. The average salary for 3D animators reflects this.

According to the U.S. Bureau of Labor Statistics, 3D animators made roughly a median salary of $58,510 annually. Some more successful  (top 90+ percentile) 3D animators have the capacity to make over $100,000 each year depending on industry working in and state living within.

What are the Education Requirements For a Career in 3D Animation?

3D animation is a technical career that requires specialized knowledge. Because of this, individuals looking to break into a career in 3D animation usually need to complete at least four years of post-secondary education. Some animators may further their education even more and earn a master’s degree in 3D animation. Research animation schools  and online animation programs today.

To earn a degree in this area, students will usually need to take a combination of art and computer courses, as well as courses in anatomy and natural sciences.

Learn more about how to become a 3D Animator.

What Can I do With a Degree in 3D Animation?

Students who have earned degrees in 3D animation are sometimes hired by large animation studios. These studios may create feature length movies or short animated scenes, which can be used for advertising or website design.

Individuals interested in a career in 3D animation may also want to consider aiding in the creation of video games. This rapidly growing industry uses 3D animation in order to create graphics and moving images while creating console or computer video games.
.I 80
.T
document.80
.W
 Ever since Jurassic Park hit the theatres worldwide nearly two decades ago, we had been ushered into a new world of make believe stuffs coming into life before our eyes. Then a lot of highly successful films like the Titanic, Avatar and hundreds more followed we could barely remember. The downside was that whenever a low budgeted film comes to theatres to persuade us of an interesting sci-fi plot, we are annoyed when we realize some clumsy, makeshift props are employed leaving us in disgust that we couldn’t remain seated inside the theatres until the movie ends. The magic of film making was revolutionized by the introduction of computers which in turn brought us Computer Graphics Imagery (CGI).
1. Computer Graphics Imagery (CGI) as defined is the utilization of computer graphics particularly 3D graphics to attain special effects in films. Its early use started in 1973 with a technothriller film “Westworld”, written and directed by Michael Crichton.

2. In 1976, Edwin Catmull and Fred Parke of the University of Utah created a computer generated hand and face which was featured on Westworld’s sequel “Futureworld”.
3. George Lucas’ space epic brainchild “Star Wars” in 1977 was the third film on the evolution of CGI technology which featured wireframe Death Star and targeting computers on the X-Wings spaceships used in the film.
5. In 1982, another two films “Star Trek II: The Wrath of Khan” and “Tron” were produced which advanced further CGI developments in film making.
6. “Tron” (1982) and “The Last Starfighter” (1984) were the first two films to make a solid 3D use of CGI. In “Tron” a hacker was figured into a world of computer where a gladiator-like game is being played in a circuit like surface. “The Last Starfighter” tells about a videogaming boy recruited by a visitor from a galaxy being invaded by aliens requesting to put his gaming skills to the test as that galaxy’s only hope against total annihilation.
7. The film “The Abyss” in 1989 with Mary Elizabeth Mastrantonio and Ed Harris who were on a deep sea quest to search for a missing nuclear submarine and coincidentally met a colony of deep sea aliens featured photo realistic CGI adapted into scenes.
8. The 1991 film “Terminator 2: Judgment Day” featuring the T-1000 cyborg with shapeshifting capability played by Robert Patrick utilized heavy use of CGI followed by “Beauty and the Beast” which both earned recognition. The former won an Oscar for Best Visual Effects and the latter became the first animated film nominated for Best Picture.
9. The 1993 release of “Jurassic Park” featured CGI dinosaurs synchronized with hydraulically controlled life-sized puppets. What happened next is history as we see how realistically dinosaurs came into life before our eyes.
10. The 1995 success of the first fully computer-generated animated film, “Toy Story” signalled the start of a new era in film making. Film production companies realized the necessity that enabled each to establish their own film studios dedicated to carry out CGI enhancements in films. Thus we learned of “CGI armed” studios like Pixar (Disney), Blue Sky Studios (20th Century Fox), DNA Productions (Paramount and Warner Bros), Sony Pictures Animation (Columbia Pictures) and Dreamworks SKG (founded by the trio of Steven Spielberg, Jeffrey Katzenberg and David Geffen).
.I 81
.T
document.81
.W
Computer Generated Imagery
Introduction

Computer-generated imagery or CGI is an area of digital visualization practices that, following its emergence in the late 1960s, quickly came to hold a privileged relationship to film production —affecting in particular animation, special effects, and the big-budget blockbuster. In these areas, digital imaging is consistently pushed to its limits by an ever-advancing state of the art. In a view promoted by the industry through plentiful “making-of” coverage, CGI is strongly identified in the popular imagination with spectacular special effects, demonstrating Hollywood’s prowess at realizing fantastic visions. But CGI plays a more significant if quieter role in its so-called invisible effects, which begin with the unnoticeable retouching of filmed “truth” and ripple outward to what some have warned is the destabilization of the cinematic medium itself, replacing the industry at every level—from production to exhibition and distribution—with its digital other. Academic attention to CGI grew slowly alongside its emergence as a powerful if alien force in filmmaking and film culture during the 1980s and 1990s but took off after the crucial year of 1999, when The Matrix heralded the fusion of analogue and digital cinema. Along with celebrity, CGI has become a key focus of popular attention on “behind the scenes” information, and an industrial entry point for fledgling filmmakers with access to cheap digital tools. But even as it extends the powers and profits of the film industry, CGI has challenged established practices and definitions, destabilizing film’s ontological base, its indexical relationship to reality, the tenets of classical narrative structure, and even the boundaries separating film from other media such as video games and experimental art.

Foundational Works

Although early and classical film theory paid some attention to cinema’s uncanny and spectacular elements, it was not until Bazin 1967 (originally 1945) defined the chief strength of film as its power to record and reproduce reality that critical awareness of the medium’s opposite tendency—creating “unreality” through manipulation—began to crystallize. While Youngblood 1970, Metz 1977, and Gunning 1990 each lay a piece of the groundwork for discussing the synaesthetic, psychological, and spectatorial functions of specifically cinematic spectacle, Heilig 2001 (originally 1955) and Sutherland 2001 (originally 1965) come at similar questions from the viewpoint of a different medium, the computer, placing emphasis on interactivity, design, and spatial architectures that would later become important aspects of virtual reality and video gaming.
.I 82
.T
document.82
.W
Cinema is about humanity, not fireballs
The question of whether computer animation has killed or enhanced the “magic” of cinema demands other questions, like:

How many more times can we tolerate digitally enhanced characters leaping into the air with their spear or knife drawn to descend superhero-like on an opponent? How many zooming overhead shots of fantasy landscapes and 360-degree panoramas can we stomach before we get dizzy? How many more villainous faces and grotesque monsters can enter our psyches before they cease to hold meaning? How many innumerable digital dots now pass for casts of millions (possibly forever superseding the quite literal “casts of thousands” from the days of “Ben-Hur")?
We’ve reached the surfeit point of limitless digital effects with limited imagination.

It should be obvious to even the most easily impressed moviegoer that the impact of the “Star Wars” and “Lord of the Rings” franchises is mostly technological and has had nothing to do with art. In this post-“Avatar” culture, Hollywood relies on digital effects to emphasize lavish other-worldly environments to give audiences what they want: escapism. But there’s also an escape from credibility happening here. Special effects used to bring us closer to realism; now they douse us in artifice. “Speed Racer,” anyone?
"Oz the Great and Powerful" has been digitized to look like a hyperactive coloring book. A prequel to "The Wizard of Oz," the movie substitutes potentially wondrous details with a certain overripeness of imagery. Technological excess has overwhelmed narrative meaning. This digital grandstanding suffocates what I -- and D.W. Griffith and Andre Bazin and past generations of theorists, critics and cinematic practitioners -- once considered the essence of cinema: nature and the human face.

The further Hollywood gets from that essence, the more computer-generated imagery we will get. “Animation Domination,” as it's advertised on the Fox network. It almost seems as if Hollywood’s emphasis on digital effects aims to turn moviegoers into children rather than aesthetically responsive viewers.

This overripeness is typical Hollywood overkill. Imagine a painter who keeps slathering on pigment. Why do we need so much color saturation? Or to put it another way: How many more fireballs must our heroes outrun?

We are suffering from digital effects overload, plain and simple.
.I 83
.T
document.83
.W
Beware of the uncanny valley
Computer-generated imagery works great for background special effects. But applied to the heroes of the story, it often gets too close for comfort. When animators attempt to bridge the gap between cartoon characters and live actors by creating ultra-lifelike human forms, their facsimiles frequently fall into a spooky region known to C.G.I. experts as the "uncanny valley." The characters seem at once human and alien, causing cognitive dissonance that settles into a feeling of fear or repulsion.
Recall (with a shudder) the 2007 film "Beowulf," in which the monster Grendel was "only slightly scarier" than "closeups of our human hero Beowulf's face," according to David Gallagher of The Times. Fearing such an effect, many animation studios steer clear of the uncanny valley altogether and prefer to place cartoonish humans amid more realistic surroundings, as in the Oscar-winning Pixar film "Brave." But the disconnect between characters and landscape can break a film's illusion, too.
Scientists find that the uncanny valley effect is elicited most strongly by characters that are highly realistic in some aspects but not others. Proportional facial features seem eeriest on faces lacking detailed skin, for example, whereas disproportionate features are more disturbing on photo-realistic faces. Psychologists have suggested that these mismatches might raise red flags because we are able to perceive subtle deviations from what we consider to be healthy or attractive in human beings. We then respond to these creatures evolutionarily, as we would toward a diseased or reproductively unfit stranger.
If experts can pinpoint and eliminate the creep factor, C.G.I. promises to replace an arguably even creepier element of film: cosmetically aged actors. They look weird to the point of distraction, and can sometimes limit a filmmaker's ability to tell stories that span decades. Computerized age progression could be the solution. In fact, C.G.I. experts I've interviewed count the 80-year-old digital double of Brad Pitt in "Benjamin Button" among their field's greatest triumphs.
.I 84
.T
document.84
.W
CGI Has inspired a new era of film making
I come at the topic of computer-generated imagery in film from an uncommon perspective: that of an actor. My movies have grossed over $4 billion at the box office, putting me in the ranks of George Clooney and Daniel Craig.

Yet you've likely never heard of me. This is because the majority of the characters I've played have been achieved via C.G.I., or what I refer to as digital hair, makeup and wardrobe. C.G.I. characters like Woody and Buzz, Shrek and Donkey, Sulley and Mike, and Nemo and Dory have left indelible impressions on all of us. But this is just one way in which C.G.I. has made “magic” onscreen.
My area of specialty happens to be one of the newest and most unique of the C.G.I. technologies: performance capture. In movies like “The Lord of the Rings,” “Avatar,” and “Pirates of the Caribbean,” hundreds of unique and fascinating characters have been created thanks to the brilliant synergy of performer and animator. The actor drives the character, providing its voice, emotions, physical movements, facial expressions and, dare I say, soul. The animator provides all the externals of the character and connects the digital dots to make the performance fluid, seamless and lifelike. Both are integral to and inseparable from the creative process.

C.G.I., in the hands of master filmmakers and wizardly animators, opens up worlds of possibility that previously existed only in our imaginations. And much like great acting, it does so without ever drawing attention to itself. For filmmakers, writers or producers, it allows them to achieve feats of storytelling previously unattainable. For actors, it allows them to explore and inhabit the souls of characters, human or otherwise, previously inaccessible.
I've played dozens of characters within a single film. I've played men and women of all shapes, sizes and ethnicities: aliens, monsters, elves and demons, ranging in age from 6 to 6,000. Because of C.G.I., I've worked in exotic locations as disparate as the North Pole, the Amazon, the Pandoran moon and the mead halls of Herot without ever leaving Los Angeles.

In my opinion, C.G.I. has ushered in a new era of filmmaking without restrictions, acting without boundaries and storytelling without limitations.
.I 85
.T
document.85
.W
Importance of Computer Generated Imagery (CGI) in Selling Your Property
CGI in real estate means the production of Computer Generated Images of a property for the presentation to potential clients before its completion.

It is the application of Computer Graphics to show interior architecture, design details, lighting, atmosphere and even the property within the environment, the gardens, garage, pool and more.

Floor plans are also brought to life using renders.

Below are but a few reasons of how Computer Generated Imagery works in your favor in the sale of your property.
Firstly, Computer Generated Imagery helps in visualizing technical concepts that would be difficult to illustrate in any other way.

This gives clients the opportunity to visualize living in that particular home.

Secondly, it is a useful way to create very high quality photo-realistic illustration.
Architectural visualizations give a professional, sharp and artistic edge to any real estate commercial presentation.

Thirdly, it is inexpensive and allows a single artist to produce content without the hiring of extras for crowd scenes, expensive set pieces or props.

Fourthly, Computer Generated Imagery’s visual effects are more controllable than other more physically based processes such as constructing miniatures for effect shots because it allows the creation of images that would not be feasible using any other technology.

Lastly, unlike hand-drawn animations, Computer Generated Imagery is time efficient and believable.

With Computer Generated Imagery there is the ability to go in and out of scenes and move images or objects not wanted without distorting the background or surrounding images.

All these make CGI (Computer Generated Imagery) really important while selling property for it gives clients the possibility to consider details such as dimensions and interior design options.

Thereby you get to present to your clients with exactly what they are to receive way before the completion of the project.
.I 86
.T
document.86
.W
Uncanny Valley
In 1970 Japanese roboticist Masahiro Mori proposed in The Uncanny Valleythat the more human a robot acted or looked, the more endearing it would be to a human being. For example, most lovable Robot Buddies look humanoid, but keep quirky and artistically mechanical affectations. However, at some point, the likeness seems too strong and yet somehow, fundamentally different—and it just comes across as a very strange human being. At this point, the acceptance drops suddenly, changing to a powerful negative reaction. The Uncanny Valley doesn't necessarily have to invoke fear though; for some people, the reaction is more similar to Narm or unintentional comedy. Either way, you don't feel the same about that character as you would a human, or even something less realistic.
If shown as a graph (like the one to the right), the acceptance on the Y axis and increasing X approaching human normal, there is a slow rise, then a sudden drop, then a sudden peak as "human normal" is reached. Masahiro Mori referred to this as the "uncanny valley". This video explains it extremely well.
Thus, things that look somewhat human, but are clearly not — such as C-3PO (in Star Wars) or a Golem — produce an accepting reaction, while things that are very nearly human, but just a little strange — such as a child's doll, a ventriloquist's dummy, or a clown — produce a negative response. For some people, the resonance is stronger with a moving object, which is why a corpse is creepy but a moving corpse is creepier still. In fact, some people that don't have a problem with things like zombies and consider them merely another monster may still be creeped out by things like unnatural movement.
This may also apply to sound as well. For example, a voice speaking words, but at a higher or lower pitch than is humanly possible, or a recording of a human voice, but played backwards. Or maybe a computer voice like Microsoft Sam. Though some people just find the effect comical and/or silly.
In recent decades this trope has applied to film CGI and video-game graphics, as technology has developed over time to allow for more photorealistic graphics, but not necessarily realistic movements. It's become very easy for computers to simulate textures and skin tones, but convincing movement and facial expressions aren't so simple, often requiring Motion Capture to look realistic. More stylized 3D models or a 2D art can generally get away with odd animations or expressions, but the more realistic the graphics shoot for, the more noticeable it is when something isn't lining up with reality. This is normally a cost issue, as detailed animation can be extremely time-consuming to craft and even more so when one set of animations is used for multiple characters and still needs look natural for all of them. Not putting in enough effort can produce the effect where a character can come across as a something less than human, like a zombie.
Many cartoons nowadays prefer a simultaneously stylized yet simplified character design, versus the realistic look amongst some older cartoons. In the latter, it's more obvious the budget just didn't allow characters to move much. Heavily rotoscoped characters also often seem less real than more stylized animated characters, especially when they're in the same production. See the Fleischer Studios version of Gulliver's Travels for an example.
Rather unfortunately, this trope can be applied to real life people and may be in part an explanation (though not an excuse) for things like racism when other groups of people inspire this reaction in certain people. People with social disabilities tend to be hurt hardest by this reaction, as people usually don't try to see past the "unnatural" behaviour of the individual and may have the same negative reaction that this trope describes.
This trope can also be used purposely, to make something creepy when creepiness is called for. Some examples of particular ways to produce this effect are listed under Creepily Long Arms, Creepy Long Fingers, Malevolent Masked Men, Body Horror and Uncanny Valley Makeup.
See also Reality Is Unrealistic, where the poor impression comes less from being "creepy" as from breaking existing conventions which audiences had come to expect. In addition, there's Off Model, Bishonen Line, No Flow in CGI, and Ugly Cute. And while you're at it, see What Measure Is a Non-Cute?, as the scientific study of that trope gave birth to this one. An opposite is Eldritch Abomination, where the unsettling effect is caused by being way too unfamiliar rather than being way too human, yet still produces the same abominable effect (although the two can overlap as a Humanoid Abomination). Furries Are Easier to Draw is a way artists get around the Uncanny Valley phenomenon; it's easy for drawn humans to to dip into the valley, but a cartoony talking animal doesn't evoke the same response.
.I 87
.T
document.87
.W
Computer Generated Imagery Case Study
There once was a time when CG was just for video games; low resolution, simple, animated, characters with no basis in reality.

Then the motion picture industry discovered CG. With unrivaled power, massive computers linked together to speed up renders, Toy Story and Shrek animation astounded us all. As CG has advanced over the years there’s hardly a movie without CG’s now realistic special effects, from hurricanes and blizzards, to bombs and explosions both on the big screen and TV.

To create the illusion of reality in motion pictures is one thing because images fly by at the rate of 30 frames per second and we’re surrounded with Dolby sound. However, CG in print is a different story. There is only one frame, silently telling its story, until the reader turns the page. Further, the resources put into print for one frame has been historically significant including: a location scout, stylist, equipment manager, prop manager, photographer and retouchers. How could CG ever replace all of those resources and effort, and approach the quality needed to replicate the reality of a beautiful live image?

Case Study

Recently, a client called in a panic. Art for a new product launch deadline was looming. The client had 4 or 5 different women’s sandals and a hand full of fabric swatches. One sandal was correct for the buckle, one was correct for the strap, yet another for the sole, so they didn’t have a whole shoe. Further, the swatches were not only for color but patterns and textures as well.

This is the perfect job for CG. Utilizing a maxed out render farm our CG artists modeled one shoe and used it across all skus. The fabrics were shot in the studio and used as a base to create needed textures. Multiple camera angles were achieved by moving the “virtual camera”.
CG programs are built to mimic photography, using a virtual studio, lighting, cameras and lenses, everything found in a conventional studio. The job was delivered in 3 days and 5 days after that these beautiful shots were headed to catalog pages and store windows across the country…while the real shoes, were just going into production on the other side of the world.

CG imagery is not perfect for every project, but in the hands of the right artists the quality these days is as good as photography and, often times better. Speed to market where there is no actual product available is a real strength. Extreme angles are easily achieved where they are near impossible in conventional photography. The placement of virtual lights in a virtual studio allows for some truly amazing shots. CG is a tremendous creative tool, giving the creative director a brand new palette and canvas.

Give us a call to set up a brief demo to see how CG can work for you. Its creative flexibility, turnaround time, and lower cost will astound you
.I 88
.T
document.88
.W
Uncanny valley (wikipedia)
The uncanny valley is a hypothesis in the field of aesthetics which holds that when features look and move almost, but not exactly, like natural beings, it causes a response of revulsion among some observers. The "valley" refers to the dip in a graph of the comfort level of beings as subjects move toward a healthy, natural likeness described in a function of a subject's aesthetic acceptability. Examples can be found in the fields of robotics and 3D computer animation, among others.
In compter animation and special effects
A number of films that use computer-generated imagery to show characters have been described by reviewers as giving a feeling of revulsion or "creepiness" as a result of the characters looking too realistic. Examples include the following:
According to roboticist Dario Floreano, the baby character Billy in Pixar's groundbreaking 1988 animated short film Tin Toy provoked negative audience reactions, which first led the film industry to take the concept of the uncanny valley seriously
The 2001 film Final Fantasy: The Spirits Within, the first photorealistic computer-animated feature film, provoked negative reactions from some viewers due to its near-realistic yet imperfect visual depictions of human characters.
Several reviewers of the 2004 animated film The Polar Express called its animation eerie. CNN.com reviewer Paul Clinton wrote, "Those human characters in the film come across as downright... well, creepy. So The Polar Express is at best disconcerting, and at worst, a wee bit horrifying”
In a review of the 2007 animated film Beowulf, New York Times technology writer David Gallagher wrote that the film failed the uncanny valley test, stating that the film's villain, the monster Grendel, was "only slightly scarier" than the "closeups of our hero Beowulf’s face... allowing viewers to admire every hair in his 3-D digital stubble”
In the 2010 live-action film The Last Airbender, the character Appa, the flying bison, has been called "uncanny". Geekosystem's Susana Polo found the character "really quite creepy", noting "that prey animals (like bison) have eyes on the sides of their heads, and so moving them to the front without changing rest of the facial structure tips us right into the uncanny valley"
.I 89
.T
document.89
.W
CG Imagery - The Artist is Key!
More and more companies are using CG (Computer Graphics) in their catalogs and other marketing collateral. The use of CG opens up whole new words of imagery and can save a significant amount in cost and speed to market.

However, is it the beginning of the end for the artist?

In a word… NO!

The CG process mimics traditional photography but only removes the physical aspects. CG replaces the physical hardware, locations, environments and props with virtual replicas. Computer simulations are used to calculate the relationship of property of lights, materials, and objects into the CG rendering.

However, it is often misconstrued that using CG in place of photography removes the human influence or that photographs are automatically created without the impact of the artist. The artist “photographer” STILL provides the input that the CG (computer element) feeds on to make the calculations.

A successful CG job still relies on the artistry of a person to translate the visual elements as input for the computer to generate the final output. However, once the artists have done “Their Magic” CG can take you beyond the physical limitations of the real world. The result is more flexibility in creativity, significantly lower cost in production, and shortened time to market.

Meet Salt Studios – media production and image realization specialist. With a single point of contact, industry digital artists and cutting edge technology, we can create, manage and enhance all of your visual assets. The result is an optimized marketing strategy with global brand consistency, reduced time to market, all while improving your bottom line efficiencies.
.I 9
.T
document.9
.W
3D Animation and generated imagery
Program Information
3D Animation and Computer Generated Imagery is a new three-year DEC program being offered at Dawson. It is the first program of its kind to be offered in English in Quebec. This innovative course of study will teach you to apply the academic, technical and general education skills necessary to enter the workforce as a 3D computer graphic artist as part of a production team in the animation industry.

Students in this program will learn:

To analyze the characteristics and requirements of a project
To produce a prototype or layout of the animation
To model characters, props and the environment
To apply textures and colors to the models
To add lighting to the scene; animate the characters and incorporate other graphic elements to render the final versions of scenes and characters
To produce digital visual effects and compositing, and work with motion capture data
Career Opportunities
The 3D Animation and Computer Generated Imagery program is designed to facilitate a student’s entry into a career as a 3D computer graphic artist in the 3D animation industry.

Upon graduation, graduates may choose to work as part of a production team as one of the following specialists:

Modeller: translating concept art into 3D models of creatures, humans, and other physical objects, like vehicles, furniture, trees, buildings, using 3D application software.
Animator: applying movement to human and animal models; infusing them with personalities and animating their subtle gestures. Animators can also animate other objects such as vehicles and spacecraft.
Texture Artist: putting the final touches on gray scale models. Texture artists design the visible surfaces that cover the architecture, environments, creatures and objects.
Lighting and Visual Effects Specialist: creating the ambiance in an animated film. These specialists are called upon to create the effects of light and shade that make sets look real. Special effects animators produce special effects, such as tornadoes, or asteroids, simulating the actions of air, fire, water and wind.
.I 90
.T
document.90
.W

Computer animation
Computer animation is the art of creating moving images via the use of computers.

It is a subfield of computer graphics and animation.

Increasingly it is created by means of 3D computer graphics, though 2D computer graphics are still widely used for low bandwidth and faster real-time rendering needs.

Sometimes the target of the animation is the computer itself, but it sometimes the target is another medium, such as film.

It is also referred to as CGI (Computer-generated imagery or computer-generated imaging), especially when used in films.

To create the illusion of movement, an image is displayed on the computer screen then quickly replaced by a new image that is similar to the previous image, but shifted slightly.

This technique is identical to how the illusion of movement is achieved with television and motion pictures.

Computer animation is essentially a digital successor to the art of stop motion animation of 3D models and frame-by-frame animation of 2D illustrations.

For 3D animations, objects (models) are built on the computer monitor (modeled) and 3D figures are rigged with a virtual skeleton.

For 2D figure animations, separate objects (illustrations) and separate transparent layers are used, with or without a virtual skeleton.

Then the limbs, eyes, mouth, clothes, etc. of the figure are moved by the animator on key frames.

The differences in appearance between key frames are automatically calculated by the computer in a process known as tweening or morphing.

Finally, the animation is rendered.

For 3D animations, all frames must be rendered after modeling is complete.

For 2D vector animations, the rendering process is the key frame illustration process, while tweened frames are rendered as needed.

For pre-recorded presentations, the rendered frames are transferred to a different format or medium such as film or digital video.

The frames may also be rendered in real time as they are presented to the end-user audience.

Low bandwidth animations transmitted via the internet (e.g. 2D Flash, X3D) often use software on the end-users computer to render in real time as an alternative to streaming or pre-loaded high bandwidth animations.
.I 91
.T
document.91
.W
How computer animation works
The movie opens with a sweeping aerial shot of an alien world. As the camera swoops downward from the clouds, a vast city emerges. Thousands of space-age vehicles whir past on an intergalactic freeway. Great skyscrapers crowd a smoggy skyline lit by a deep orange sunset. The camera continues its speedy descent to the 112th-story balcony of a steel gray apartment building, where it focuses on the pensive face of our hero, a giant lizard man named Fizzle.

We know that none of this is real, but we still believe. That's the magic of modern filmmaking. Using powerful computers, animators and digital effects artists at companies like Industrial Light & Magic can construct fictional worlds and virtual characters that are so lifelike, so convincingly real, that the audience suspends its disbelief and enjoys the show.

Computer animators are artists. While their tools are high-tech, nothing replaces their creative vision. That said, over the past two decades, computers have opened up unimaginable possibilities for animators. With sophisticated modeling software and powerful computer processors, the only limit is the animator's imagination.

The applications of computer animation extend far beyond film and television. Video games are at the forefront of interactive 2-D and 3-D animation. 3-D animators help design and model new products and industrial machines. In fields like medicine and engineering, 3-D animation can help simplify and visualize complex internal processes. And computer animators are in high demand for marketing and advertising campaigns.

But how exactly do these magicians create people, animals, objects and landscapes out of thin air? What are the basic techniques for modeling and animating virtual creations? And how long does the process take? (Hint: much longer than you think!) Keep reading to find out.

what is computer animation
To animate means "to give life to". An animator's job is to take a static image or object and literally bring it to life by giving it movement and personality. In computer animation, animators use software to draw, model and animate objects and characters in vast digital landscapes. There are two basic kinds of computer animation: computer-assisted and computer-generated.

Computer-assisted animation is typically two-dimensional (2-D), like cartoons. The animator draws objects and characters either by hand or with a computer. Then he positions his creations in key frames, which form an outline of the most important movements. Next, the computer uses mathematical algorithms to fill in the "in-between" frames. This process is called tweening. Key framing and tweening are traditional animation techniques that can be done by hand, but are accomplished much faster with a computer.

Computer-generated animation is a different story. First of all, it's three-dimensional (3-D), meaning that objects and characters are modeled on a plane with an X, Y and Z axis. This can't be done with pencil and paper. Key framing and tweening are still an important function of computer-generated animation, but there are other techniques that don't relate to traditional animation. Using mathematical algorithms, animators can program objects to adhere to (or break) physical laws like gravity, mass and force. Or create tremendous herds and flocks of creatures that appear to act independently, yet collectively. With computer-generated animation, instead of animating each hair on a monster's head, the monster's fur is designed to wave gently in the wind and lie flat when wet.

Technology has long been a part of the animator's toolkit. Animators at Disney revolutionized the industry with innovations like the use of sound in animated short films and the multi-plane camera stand that created the parallax effect of background depth.

The roots of computer animation began with computer graphics pioneers in the early 1960s working at major U.S. research institutes, often with government funding [source: Carnegie Mellon School of Computer Science]. Their earliest films were scientific simulations with titles like "Flow of a Viscous Fluid" and "Propagation of Shock Waves in a Solid Form" .

Ed Catmull at the University of Utah was one of the first to toy with computer animation as art, beginning with a 3-D rendering of his hand opening and closing. The University of Utah was the source of the earliest important breakthroughs in 3-D computer graphics, like the hidden surface algorithm that allows a computer to conceptualize three-dimensional objects, and the Utah Teapot, a strikingly rendered 3-D teapot that signaled a turning point in the photorealistic quality of 3-D graphics [source: Carnegie Mellon School of Computer Science].

In 1973, "Westworld" became the first film to contain computer-generated 2D graphics. More films in the late 1970s and early 1980s relied on computer graphics, or CG, to create primitive effects that were designed to look computer-generated. "Tron" (1982) was ideal for showcasing undeniably digital effects since the movie took place inside a computer.

"Jurassic Park" (1993) was the first feature film to integrate convincingly real, entirely computer-generated characters into a live action film, and "Toy Story" (1995) from Pixar was the first full-length "cartoon" made entirely with computer-generated 3-D animation.

The increasing sophistication and realism of 3-D animation can be directly credited to an exponential growth in computer processing power. Today, a standard desktop computer runs 5,000 times faster than those used by computer graphics pioneers in the 1960s. And the cost of the basic technology for creating computer animation has gone from $500,000 to less than $2,000 [source: PBS].

Now let's look at the basics of creating a 3-D computer-generated object.

Computer generated objects
To create a 3-D computer-generated object, you'll need modeling software like Maya, 3ds Max or Blender. These programs come loaded with a large number of basic 3-D shapes, called primitives or prims, which are the building blocks of more complex objects. For example, you could model a car by connecting cubes, cylinders, pyramids and spheres of different shapes and sizes. Since these are 3D objects, they're modeled on the X, Y and Z axes and can be rotated and viewed from any angle.

When you first begin to model an object, it doesn't have any surface color or texture. All you see on your screen is the object's skeleton -- the lines and outlines of the individual cubes, blocks and spheres that have been used to construct it. This is called a wireframe. Each shape that's formed by the lines of the wireframe is called a polygon. A pyramid, for example, is made up of four triangle-shaped polygons.

In practice, there are several ways to create a wireframe model of an object. If you don't want to be confined to constructing objects from fixed shapes like blocks and cylinders, you can use a more free-form technique called spline-based modeling. Splines allow for objects with smooth, curved lines. Another method is to sculpt an object out of clay or some other physical material and use a 3-D scanner to create a wireframe copy of the object in the modeling software.

Once you have your wireframe -- through any modeling method you choose -- you can shade its surface to see what it would look like as a 3-D object. But to make the object look more realistic, you need to add color and surface texture. This is done in something called the materials editor . Here you can play with an endless palette of colors or create your own by adjusting the red, green and blue values, and tinkering with hue and saturation. Common surface textures like wood grain, rock, metal and glass usually come with the modeling software and can be easily applied to surfaces. You can also create image files in a program like Photoshop and wrap the image around the object like wallpaper.

Lighting is perhaps the most important component for giving an object depth and realism. Modeling programs allow you to light your objects from every imaginable angle and adjust how the surface of your objects reflect or absorb light. There are three basic values that dictate how a surface responds to light:

Ambient: the color of an object's surface that's not exposed to direct light
Diffuse: the color of the surface that's directly facing the light source
Specular: the value that controls the reflectiveness or shininess of the surface

Modeling programs are especially helpful for creating realistic looking 3D objects because they contain mathematical algorithms that replicate the natural world. For example, when you light a sphere from a certain angle, the surface reflects light in just the right way and the shadow is cast at the precise angle. These details trick the mind into thinking that this object on a two-dimensional screen actually has depth and texture.

Now let's look at how animators use computers to help create vast digital landscapes and realistic animated sets.
computer generated landscapes
Since the earliest days of motion pictures, filmmakers have looked for ways to convincingly (and inexpensively!) recreate vast, realistic landscapes and backdrops without having to actually film on-location at the peak of Mt. Everest or the moon's surface.

The most common solution is a production effect called matte painting. In traditional matte painting, artists relied on several techniques, from simply painting a huge fake backdrop (think of those old westerns with the cactus and sunset in the distance) to carefully replacing parts of a shot with scenes painted on glass.

Computers have added a whole new dimension to matte paintings. Literally. Digital matte painters use a combination of source photographs, 2-D Photoshop images, 3-D modeling and 3-D animation to create impressive fictional landscapes. Think of those magnificent establishing shots in the recent "Star Wars" movies, showing a sprawling intergalactic metropolis or a jungle fortress crawling with thick foliage and perched atop a raging waterfall.

For live action films, digital matte painters often get the assignment of creating a historically accurate backdrop for a scene. In "The Last Samurai," for example, the script called for Tom Cruise's character to wander out of a bar and into the streets of San Francisco, circa 1876. First, the live actors performed their scene in front of a green or blue screen. Then the digital matte painters consulted archive photos of the city to model a 3-D skyline. They took digital photos of a beautiful sunset and placed it behind their model cityscape. Then they created a computer-generated trolley that would clank down the steep street in front of the actors. (Go here for behind-the-scenes pictures and videos from Matte World Digital.)

Digital matte painters use the same techniques when creating landscapes for fully animated films, like those made by Pixar. If the characters are going to interact a lot with the virtual set, then each set element is rendered in 3-D [source: Pixar]. But for large establishing shots, or an enormous backdrop that will only be seen once, the matte painters use a combination of 2D Photoshop collages and 3D models to build realistic landscapes that fit within the style of the animated film. Pixar movies, for example, have become increasingly photorealistic without losing their "cartoony" quality. So the landscapes can't look perfectly "real." They have to be built on a color and texture palette that matches the rest of the movie.

Another technology that adds impressive realism to a digital landscape is something called a particle system [source: Vanderbilt University School of Engineering]. Particle systems use mathematical algorithms to recreate the natural movements of animated elements like smoke, fire and flocks of birds. For digital matte paintings, the animator doesn't have to draw every flame and every wisp of smoke as the city burns. He just uses the modeling software's particle tools to program how large he wants the flames to be and how dark and billowy the smoke should be. With the same controls, he can model one CG seagull and program the software to create a flock of birds that flap their wings at different paces to take slightly different paths as they soar across the sunset.

.I 92
.T
document.92
.W
computer generated characters
The process of creating a computer-animated character begins as it always has, with a pencil and paper. The art department submits hundreds of character sketches based on discussions with the writers and director. Once they settle on a design for a particular character, it's the animator's job to model the character in 3-D on the computer. Sometimes the art department will create a 3-D clay model of the character and then scan it into the computer to create a wireframe model.

Modeling characters isn't that different than modeling an object. The hard part is animating them. The human eye is very sensitive to unnatural or jerky movements. Walking, for example, is an extremely complicated movement that requires just about every part of the body to participate in a single, fluid motion.

One solution is to build an animated character as if it had an internal skeleton. This is called an articulated model [source: Vanderbilt University School of Engineering]. Basically, the character is built upon bones and joints that act according to a hierarchy. There are joints at the top of the hierarchy -- elbows, for example -- that control the movement of body parts that are lower in the hierarchy -- upper arm, forearm and hand, in this case. In this hierarchal structure, the animator only has to move one joint or body part, and the lower joints and body parts assume their correct position, like pulling a marionette's strings.

This brings us back to key framing and tweening. When animating a character, the animator only poses the character in key positions and lets the computer fill in the "in between" frames. This is made even easier by the articulated model and something called inverse kinematics [source: Vanderbilt University School of Engineering].

Let's say the animator wants to make the character raise his hand. Since all of the character's body parts are connected in a hierarchy, all the animator has to do is set a key frame with the character's hand in the desired position. The computer will not only fill in the movement of the hand, but of all the parts connected to the hand (arm, elbow, shoulder, et cetera). Animation software often comes with pre-loaded inverse kinematic models for walking and other common character movements.

Another popular method for creating smooth, realistic character movements is through motion capture. With motion capture, a live actor puts on a special suit embedded with dozens of sensors. The sensors rest on key parts of the body, like limbs and joints. The computer tracks and records the movements of the sensors and can use that data in different ways. The data can be used to directly control the limbs and joints of an animated character. In this sense, the live actor is moving the animated character like a puppet, even in real time. Or the sensor data can simply be used as a guide over which a character is modeled and animated.
.I 93
.T
document.93
.W
The Computer animation process
Half of the process of creating a computer-animated feature film has nothing to do with computers. First, the filmmakers write a treatment, which is a rough sketch of the story. When they've settled on all of the story beats -- major plot points -- they're ready to create a storyboard of the film. The storyboard is a 2-D, comic-book-style rendering of each scene in the movie along with some jokes and snippets of important dialogue [source: Pixar]. During the storyboarding process, the script is polished and the filmmakers can start to see how the scenes will work visually.

The next step is to have the voice actors come in and record all of their lines. Using the actors' recorded dialogue, the filmmakers assemble a video animated only with the storyboard drawings. After further editing, re-writing, and re-recording of dialogue, the real animation is ready to begin.

The art department now designs all the characters, major set locations, props and color palettes for the film. The characters and props are modeled in 3-D or scanned into the computers from clay models. At Pixar, each character is equipped with hundreds of avars, little hinges that allow the animators to move specific parts of the character's body. Woody from "Toy Story," for example, had over 100 avars on his face alone [source: Pixar].

The next step is to create all of the 3-D sets, painstakingly dressed with all of the details that bring the virtual world to life. Then the characters are placed on the set in a process called blocking. The director and lead animators block the key character positions and camera angles for each and every shot of the movie.

Now teams of animators are each assigned short snippets of scenes. They take the blocking instructions and create their own more detailed key frames. Then they begin the tweening process. The computer handles a lot of the interpolation -- calculating the best way to tween two key frames -- but the artist often has to tweak the results so they look even more lifelike. It's common for an animator to re-do a single short animated sequence several times before the director or lead animator is satisfied [source: Pixar].

High-quality animated films are produced at a frame rate of 24 frames per second (fps). For a 90 minute film, that's nearly 130,000 frames of animation. At Pixar, for example, an individual animator is expected to produce 100 frames of animation a week [source: Pixar].

Now the characters and props are given surface texture and color. They're dressed with clothing that wrinkles and flows naturally with body movements, hair and fur that waves in the virtual breeze, and skin that looks real enough to touch. Then it's time to light the scenes, using ambient, omnidirectional and spotlights to create depth, shadows and moods.

The final step of the process is called rendering. Using powerful computers, all of the digital information that the animators have created -- character models, key frames, tweens, textures, colors, sets, props, lighting, digital matte paintings, et cetera -- is assembled into a single frame of film. Even with the incredible computing power of a company like Pixar, it takes an average of six hours to render one frame of an animated film [source: Pixar]. That's over 88 years of rendering for a 90-minute film. Good thing they can render more than one frame at a time.
.I 94
.T
document.94
.W
A Short History of Computer Animation

For an excellent, albeit Pixar-centric, history of computer graphics, see the history of computer graphics in the toystory web site.

In the Research Labs

Computer animation has been around as long as computer graphics. The University of Utah , funded by DARPA, was the early pioneer in computer graphics and produced many of the well-known names in graphics as well as most of the important early work in computer graphics. The seminal work in computer graphics is Donald Sutherland's SketchPad system. This system animated line drawings on a screen by enforcing constraints in real-time. This is a form of model-based animation and will be discussed further in the chapter that deals with that topic (Chapter V).

Also produced from the effort of the University of Utah were some early films on a walking and talking figure, an animated hand and an animated face by such folks as Ed Catmull, Frank Crow, Fred Parke, and Jim Blinn. It has only been recently that this early work in animation has actually been eclipsed.

In the late sixties Chuck Csuri was doing some pioneering work in computer animation in the Computer Graphics Research Group at The Ohio State University. A major feature of the animation that came out of Ohio State in the mid-seventies was real-time video playback from a digital disk. The hardware that took the digital information, uncompressed it on the fly and converted it into a video signal was developed by the University of North Carolina under John Staudhammer. In the early 80s, the research group became the Advanced Computing Center for Art and Design and continues to produce computer animation.

Norm Badler , at the University of Pennsylvania, was one of the first researchers addressing the problem of human figure animation. He has continued this research and has established the Center for Human Modeling and Simulation . Jack is a software package developed at the Center which supports the positioning and animation of anthropometrically valid human figures in a virtual world.

Also in the mid-seventies, at Cornell University , the Program for Computer Graphics , under the direction of Don Greenberg , generated some architectural walk-throughs of Cornell's campus.

In 1974, the first computer animated film called Hunger was produced by Rene Jodoin, and directed and animated by Peter Foldes. This effort was a 2 1/2 D system that depended heavily on object interpolation techniques. This is discussed further in the chapter that covers object interpolation algorithms (Chapter IV). Canada has been active in computer animation (and animation in general) due in large part to the National Film Board of Canada and the National Resource Council Canada .

NYIT got into graphics in a big was in the late 70s. They produced some incredible animation. Many of the people from the Utah effort contributed to the NYIT lab. The Works represents some of the early impressive pieces to come out of NYIT.

Computer Animation: Films and Videos

Early computer animation companies included Mathematical Applications Group, Inc. (MAGI), Information International Inc. (III, or Triple-I), Digital Productions, Digital Effects, Image West, Robert Abel and Associates, and Cranston-Csuri.

Current computer animation companies (who also contribute significantly to research in the area are: Pixar , Industrial Light and Magic (ILM) , Pacific Data Images (PDI) , Disney , Xaos, Rhythm & Hues , Digital Domain , Lamb & Company , Metrolight Studios , Boss Film Studios , deGraf/Wahrman , R/Greenberg Associates , Blue Sky Productions , Sony Pictures Imageworks, and Apple . (One might also include Silicon Graphics. in that list since their equipment is used so extensively for computer animation.)

Of special note, are the award winning animations which Pixar has produced, including:

Luxo Jr. (1986)- first computer animation to be nominated for an Academy Award
Red's Dream (1987)
Tin Toy (1988)- first computer animation to win an Academy Award
Knick Knack (1989)
These animations, I believe, really paved the way for computer animation to be taken as a serious enterprise. These pieces were the first fully computer generated animations to be taken seriously as animations, irrespective of the technique involved.

Early on, Computer Graphics (CG) appeared in a variety of movies in which it was used as computer graphics (that is, the CG was not intended to fool the audience into thinking it was anything other than CG). For example, Future World (1976) and Star Wars (1977, Image West) fall into this category. More recently, Lawnmower Man (1992, Pixar) which has a segment of Hollywood's view of Virtual Reality in it, used CG in the same role, although a more sophisticated example.

Tron (1982, MAGI) was a little different. The CG was still supposed to be computer-like because the action takes place inside a computer. But in this case, it was an integral part of the environment that the actions (and actors) were taking place in. The CG was used throughout the movie. It integrated computer animation with live action, but, since the action took place in a computer, the CG didn't have to look realistic (and didn't). This was the first time CG was used as an integral part of a movie.

Along the same lines of Tron in using CG to create an 'inside the computer' environment is Reboot (1995, Limelight Ltd./BLT Productions). Reboot deserves special mention as the first Saturday morning cartoon that is full three-dimensional computer-generated animation. The action takes place inside a computer so they don't have to go for 'realism'. Still, there are several human-like principle characters and they do a very impressive job.

One main use of CG has been to replace physical models. In this case, CG is used to create realistic elements which are intermixed with the live action. The Last Star Fighter (1984, Gray Demos' Digital Productions, even the Cray X-MP was in the credits) used computer animation instead of building models for special effects. The action takes place in space as well as on planets; CG was used for the scenes in space and physical models were used for the scenes on a planet. It's not hard to tell when the movie switched between CG models and physical models. There were probably 20 minutes of CG used in the movie. This was the first time CG was used as part of the live action in which it wasn't supposed to look computer generated. More recently, Apollo 13 (1995, Digital Domain) used CG models of the return vehicle from the mission. In TV-land, special note should go to Babylon 5 (1995, Newtek). Babylon 5 is the first TV show to routinely use CG models as regular features of it's sci-fi show - and it's Amiga-based.

CG is also used to create 'alien' creatures. Creatures which are supposed to be realistic, but don't have to match anything that the audience is familiar with. The Abyss (1989, ILM) is one such movie in which CG is used to effect an alien creature which is integrated with the rest of the live action. Some of the CG in Terminator II served a similar purpose as well as Casper (1995, ILM), Species (1995, Boss Film Studios), Mighty Morphin' Power Rangers (VIFX), Sexy Robot (TV Commercial, Abel)

More challenging is the use of CG to create realistic models of creatures that are familiar to the audience. Jurassic Park (1993, ILM) was the first to completely integrate use of CG character animation in which the graphics were designed so as to blend in with the live action so that it was difficult to tell what was computer generated and what wasn't. Jumanji (1995, ILM) does the same thing with it's incredible modeling of animals. To a lesser extent, Batman Returns (1995, Digital Domain) also does the same thing by providing 'stunt doubles' of Batman in a few scenes. CG was used to create the face of RoboCop 2 (1990, deGraf/Wahrman) and animated skeletons in Total Recall (Metrolight) as well.

Another popular CG technique for special effects is the use of particle systems. One of the best examples is in Star Trek II: The Wrath of Khan (LucasFilm - progenitor of ILM) in which a wall of fire sweeps over the surface of a planet. Another example is Lawnmower Man in which a character disintegrates into a swirl of small balls. A more recent example from television is in the opening sequence of Star Trek: Deep Space Nine (1995) to model a comet's tail. A movie soon to be released is called Twister which also uses particle systems.

Of course, one use of computer animation is simply to 'do animation.' By that I mean that is it used to produce animated pieces that would otherwise be done by more traditional means - essentially 3D cartoons (although that term cheapens the idea somewhat). The Pixar animations have been previously mentioned. Technological Threat was an early animation that combined computer animation with hand-drawn animation to produce an entertaining piece. TV commercials, for the most part, fall into this category. Some popular ones come to mind: Listerine, Shell dancing cars, LifeSavers. Toy Story (1995, Pixar), the first full length fully computer-generated 3D animation, would fall into a category of 3D cartoon. See the paper on the making of Toy Story . Absolute realism is not the objective as much as doing a computer generated version of what would normally be done by traditional animation means. The previously mentioned 2 1/2 D Hunger would fall into this category, as would the TV episode of The Simpsons (1995, PDI) in which Homer turned into a 3D CG character and the TV special Incredible Crash Dummies (Lamb & Company).

Although I'd like to restrict my topic to 3D computer animation, I suppose that morphing should be mentioned. This is essentially a 2D procedure which warps control points of one image into the control points of another image while the images themselves are blended. In Willow (1988, ILM), ILM provided the morph of several animals. This technique was also used by ILM in Indiana Jones and the Last Crusade (1989) and Terminator 2 . PDI is known for its use of morphing in various commercials including a Plymouth Voyager commercial and an Exxon commercial in which a car changes into a tiger. Of course, morphing has gone on to become another Energizer Bunny of TV commercials - it keeps going and going and going... Full 3D morphing has to make it out of the research labs and into any production environment.

There is another class of movies in which CG plays a role - that of 'hidden special effect' (for lack of a better term). CG can be used to cover up mechanical special effects or to enhance the scene to integrate a mechanical special effect more completely. For the most part, this resides in the 2D realm and, as such, will not be the focus of this document. However, with the onset of digital techniques for 2D compositing, sequences will be routinely digitally available making them susceptible to a variety of digital post-processing techniques. For example, in True Lies (1994, Digital Domain), CG was used to erase support wires from suspended actors. In Forest Gump (1994, Digital Domain), CG was used to insert a ping pong ball in a sequence showing an extremely fast action game. In Babe (1995, Rythm & Hues), CG was used to move the mouths of animals and fill in the background uncovered by the movement. In Interview with a Vampire (1994, Digital Domain), CG was used to curl the hair of a woman during the transformation into a vampire. In this case, some of the effect was created using 3D graphics and then integrated into the scene by 2D compositing.
.I 95
.T
document.95
.W
These Retro computer animations were way ahead of their time
Computer generated imagery is now so ubiquitous at the box office that it's a pleasant surprise when a movie like Mad Max: Fury Road goes light on the CGI. But while this technology came into its own in the 1990s and has gotten much more realistic from there, computer-generated graphics have existed since the early 1960s. Those early attempts are amazing to behold, and show us something cool about the history of graphics.

One of the first documented animations was a Swedish demonstration of a planned highway. It's a pretty simple vector animation by today's standards, but a robust demonstration at the time. Produced in 1960, it aired on Swedish TV in late 1961.
In 1963, Ivan Sutherland of MIT gave a demonstration of a light pen that enabled computer-rendered drawing. The device interacted with the screen as a computer peripheral that's somewhere between a mouse and a stylus. The technique was rough. It didn't exactly enable a full digital drawing, but assisted in the rendering of circles, lines, and other shapes.

Part one of the demonstration can be seen here. What's really impressive happens around the three-minute mark, where Sutherland demonstrates the capability of the Sketchpad to render a 3D object. At around 5:40, they mention that MIT is working on creating objects with more curves and not-so-straight-ahead renderings.
Around the same time, Bell Laboratories was also working on CGI. In this 1963 demonstration, it showed off a 3D rendering of how a communications satellite might stay in contact with the ground (pretty advanced for 1963).This is not only a demo of 3D modeling, but also full-on 3D animation. It's quite fluid – no less impressive than CGI used in movies like Star Wars more than a decade later.
"Hummingbird" was an art piece Charles Csuri and James Shaffer created in 1967. The animation doesn't quite put the hummingbird in flight. Impressively, though, it rendered an authentic light drawing of the hummingbird before twisting, distorting, and fragmenting it for the experimental piece. A Russian film, "Kitty," did little more with the premise.
A Computer Animated Hand is what truly revealed the potential of CGI graphics. Created by Edwin Catmull and Fred Parke while they were students at the University of Utah, the 1972 project demonstrated a fully rendered human-like hand. Sadly, Catmull left computers behind and was never heard from again...

...Just kidding, he's the president of Pixar now. And A Computer Animated Hand has since been abducted into the National Film Registry as an important cultural artifact. It's not hard to see why:

Parke was no slouch when it came to CGI, either. By 1974, he presented this 3D rendering of faces as his thesis, showing a deep advancement in the field of "grimaces from the uncanny valley." He also rendered 3D faces in 1974 that were leagues better than the infamous CGI used in 2001's The Mummy Returns, which turned The Rock into a CGI monster with the texture of silly putty.
Where Catmull continued his work in the entertainment industry, Parke stayed roughly within academia, currently serving as the head of Associate Head of the Department of Visualization at Texas A&M's architecture school. But by creating one of the first realistic, 3D renderings of a human face, his contributions to the field were as immeasurable.

This work on the computer-animated hand eventually ended up in Futureworld, an 1976 sequel to Westworld. Westworld used one of the first examples of digital imaging, re-rendering scenes shot on film to appear as though you were seeing them from the pixellated viewpoint of Yul Brinner's defective cowboy robot. But Futureworld featured a full rendering of a hand on screen – becoming the first official 3D animation in a motion picture, a dark path that would lead us to Jar Jar Binks and the career of Michael Bay.

These experiments of the 1960s and 70s happened at a time when the personal computer and home video game systems were just a dream of the future. Even, computers were capable of powerful things, including giving birth to the way movies are made today.
.I 96
.T
document.96
.W
CS Careers: Computer Animation
Computer animation has become a mainstay in the entertainment industry, and sometimes you wouldn’t even realize that something you are watching is computer animation. From character animations in Pixar films, to creating realistic massive crowd replications in big budget blockbusters to designing virtual reality worlds for new technology like the Oculus Rift, computer animation or CGI (computer-generated imagery) animation is the process used for generating animated images by using computer graphics. [i] Thanks to its growing popularity, the job market for computer animators has been increasing!
There are two types of computer animation commonly used in the field:
Computer-assisted animation is usually classed as two-dimensional (2D) animation. Creators drawings either hand drawn (pencil to paper) or interactively drawn(drawn on the computer) using different assisting appliances and are positioned into specific software packages. Within the software package the creator will place drawings into different key frames which fundamentally create an outline of the most important movements. The computer will then fill in all the ” in-between frames”, commonly known as Tweening. Computer-assisted animation is basically using new technologies to cut down the time scale that traditional animation could take, but still having the elements of traditional drawings of characters or objects.[i] Two examples of films using computer-assisted animation are Beauty and the Beast and Antz.
Computer-generated animation is known as 3-dimensional (3D) animation. Creators will design an object or character with an X,Y and Z axis. Unlike the traditional way of animation no pencil to paper drawings create the way computer generated animation works. The object or character created will then be taken into a software, key framing and tweening are also carried out in computer generated animation but are also a lot of techniques used that do not relate to traditional animation. Animators can break physical laws by using mathematical algorithms to cheat, mass, force and gravity rulings. Fundamentally, time scale and quality could be said to be a preferred way to produce animation as they are two major things that are enhanced by using computer generated animation. Another great aspect of CGA is the fact you can create a flock of creatures to act independently when created as a group. An animal’s fur can be programmed to wave in the wind and lie flat when it rains instead of programming each strand of hair separately.[i] A few examples of computer-generated animation movies are Toy Story, Frozen, Inside Out, Shrek, and Finding Nemo.
Check out this behind the scenes videos of the Making of Pixar Animation Monsters University:
The type of computer science and S.T.E.A.M. skills needed in computer animation can include drawing, 3D modeling, virtual reality, photography for stop motion animation, motion capture, graphic design, and computer programming. There are many colleges and universities that now offer degrees in computer animation, where the focus is generally on the more creative and artistic side of the field, but also teaching the latest high-end software needed to perform many tasks. The most popular animation software out there now includes Autodesk Maya, Adobe After Effects and Animate, Toon Boom Harmony, Cinema 4D, DragonFrame for stop motion animation, Pixologic, and several from The Foundry.
Those interested in a career in animation might find employment in a production or animation studios for TV and film, but also in advertising, web design, and video game fields. Some of the most well known animation studios are Pixar, DreamWorks Animation, Walt Disney Animation, Blue Sky Studios, Nickelodeon Studios, and Sony Pictures Animation. Many of these studios have high-profiled internships where students can get their foot in the door. Here are just a few …
Pixar Internships
Disney TV Animation Internship
Nickelodeon Internship Program
DreamWorks Animation Television Apprenticeship
.I 97
.T
document.97
.W
How does computer animation work?
Admittedly, it’s quite a long way until one of our TASSEN clips is finished: Aside from conceptualizing the jokes and plot lines and
the matching sound recordings, we also need to get started by creating a virtual 3D model.  
Let’s begin with the first step of computer animations: MODELING.  

First of all, you need a design. This design will determine from which basic geometrical shape the character will be virtually modeled.  

Starting from this foundation, more and more lines are added, moved or erased. Meanwhile, we keep an eye on how the results will look in the gray preview version.   This preview is usually called “GL” in our industry, based on the term “Open GL,” the default graphics display setting for graphic processors in computers.  

At this point, the final appearance and desired image quality are not yet an issue.
Once the MODELING is completed, we begin
with two processes that run simultaneously:  
They’re called SHADING and RIGGING.
 
SHADING is all about the shades on the surface of the object. During this process, the surfaces are covered with material surfaces and textures.  
This step is a major factor for the final look and optical quality of an animation.  
For instance, porcelain is a rather interesting surface material: It combines the matted, slightly translucent look of porcelain with a highly reflected and also transparent finishing layer.  

At the same time, SHADING is also an important precursor to RENDERING and associated POST-PRODUCTION.  

During the RIGGING process, the grid model is enhanced with an animation skeleton. We literally add the bones along which a character can later be moved.
 
We also add so-called “shapes,” including facial expressions, that can be associated with control panels during RIGGING, allowing for blending different shapes to create a wide range of nuances in the 3D-model. In the next step, the rigged 3D-model is passed on to the person in charge of moving this skeleton: The animator.
Now, when we speak of ANIMATION, we mean the entire field of ANIMATION – the way in which objects are moved/animated.
 
In the world of computer animation, the animator takes over the role of an actor. He is the one breathing life into the 3D-skeleton, creating a funny or serious character in the process.  

Here at FIFTYEIGHT, we take great care in animation – making sure that the viewer can make an emotional connection to our animated characters. If something is animated without a “soul,” even the highest quality graphical finish becomes useless.  

Once a character is animated and the scene has been properly lit up by the shading artist, it’s time for RENDERING to begin.  

A mere second of finished video requires a multitude of individual frames to create movement.  

This is the process during which multiple computers with manifold processors are calculating away at processing the images in an air-cooled room.  

The current industry standard is at 25 single images per second, also called FRAMES.  

Every individual frame, especially in complex scenes, can consist of up to 10 PASSES.  

Based on these passes, the reflectiveness of certain objects during POST-PRODUCTION can be amplified or toned down by applying maskings. We can also add motion blurs, tweak colors and adjust brightness and contrast etc.
During POST-PRODUCTION, or “Post” in short,
all these settings are applied by the director and the shading artist. It is customary for post-production to work closely with the shading artist; in some cases, it’s even the same person.

If a film is entirely shot from one angle, all that
is still needed is the audio track. In a clip consisting of numerous angles and takes, the sequences of images are joined together and cut appropriately.

These image sequences are called SHOTS that are compiled during the EDITING stages.  
The editing creates the final cut, which is the basis for transferring the finished move
to tapes or exporting it for digital upload.  

That’s it. Sounds like a lot of work? That’s because it is!  

But it’s also a whole lot of fun and if we end up getting a great response like for our TASSEN clips, it’s definitely been worth all the effort!
.I 98
.T
document.98
.W
The 5 Types of Animation – A Beginner’s Guide
What Is This Guide About?
The purpose of this guide is to, well, guide you through the intricacies of becoming an animator.


Traditional animation
Traditional animation, sometimes referred to as cel animation, is one of the older forms of animation, in it the animator draws every frame to create the animation sequence. Just like they used to do in the old days of Disney. If you’ve ever had one of those flip-books when you were a kid, you’ll know what I mean. Sequential drawings screened quickly one after another create the illusion of movement.

“There’s always room out there for the hand-drawn image. I personally like the imperfection of hand drawing as opposed to the slick look of computer animation.”
Matt Groening
About Traditional Animation
In traditional animation, animators will draw images on a transparent piece of paper fitted on a peg using a colored pencil, one frame at the time. Animators will usually do test animations with very rough characters to see how many frames they would need to draw for the action to be properly perceived. Timing is extremely important in traditional animation, since the frames has to fit the soundtracks exactly, as such the animation process of traditional animation can be lengthy and costly. Once the clean-up and in-between are complete, the production would step over to photographing each individual frame.

History
The history of animation can be stretched as far back as 5.000BC, if you are lenient on the techniques of the art form, found on a pottery bowl in Iran that depicts a goat leaping.

The techniques of animation that we are more familiar with, however, first appeared in 1650 as The Magic Lantern, by the Venetian inventor Giovanni Fontana. Whether or not he truly is the inventor is still highly debated. A simple lantern with a strip of animation sliding past a crude lens, illuminated by a single candle, was the humankind’s first introduction to projection. Which was primarily used to scare people witless with images of devilish creatures running on the wall, and generally play on people’s superstitions.

Many more inventions came along, such as the Phenakistoscope and Zoetrope, but the first projection of animation on a screen came in 1877 with the Praxinoscope, invented by the French science teacher Charles-Émile Reynaud. He then later invented the Théâtre Optique in 1888, which he then used to stage the first public screening of animation at the Musée Grévin in Paris in 1892.

There he screened the animated short Pauvre Pierrot, which is notable for being the first time film perforations was used, and also for having the animation drawn directly on the frames instead of photographed.

The first film recorded on a filmstrip was made in 1900, which also included animated sequences where J. Stuart Blackton draws a man on a aisle holding a bottle of wine, and  then the man grabs the bottle. Blackton then followed it up five years later with the Humoureous Phases of Funny Faces, which cemented J.Stuart Blackton as the forefather of American animation.

Stepping to France in 1908, we saw the worlds first fully animated film, made by the French artist Émile Cohl. The film was called Fantasmagorie, which contained stick figures encountering various inanimate objects that they interact with.

As the 1910’s rolled around, studio produced animations came into fruition with the newspaper cartoonist Winsor McCay, who directed several animated shorts. As such, during the 1910’s animations we’re then nicknamed ‘Cartoons’. They we’re mainly produced for cinemas to as pre-show attractions before the feature film. John Randolph Bray and  Earl Hurd was the most successful animation producers of the decade, and was responsible for patenting the cel animation process, which would come to dominate the animation industry for most of the century.

Nowadays, traditional animation is being done mostly on computers by using a tablet (such as the Wacom Cintiq.) It is usually animated on 12 frames per second, with occasional faster actions animated on 24 frames per second.

2D Animation
This style has become very popular in the last decade with the increasing amount of people doing it due to the accessibility of the technology. Flash is cheap and easy to use. Such are other vector based animation programs. 2D animation can be done in After Effects too.

“Animation is different from other parts. Its language is the language of caricature. Our most difficult job was to develop the cartoon’s unnatural but seemingly natural anatomy for humans and animals.”
Walt Disney
About 2D Animation
2D animation is mostly referred to any key framed animation that is produced on a flat surface, but can also refer to vector animations that adopts the techniques of traditional animation.

Cel animation is often most thought of when talking about 2D animation, and the process is often lengthy and complicated. The technique is the same as in traditional animation, but when the animations and in-betweens are done, the frames are brought over to a process called ink-and-paint.

There the people in charge of inking and painting the frames, places a plastic sheet of celluloid on top of the transparent paper containing the animated characters, and then proceed to copy the frames on the celluloid. This way frames can overlay each other because of the complete transparency of celluloid, which makes it easier to place multiple characters and props on top of a background.

Vector based animations, meaning computer generated 2D animations, uses the exact same techniques as traditional animation, but the benefits is the lack of physical objects needed to make traditional 2D animations apart from a computer.

History
In the late 90’s, due to bandwidth restrictions, many artists started using Flash to distribute short (and very limited) animations on the web, which were usually very small in size.

That limitation gave Flash the mass appeal that made it such a huge success among independent artists and animators, which lasted to today.

Flash really skyrocketed in 2005 when it was purchased by Adobe. When YouTube started growing, it completely exploded, and today you can find thousands of Flash animations there.

The reason 2D was put in a separate category in a different category is that in addition to the option of animating frame by frame, an animator has the option of creating rigs for the characters and then moving the body parts individually instead of drawing the character over and over.

After Effects allows you to create complex rigs for animation, or use the puppet tool to drag and move body parts of a drawn character.

These flexibilities give beginners more options when approaching animation, especially if drawing isn’t their strong suit, unlike traditional animation, when drawing skills are mandatory.

3D Animation (CGI, Computer animation)
3D animation works in a completely different way than traditional animation. They both require an understanding of the same principles of movement and composition, but the technical skill set is very different for each task. while in the past you had to be an amazing draftsman to be an animator, with computer animation that is not the case. 3D animation is more similar to playing with puppets rather than drawing.

“Computers don’t create computer animation any more than a pencil creates pencil animation. What creates computer animation is the artist.”
John Lasseter
About 3D Animation
3D animation, also referred to as CGI animation, is made by generating images using computer graphics that create a series of images that forms an animation. CGI means Computer Generated Images, so it can easily mean both static and dynamic images using computer graphics.

The animation techniques of 3D animation has a lot of similarities with stop-motion animation, as they both deal with animating and posing models, and still conforms to the frame-by-frame approach of 2D animation, but is a lot more controllable since it is all digital feedback.

Instead of drawn or constructed with clay, characters in 3D animations are digitally modeled on screen, and then fitted with a ‘skeleton’ that allows animators to animate the models for their use.

Animation is done by posing the models in certain key frames, which the computer will then calculate and perform a ‘tweening’ animation that is interpreted by the computer in each frame between the key frames.

When the modeling and/or animation is complete, the computer has to render each frame individually, which unlike 2D or stop-motion animations, can be very time consuming depending on the quality of the images and the quantity of polygons in the scene.

a 3D animator will spend most of their time looking at curves that represent the movement of different body parts over time.

Another big difference with 3D animation is that unlike traditional animation, the character’s body parts are always present and should be taken to consideration.

I’ll explain:

When animating in 2D, the character has to be drawn from every frame. When the character is viewed from the side, half of its body isn’t shown and thus isn’t drawn. It technically doesn’t exist. It’s drawn on a flat page and there isn’t really more of the character other than what the animator draws.

With 3D though, the character’s body parts always exist in the shot. Even when one hand isn’t visible, it’s still there. That adds some work for the animator, since we need to be aware of the entire character at all times.

The last major difference with 3D animation is the frame rate. Traditional animators usually work on 2’s which means they draw a new drawing every 2 frames, and thus having one drawing last for 2 frames. With 3D animation, however, the motion is always smooth (except for stylized pieces which intentionally try to look different) and having a character stop completely looks like a mistake.

Even when the character is standing still there should always be some sign of life or gentle movement to keep the illusion of life, this is something 2D animation can get away with much more easily than 3D animation.

History
3D animation has definitely revolutionized how the animation industry looks today, and it was all started with Toy Story (1995, Lassetter.) Computer generated animations wasn’t completely new at the time, since it had already been often used in TV shows, movies and computer games, but Toy Story set the bar by being the first feature-length computer animation, leading to a whole new industry and market.    

3D animation also lead to studios trying to achieve photo-realistic animations by combining high-level computer processing with advance motion-capture. This has led to films such as Final Fantasy: Spirits Within (2001, Sakaguchi) and The Polar Express (2004, Zemeckis), with very mixed results. This kind of animation became rarer as the decade passed, as the process is a lot more complicated than key framed 3D animations, but has passed on to feature film VFX.
.I 99
.T
document.99
.W
Usage of 3D animation techniques in today's world
Over the past few years, numerous businesses, 3D studios and student 3D graphics artists have made a successful push forward in the worldwide utilization of 3D items, computer animation (CGI) and three dimensional graphics. There are many different methods being utilized to create this content, and with over 40 3D titles hitting the big screens last year, the 3D evolution has officially began.

One of the first and most recognized methods to viewing 3D is through the anaglyph (cayan and Blue) glasses we all know too well. Watching anaglyphs via properly shaded eyeglasses ends up with each eye viewing a somewhat distinct image. So how do these glasses work?  In a red-cyan anaglyph in particular, a person’s eye covered by the reddish colored form of filtration views the red-colored portions of the particular graphic as “white”, as well as the cyan portions like “black” (with the brain supplying certain adaptations regarding color); the eye covered by the glowing cyan filtration system interprets the contrary influence. Genuine white-colored as well as genuine dark sections tend to be recognized the identical through each eye. The mind combines mutually the graphic it obtains coming from each individual eye, plus interprets the variations as being the consequence of diverse distances. That generates an ordinary stereograph picture without demanding the audience to cross his or her eyes. The computer may both accelerate innovative procedures for animating character types along with the time period it requires to create a movie or television show on the display screen.
A PC is merely a device; therefore with no competent designer at the helm, nothing could be developed. Designers have to have established solutions as well as applications they can rely on to generate the excellent pictures people love to see. Computer animation continues to be known as the intricate relationship between artwork and technology.”

One of many yet most quickly developing aspects of the computer graphics and computer animation industry is clearly the video game market.  Computer animated game creation relies heavily around the development involving premium quality three dimensional computer animations. Applications along with software programs are being continuously enhanced to maintain and increase the animated graphics and artwork which are growing to be more complicated, whilst the concept in the components simplifies.

The past year has been a thrilling time period for cell phones as well. We have observed a great amount of mobile phones with dual-core processors, 4G connectivity, as well as larger superior displays–all of which seeming to have stemmed from the initial trend associated with 3D. Overseas and only recently in the states, the current trend for new phones hitting the market has been 3D display smart mobile phones. These tend to be astonishingly effective cell phones for single person glasses-free 3D screens along with dual-lens digital cameras that enable you to photograph 3D photographs and video clip in 3D using stereo techniques of a side by side capture.

Three dimensional illustrations or photos have the ability to give  website page models a variety of three dimensional illusions, which can be effective tools pertaining to managing awareness.

Utilizing 3D graphics within website development may also may provide substantial benefit all around for web page file size of HTML 5 stereoscopic techniques. Although if it is overused it may decrease user friendliness, stereoscopic website development will be an art and must be utilized intentionally and with consideration.
Three dimensional artwork develops quite an impression of space among various components. This makes it an effective means of reinforcing variations. Shadowing, such as drop-shadows, gradients, and highlighting, has the potential to be the most successful standard. In actuality, items that are tangible are three-dimensional; for instance switches for a car radio. The developers associated with earlier graphical user interfaces for computer systems utilized this to generate a genuinely exact Visual intuitive shortcut to convey “clickable”. The press button impression is among the most robust layout conventions in interactive layout. Source of light are frequently important. A couple of things to keep in mind regarding most 3D/shading effects are usually that they’re both lumination effects plus illusions. For the impression to be effective, an individual would need to assume that everything that they’re viewing might be actual. To produce an actual impression, you must use a credible facsimile regarding reality, along with persistence in procedure. Probably the most frequent errors in three dimensional effects are to try using several illumination methods incorrectly or as distinct components. It’s fine to have multiple source of light, and plenty of layouts do this regularly since it generates brighter as well as smoother outcomes. Yet, the entire lumination environment needs to be believable. Lower bandwidth animated graphics transmitted by means of the web utilize software package on the end-users pc to be able to render instantly instead of buffering or dealing with pre-loaded higher bandwidth animated graphics. Numerous enterprises stand to greatly benefit from this concept.

The real estate industry is very excited, as they are projected to generate the most profitability from it’s integration.  3D visualizations and virtual tours permit stockbrokers to be able to feature his or her properties in genuine style rather than static pictures. This is likely to become primarily efficient when it comes to extravagant, top-end real estate, who wishes to observe derelict structures through a model in 3D. For the potential real estate customer, it’s going to be much like being on spot and having a more detailed glance at the specifics. These people will receive a feeling of the dimension and depth of the suites, the illumination, the views, and also the luxury of the residence. 3D Film Connection is poised and ready to deliver these powerful 3D Stereoscopic Animations for the ever expanding list of appropriate and cost worthy uses.

